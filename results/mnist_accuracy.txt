=== BASELINE ===

model                          test    fgsm    pgd   deepfool carlini    fgsm    pgd    deepfool carlini
                                        -----baseline adversaries-----    -----robust adversaries-----

original                       99.13   5.91    0.71    34.83   28.96
fgsm_robust                    99.06   98.91   32.55   96.08   95.82     3.62    1.12   31.70    39.89    # 24 ago 15:49
deepfool_robust                99.03   23.11   35.55   99.20   95.70     17.41   0.70   54.31    35.48    # 24 ago 13:09:18
pgd_robust                     99.10   44.60   99.02   98.34   97.19     1.40    0.68   35.64    58.64    # 24 ago 13:08
carlini_robust                 99.10   14.74   3.85    94.63   99.06     2.42    0.68   33.27    31.18    # 24 ago 13:09:45

=== RANDREG ===    # proj_mode = one_channel
                                                                         
proj lambda  batch_s  epochs   test    fgsm    pgd  deepfool  carlini    fgsm    pgd   deepfool  carlini
                                        -----baseline adversaries-----    -----randreg adversaries-----

# building regularization term: loss gradients on projected points
0    0.5     1000      12      97.64   24.14   43.05   93.22   90.94      2.27   1.49   46.25   33.07    # no random projections, only regularization
1    0.5     1000      12      97.52   26.24   49.99   93.92   91.45                    -
3    0.5     1000      12      98.31   15.95   21.93   94.00   91.33     13.80   1.4    -
5    0.5     1000      5       98.15   17.72   25.75   93.49   91.00                    -
3    0.5     500       12      98.39   15.18   16.20   93.16   90.45     21.22   2.38   33.08   38.10    # norm
3    0.5     1000      12      98.25   17.28   23.82   94.73   92.04     14.15   1.29   49.40   36.76    # 22 ago, 10:25, flat inputs nel gradiente
3    0.5     1000      12      70.00   27.00   50.00   65.00   64.00     5.00    8.00   -                # 23 ago 14:25:13 size=(18,28)
3    0.5     1000      12      98.31   15.18   17.54   93.62   90.96     15.61   1.32   54.50   36.29    # 23 ago 17:20 size=(10,20)
3    0.5     1000      12      98.31   17.28   16.82   93.78   90.05     12.79   1.20   41.81   33.09    # 26 ago 09:07 size=(18,28) + norm

# tuning lambda: size_range=(18,28), no norm, earlystopping
3    0.3     1000      12      97.62   24.41   42.86   93.39   90.51     1.62    1.39   37.43   32.95    # 26 ago 14:53
3    0.4     1000      12      97.69   24.07   48.25   94.26   91.64     2.06    1.33   39.53   31.73    # 26 ago 14:54
3    0.5     1000      12      97.44   25.76   46.46   93.11   90.78     2.00    1.62   43.83   31.37    # 26 ago 14:55:44
3    0.6     1000      12      97.21   28.53   54.16   93.41   91.03     1.69    1.76   31.60   32.50    # 26 ago 14:55:12
3    0.7     1000      12      97.39   24.81   43.32   92.69   89.98     1.95    1.55   41.50   32.87    # 26 ago 14:56 

# testing projected_loss_regularizer, size_range=(8,28), proj_mode="grayscale"
1    0.6     1000      12
3    0.6     1000      12                                                                                # 27 ago 13:59
5    0.6     1000      12




=== RANDENS ===    # proj_mode = one_channel

n_proj  size_proj              test    fgsm    pgd   deepfool  carlini      test    fgsm    pgd   deepfool  carlini
                                       --- no baseline_prob ---                     --- baseline_prob ---

6       8                      96.60   28.74   63.38   93.65   92.20
9       8                      96.90   30.41   62.58   94.11   93.17
12      8                      97.03   30.93   63.56   94.39   93.45  
15      8                      97.05   32.30   64.75   94.52   93.53 
6       12                     97.73   30.07   61.37   95.59   94.19 
9       12                     97.72   30.40   62.05   95.68   94.34 
12      12                     97.74   30.38   62.85   95.92   94.47
15      12                     97.74   31.04   63.84   95.80   94.56
6       16                     97.92   28.14   58.40   96.15   94.60  
9       16                     98.04   28.20   58.65   96.37   95.09
12      16                     98.08   27.90   59.79   96.52   95.17 
15      16                     98.13   27.97   60.94   96.53   95.23 
6       20                     98.30   24.75   55.75   96.44   95.36   
9       20                     98.30   24.58   56.88   96.59   95.56
12      20                     98.31   24.75   57.58   96.65   95.53 
15      20                     98.33   25.03   57.56   96.77   95.62

                                          # 27 ago 09:58                             # 27 ago 14:11


















