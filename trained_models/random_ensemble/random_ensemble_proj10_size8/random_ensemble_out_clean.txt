
Loading mnist.
('x_train shape:', (60000, 28, 28, 1), '\nx_test shape:', (10000, 28, 28, 1))

Computing random projections.
('Input shape: ', (60000, 28, 28, 1))
('Projected data shape:', (10, 60000, 8, 8, 1))
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 0.8341 - acc: 0.7307
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4743 - acc: 0.8534
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4050 - acc: 0.8739
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3618 - acc: 0.8886
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3435 - acc: 0.8926
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3169 - acc: 0.9026
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3053 - acc: 0.9051
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2890 - acc: 0.9098
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2830 - acc: 0.9124
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2667 - acc: 0.9170
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2607 - acc: 0.9186
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2549 - acc: 0.9203
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 0.9072 - acc: 0.7013
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5412 - acc: 0.8269
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4709 - acc: 0.8531
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4160 - acc: 0.8697
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3866 - acc: 0.8786
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3610 - acc: 0.8868
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3369 - acc: 0.8934
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3212 - acc: 0.9007
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3205 - acc: 0.9014
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3065 - acc: 0.9044
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2957 - acc: 0.9083
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2918 - acc: 0.9085
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 0.9248 - acc: 0.7021
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5795 - acc: 0.8178
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4875 - acc: 0.8485
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4304 - acc: 0.8665
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4009 - acc: 0.8745
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3761 - acc: 0.8830
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3546 - acc: 0.8903
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3442 - acc: 0.8940
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3286 - acc: 0.8986
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3155 - acc: 0.9014
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3024 - acc: 0.9049
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.2972 - acc: 0.9073
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.0713 - acc: 0.6502
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6135 - acc: 0.8071
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5071 - acc: 0.8409
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4469 - acc: 0.8605
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4190 - acc: 0.8696
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3853 - acc: 0.8790
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3617 - acc: 0.8855
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3407 - acc: 0.8925
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3357 - acc: 0.8957
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3267 - acc: 0.8970
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3170 - acc: 0.9012
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3055 - acc: 0.9042
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.0848 - acc: 0.6446
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6380 - acc: 0.8006
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5357 - acc: 0.8313
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4838 - acc: 0.8497
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4428 - acc: 0.8621
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4180 - acc: 0.8714
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3965 - acc: 0.8769
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3770 - acc: 0.8830
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3586 - acc: 0.8875
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3451 - acc: 0.8912
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3399 - acc: 0.8947
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3304 - acc: 0.8967
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.1813 - acc: 0.6057
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6872 - acc: 0.7813
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5774 - acc: 0.8178
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5134 - acc: 0.8361
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4712 - acc: 0.8515
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4506 - acc: 0.8584
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4176 - acc: 0.8694
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4007 - acc: 0.8729
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3847 - acc: 0.8797
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3714 - acc: 0.8844
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3594 - acc: 0.8891
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3530 - acc: 0.8901
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.0375 - acc: 0.6626
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6425 - acc: 0.7988
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5349 - acc: 0.8320
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4946 - acc: 0.8463
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4422 - acc: 0.8635
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4108 - acc: 0.8717
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3841 - acc: 0.8810
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3732 - acc: 0.8853
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3599 - acc: 0.8883
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3439 - acc: 0.8929
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3325 - acc: 0.8980
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3271 - acc: 0.8999
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.0081 - acc: 0.6706
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6120 - acc: 0.8079
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5114 - acc: 0.8405
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4542 - acc: 0.8580
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4143 - acc: 0.8723
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3973 - acc: 0.8774
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3717 - acc: 0.8842
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3522 - acc: 0.8902
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3407 - acc: 0.8945
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3353 - acc: 0.8956
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3179 - acc: 0.9023
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3078 - acc: 0.9046
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.1025 - acc: 0.6337
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6690 - acc: 0.7883
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5624 - acc: 0.8241
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5096 - acc: 0.8415
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4607 - acc: 0.8575
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4428 - acc: 0.8647
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4195 - acc: 0.8700
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3965 - acc: 0.8782
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3847 - acc: 0.8822
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3652 - acc: 0.8880
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3595 - acc: 0.8915
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3457 - acc: 0.8937
('\nTraining infos:\nbatch_size = ', 128, '\nepochs =', 12, '\nx_train.shape = ', (60000, 8, 8, 1), '\ny_train.shape = ', (60000, 10), '\n')
Epoch 1/12

469/468 [==============================] - 2s 5ms/step - loss: 1.0430 - acc: 0.6577
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.6348 - acc: 0.8027
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.5344 - acc: 0.8338
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4851 - acc: 0.8490
Epoch 5/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4464 - acc: 0.8609
Epoch 6/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4144 - acc: 0.8703
Epoch 7/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4056 - acc: 0.8750
Epoch 8/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3839 - acc: 0.8812
Epoch 9/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3671 - acc: 0.8865
Epoch 10/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3603 - acc: 0.8888
Epoch 11/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3504 - acc: 0.8922
Epoch 12/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3431 - acc: 0.8942
('\nTesting infos:\nx_test.shape = ', (10000, 28, 28, 1), '\ny_test.shape = ', (10000, 10), '\n')

Computing random projections.
('Input shape: ', (10000, 28, 28, 1))
('Projected data shape:', (10, 10000, 8, 8, 1))
('\nPredictions on the first element:\n', array([[1.3419401e-02, 1.2120020e-02, 7.5313717e-02, 4.5687333e-02,
        1.3900515e-01, 3.0185908e-01, 1.6973455e-01, 4.2785336e-03,
        2.2065052e-01, 1.7931703e-02],
       [3.8875129e-02, 4.9780592e-05, 1.1200212e-01, 8.0172736e-03,
        3.8941029e-01, 4.3377377e-02, 8.9032061e-02, 5.2751057e-02,
        5.0035015e-02, 2.1644996e-01],
       [2.4402540e-03, 4.7110367e-04, 5.6089085e-02, 2.7618864e-01,
        6.8934783e-02, 2.1325581e-01, 1.4201949e-04, 5.2582741e-02,
        3.7875012e-02, 2.9202062e-01],
       [1.9029567e-01, 2.2211235e-02, 2.8768033e-01, 1.3434467e-01,
        3.1854000e-03, 2.4457364e-01, 7.6354668e-02, 1.4264555e-02,
        2.3429871e-02, 3.6600253e-03],
       [1.4910717e-01, 5.7868576e-05, 7.2195965e-01, 5.3335320e-02,
        4.9466308e-04, 2.3597447e-02, 6.9499998e-03, 2.2215579e-02,
        2.0425122e-02, 1.8572072e-03],
       [2.4046794e-02, 6.0170498e-03, 1.0849443e-02, 1.8610510e-01,
        9.0114186e-03, 6.1165953e-01, 5.9376722e-03, 9.3829380e-03,
        5.7468504e-02, 7.9521552e-02],
       [2.4370439e-03, 3.1157366e-03, 1.1942947e-01, 1.8339108e-01,
        4.8566926e-02, 2.2830430e-02, 1.8188471e-04, 3.2808936e-01,
        2.8429898e-02, 2.6352814e-01],
       [4.0307343e-03, 6.1004004e-03, 3.1923965e-02, 8.4539324e-02,
        3.6053911e-02, 3.9079964e-01, 2.3971808e-03, 2.9462752e-01,
        5.0416842e-02, 9.9110492e-02],
       [9.8263170e-04, 8.8398613e-02, 1.8625444e-01, 9.5395967e-03,
        9.0432251e-03, 2.3371369e-01, 1.2641944e-01, 1.4430849e-03,
        3.4388170e-01, 3.2363419e-04],
       [6.4851524e-09, 3.2255646e-11, 2.5369729e-06, 1.6917944e-06,
        5.9076854e-08, 7.4873256e-08, 1.7704859e-12, 9.9978036e-01,
        6.2854570e-09, 2.1519247e-04]], dtype=float32))

Original test data.
Correctly classified: 3473
Incorrectly classified: 6527
Test accuracy: 0.00%
('\nTesting infos:\nx_test.shape = ', (10000, 28, 28, 1), '\ny_test.shape = ', (10000, 10), '\n')

Computing random projections.
('Input shape: ', (10000, 28, 28, 1))
('Projected data shape:', (10, 10000, 8, 8, 1))
('\nPredictions on the first element:\n', array([[1.3419401e-02, 1.2120020e-02, 7.5313717e-02, 4.5687333e-02,
        1.3900515e-01, 3.0185908e-01, 1.6973455e-01, 4.2785336e-03,
        2.2065052e-01, 1.7931703e-02],
       [3.8875129e-02, 4.9780592e-05, 1.1200212e-01, 8.0172736e-03,
        3.8941029e-01, 4.3377377e-02, 8.9032061e-02, 5.2751057e-02,
        5.0035015e-02, 2.1644996e-01],
       [2.4402540e-03, 4.7110367e-04, 5.6089085e-02, 2.7618864e-01,
        6.8934783e-02, 2.1325581e-01, 1.4201949e-04, 5.2582741e-02,
        3.7875012e-02, 2.9202062e-01],
       [1.9029567e-01, 2.2211235e-02, 2.8768033e-01, 1.3434467e-01,
        3.1854000e-03, 2.4457364e-01, 7.6354668e-02, 1.4264555e-02,
        2.3429871e-02, 3.6600253e-03],
       [1.4910717e-01, 5.7868576e-05, 7.2195965e-01, 5.3335320e-02,
        4.9466308e-04, 2.3597447e-02, 6.9499998e-03, 2.2215579e-02,
        2.0425122e-02, 1.8572072e-03],
       [2.4046794e-02, 6.0170498e-03, 1.0849443e-02, 1.8610510e-01,
        9.0114186e-03, 6.1165953e-01, 5.9376722e-03, 9.3829380e-03,
        5.7468504e-02, 7.9521552e-02],
       [2.4370439e-03, 3.1157366e-03, 1.1942947e-01, 1.8339108e-01,
        4.8566926e-02, 2.2830430e-02, 1.8188471e-04, 3.2808936e-01,
        2.8429898e-02, 2.6352814e-01],
       [4.0307343e-03, 6.1004004e-03, 3.1923965e-02, 8.4539324e-02,
        3.6053911e-02, 3.9079964e-01, 2.3971808e-03, 2.9462752e-01,
        5.0416842e-02, 9.9110492e-02],
       [9.8263170e-04, 8.8398613e-02, 1.8625444e-01, 9.5395967e-03,
        9.0432251e-03, 2.3371369e-01, 1.2641944e-01, 1.4430849e-03,
        3.4388170e-01, 3.2363419e-04],
       [6.4851524e-09, 3.2255646e-11, 2.5369729e-06, 1.6917944e-06,
        5.9076854e-08, 7.4873256e-08, 1.7704859e-12, 9.9978036e-01,
        6.2854570e-09, 2.1519247e-04]], dtype=float32))

Original test data.
Correctly classified: 3473
Incorrectly classified: 6527
Test accuracy: 0.00%
