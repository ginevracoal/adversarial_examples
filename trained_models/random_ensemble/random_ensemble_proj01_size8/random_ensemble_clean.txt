
Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 28, 28, 1)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 12, 12, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 9216)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               1179776   
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1290      
=================================================================
Total params: 1,199,882
Trainable params: 1,199,882
Non-trainable params: 0
_________________________________________________________________

GaussianRandomProjector seed =  123

Computing random projections.
Input shape:  (60000, 28, 28, 1)
Output shape: (10, 60000, 8, 8, 1) -> 10 random projections of 60000 images whose shape is (8, 8, 1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 8, 8, 1)           0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 6, 6, 32)          320       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 64)          18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               32896     
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 10)                1290      
=================================================================
Total params: 53,002
Trainable params: 53,002
Non-trainable params: 0
_________________________________________________________________

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 3s 6ms/step - loss: 0.8375 - acc: 0.7317
Epoch 2/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4818 - acc: 0.8496
Epoch 3/12

469/468 [==============================] - 2s 5ms/step - loss: 0.4043 - acc: 0.8761
Epoch 4/12

469/468 [==============================] - 2s 5ms/step - loss: 0.3618 - acc: 0.8879
Epoch 5/12

469/468 [==============================] - 3s 6ms/step - loss: 0.3345 - acc: 0.8962
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.3210 - acc: 0.9010
Epoch 7/12

469/468 [==============================] - 3s 7ms/step - loss: 0.3025 - acc: 0.9054
Epoch 8/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2834 - acc: 0.9119
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2784 - acc: 0.9128
Epoch 10/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2715 - acc: 0.9155
Epoch 11/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2632 - acc: 0.9174
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2495 - acc: 0.9228

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2468 - acc: 0.9224
Epoch 2/12

469/468 [==============================] - 4s 9ms/step - loss: 0.2416 - acc: 0.9246
Epoch 3/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2347 - acc: 0.9253
Epoch 4/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2377 - acc: 0.9254
Epoch 5/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2296 - acc: 0.9290
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2284 - acc: 0.9279
Epoch 7/12

469/468 [==============================] - 4s 10ms/step - loss: 0.2201 - acc: 0.9312
Epoch 8/12

469/468 [==============================] - 3s 7ms/step - loss: 0.2189 - acc: 0.9308
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2151 - acc: 0.9326
Epoch 10/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2118 - acc: 0.9337
Epoch 11/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2128 - acc: 0.9337
Epoch 12/12

469/468 [==============================] - 3s 7ms/step - loss: 0.2028 - acc: 0.9347

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 3s 7ms/step - loss: 0.2052 - acc: 0.9351
Epoch 2/12

469/468 [==============================] - 4s 8ms/step - loss: 0.2024 - acc: 0.9354
Epoch 3/12

469/468 [==============================] - 5s 10ms/step - loss: 0.2002 - acc: 0.9373
Epoch 4/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1939 - acc: 0.9388
Epoch 5/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1938 - acc: 0.9389
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1881 - acc: 0.9406
Epoch 7/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1932 - acc: 0.9390
Epoch 8/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1926 - acc: 0.9387
Epoch 9/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1914 - acc: 0.9398
Epoch 10/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1860 - acc: 0.9402
Epoch 11/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1862 - acc: 0.9414
Epoch 12/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1887 - acc: 0.9406

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1822 - acc: 0.9424
Epoch 2/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1764 - acc: 0.9444
Epoch 3/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1768 - acc: 0.9441
Epoch 4/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1800 - acc: 0.9436
Epoch 5/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1826 - acc: 0.9423
Epoch 6/12

469/468 [==============================] - 4s 7ms/step - loss: 0.1765 - acc: 0.9432
Epoch 7/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1783 - acc: 0.9435
Epoch 8/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1786 - acc: 0.9432
Epoch 9/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1773 - acc: 0.9440
Epoch 10/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1729 - acc: 0.9450
Epoch 11/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1660 - acc: 0.9472
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1702 - acc: 0.9446

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1700 - acc: 0.9457
Epoch 2/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1682 - acc: 0.9460
Epoch 3/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1707 - acc: 0.9456
Epoch 4/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1685 - acc: 0.9462
Epoch 5/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1640 - acc: 0.9478
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1676 - acc: 0.9476
Epoch 7/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1639 - acc: 0.9485
Epoch 8/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1646 - acc: 0.9468
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1647 - acc: 0.9472
Epoch 10/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1701 - acc: 0.9463
Epoch 11/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1660 - acc: 0.9475
Epoch 12/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1639 - acc: 0.9477

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1627 - acc: 0.9496
Epoch 2/12

469/468 [==============================] - 4s 7ms/step - loss: 0.1594 - acc: 0.9499
Epoch 3/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1640 - acc: 0.9472
Epoch 4/12

469/468 [==============================] - 4s 7ms/step - loss: 0.1647 - acc: 0.9473
Epoch 5/12

469/468 [==============================] - 4s 7ms/step - loss: 0.1601 - acc: 0.9498
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1590 - acc: 0.9490
Epoch 7/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1595 - acc: 0.9495
Epoch 8/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1641 - acc: 0.9477
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1627 - acc: 0.9490
Epoch 10/12

469/468 [==============================] - 4s 7ms/step - loss: 0.1603 - acc: 0.9489
Epoch 11/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1576 - acc: 0.9492
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1583 - acc: 0.9499

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1613 - acc: 0.9495
Epoch 2/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1532 - acc: 0.9505
Epoch 3/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1588 - acc: 0.9490
Epoch 4/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1575 - acc: 0.9495
Epoch 5/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1576 - acc: 0.9502
Epoch 6/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1573 - acc: 0.9500
Epoch 7/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1646 - acc: 0.9491
Epoch 8/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1643 - acc: 0.9480
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1536 - acc: 0.9517
Epoch 10/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1544 - acc: 0.9505
Epoch 11/12

469/468 [==============================] - 3s 6ms/step - loss: 0.1533 - acc: 0.9511
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1580 - acc: 0.9499

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1527 - acc: 0.9510
Epoch 2/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1552 - acc: 0.9510
Epoch 3/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1527 - acc: 0.9508
Epoch 4/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1561 - acc: 0.9495
Epoch 5/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1600 - acc: 0.9485
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1542 - acc: 0.9509
Epoch 7/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1578 - acc: 0.9505
Epoch 8/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1543 - acc: 0.9510
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1549 - acc: 0.9514
Epoch 10/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1545 - acc: 0.9514
Epoch 11/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1535 - acc: 0.9513
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1555 - acc: 0.9503

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1512 - acc: 0.9529
Epoch 2/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1499 - acc: 0.9517
Epoch 3/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1530 - acc: 0.9515
Epoch 4/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1525 - acc: 0.9515
Epoch 5/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1522 - acc: 0.9514
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1532 - acc: 0.9519
Epoch 7/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1489 - acc: 0.9528
Epoch 8/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1521 - acc: 0.9519
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1494 - acc: 0.9516
Epoch 10/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1531 - acc: 0.9514
Epoch 11/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1514 - acc: 0.9516
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1557 - acc: 0.9508

Training infos:
batch_size =  128 
epochs = 12 
x_train.shape =  (60000, 8, 8, 1) 
y_train.shape =  (60000, 10) 

Epoch 1/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1536 - acc: 0.9517
Epoch 2/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1493 - acc: 0.9527
Epoch 3/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1525 - acc: 0.9519
Epoch 4/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1519 - acc: 0.9516
Epoch 5/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1541 - acc: 0.9507
Epoch 6/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1543 - acc: 0.9517
Epoch 7/12

469/468 [==============================] - 4s 9ms/step - loss: 0.1511 - acc: 0.9516
Epoch 8/12

469/468 [==============================] - 5s 10ms/step - loss: 0.1505 - acc: 0.9530
Epoch 9/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1509 - acc: 0.9526
Epoch 10/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1520 - acc: 0.9525
Epoch 11/12

469/468 [==============================] - 3s 7ms/step - loss: 0.1492 - acc: 0.9523
Epoch 12/12

469/468 [==============================] - 4s 8ms/step - loss: 0.1502 - acc: 0.9524

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 


Computing random projections.
Input shape:  (10000, 28, 28, 1)
Output shape: (10, 10000, 8, 8, 1) -> 10 random projections of 10000 images whose shape is (8, 8, 1)

Original test data.
Correctly classified: 9416
Incorrectly classified: 584
Test accuracy: 94.16%
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 8, 8, 1)           0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 6, 6, 32)          320       
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 4, 4, 64)          18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 64)          0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 128)               32896     
_________________________________________________________________
dropout_6 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 10)                1290      
=================================================================
Total params: 53,002
Trainable params: 53,002
Non-trainable params: 0
_________________________________________________________________

Computing random projections.
Input shape:  (10000, 28, 28, 1)
Output shape: (10, 10000, 8, 8, 1) -> 10 random projections of 10000 images whose shape is (8, 8, 1)

Adversarial test data:
Correctly classified: 4213
Incorrectly classified: 5787
Adversarial accuracy: 42.13%
