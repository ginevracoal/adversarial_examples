
Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  6 , size_proj =  8 ) ===

Loading time: --- 8.142409086227417 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)
Correctly classified: 9660
Incorrectly classified: 340
Test accuracy: 96.60%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.97      0.96      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.96      0.97      0.96       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.96      0.96      0.96      1028
           8       0.95      0.96      0.96       974
           9       0.96      0.94      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.89      0.90       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.95      1028
           8       0.90      0.92      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9365
Incorrectly classified: 635
Test accuracy: 93.65%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.94       982
           5       0.91      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.90      0.92      0.91       974
           9       0.93      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9383
Incorrectly classified: 617
Test accuracy: 93.83%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.99      0.99      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.93       982
           5       0.91      0.91      0.91       892
           6       0.97      0.95      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.90      0.92      0.91       974
           9       0.94      0.90      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9362
Incorrectly classified: 638
Test accuracy: 93.62%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.93      0.92      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.91      0.91      0.91       892
           6       0.96      0.95      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.88      0.93      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.91      0.93      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.91      0.91       892
           6       0.97      0.94      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.90      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9376
Incorrectly classified: 624
Test accuracy: 93.76%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.94      0.89      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.95      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 2874
Incorrectly classified: 7126
Adversarial accuracy: 28.74%
              precision    recall  f1-score   support

           0       0.70      0.46      0.56       980
           1       0.33      0.00      0.00      1135
           2       0.51      0.50      0.51      1032
           3       0.31      0.42      0.36      1010
           4       0.18      0.11      0.14       982
           5       0.32      0.33      0.32       892
           6       0.61      0.29      0.39       958
           7       0.37      0.09      0.14      1028
           8       0.15      0.64      0.25       974
           9       0.12      0.07      0.09      1009

   micro avg       0.29      0.29      0.29     10000
   macro avg       0.36      0.29      0.28     10000
weighted avg       0.36      0.29      0.27     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2436
Incorrectly classified: 7564
Test accuracy: 24.36%
              precision    recall  f1-score   support

           0       0.43      0.30      0.35       980
           1       0.60      0.01      0.02      1135
           2       0.38      0.45      0.41      1032
           3       0.23      0.51      0.32      1010
           4       0.11      0.06      0.08       982
           5       0.15      0.08      0.11       892
           6       0.34      0.24      0.28       958
           7       0.42      0.08      0.13      1028
           8       0.18      0.50      0.26       974
           9       0.18      0.21      0.19      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.30      0.25      0.22     10000
weighted avg       0.31      0.24      0.21     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2311
Incorrectly classified: 7689
Test accuracy: 23.11%
              precision    recall  f1-score   support

           0       0.52      0.31      0.39       980
           1       0.12      0.00      0.00      1135
           2       0.39      0.43      0.41      1032
           3       0.22      0.28      0.25      1010
           4       0.21      0.12      0.15       982
           5       0.26      0.21      0.24       892
           6       0.41      0.31      0.36       958
           7       0.40      0.07      0.12      1028
           8       0.13      0.49      0.20       974
           9       0.12      0.11      0.11      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.28      0.23      0.22     10000
weighted avg       0.28      0.23      0.22     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2158
Incorrectly classified: 7842
Test accuracy: 21.58%
              precision    recall  f1-score   support

           0       0.79      0.20      0.32       980
           1       0.16      0.00      0.01      1135
           2       0.35      0.34      0.34      1032
           3       0.19      0.27      0.22      1010
           4       0.19      0.15      0.17       982
           5       0.27      0.29      0.28       892
           6       0.49      0.21      0.29       958
           7       0.23      0.02      0.03      1028
           8       0.14      0.65      0.23       974
           9       0.19      0.09      0.12      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.30      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.44      0.33      0.38       980
           1       0.56      0.08      0.14      1135
           2       0.29      0.37      0.33      1032
           3       0.23      0.22      0.22      1010
           4       0.21      0.15      0.18       982
           5       0.15      0.26      0.19       892
           6       0.35      0.29      0.32       958
           7       0.36      0.22      0.27      1028
           8       0.15      0.39      0.22       974
           9       0.20      0.13      0.16      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.24     10000
weighted avg       0.30      0.24      0.24     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.46      0.39      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.34      0.43      0.38      1032
           3       0.24      0.27      0.26      1010
           4       0.21      0.20      0.20       982
           5       0.17      0.35      0.23       892
           6       0.38      0.22      0.27       958
           7       0.26      0.10      0.14      1028
           8       0.18      0.42      0.25       974
           9       0.14      0.10      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.24      0.25      0.23     10000
weighted avg       0.23      0.24      0.22     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2385
Incorrectly classified: 7615
Test accuracy: 23.85%
              precision    recall  f1-score   support

           0       0.37      0.36      0.37       980
           1       0.17      0.00      0.00      1135
           2       0.53      0.34      0.42      1032
           3       0.27      0.44      0.33      1010
           4       0.15      0.10      0.12       982
           5       0.22      0.41      0.29       892
           6       0.33      0.07      0.12       958
           7       0.17      0.19      0.18      1028
           8       0.16      0.37      0.22       974
           9       0.20      0.15      0.17      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.22     10000
weighted avg       0.26      0.24      0.22     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 6338
Incorrectly classified: 3662
Adversarial accuracy: 63.38%
              precision    recall  f1-score   support

           0       0.88      0.81      0.84       980
           1       0.96      0.18      0.31      1135
           2       0.64      0.74      0.69      1032
           3       0.57      0.77      0.65      1010
           4       0.62      0.63      0.63       982
           5       0.60      0.69      0.64       892
           6       0.88      0.73      0.80       958
           7       0.80      0.58      0.68      1028
           8       0.42      0.83      0.56       974
           9       0.56      0.45      0.50      1009

   micro avg       0.63      0.63      0.63     10000
   macro avg       0.69      0.64      0.63     10000
weighted avg       0.70      0.63      0.62     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4815
Incorrectly classified: 5185
Test accuracy: 48.15%
              precision    recall  f1-score   support

           0       0.73      0.65      0.69       980
           1       0.90      0.19      0.32      1135
           2       0.55      0.52      0.54      1032
           3       0.47      0.68      0.56      1010
           4       0.50      0.37      0.43       982
           5       0.54      0.35      0.42       892
           6       0.67      0.52      0.58       958
           7       0.75      0.32      0.45      1028
           8       0.28      0.81      0.42       974
           9       0.38      0.44      0.41      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.48     10000
weighted avg       0.58      0.48      0.48     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4918
Incorrectly classified: 5082
Test accuracy: 49.18%
              precision    recall  f1-score   support

           0       0.87      0.62      0.72       980
           1       0.97      0.11      0.20      1135
           2       0.53      0.70      0.60      1032
           3       0.42      0.68      0.52      1010
           4       0.64      0.32      0.43       982
           5       0.39      0.58      0.47       892
           6       0.79      0.66      0.72       958
           7       0.76      0.17      0.28      1028
           8       0.31      0.65      0.42       974
           9       0.40      0.50      0.45      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4812
Incorrectly classified: 5188
Test accuracy: 48.12%
              precision    recall  f1-score   support

           0       0.93      0.45      0.61       980
           1       0.90      0.10      0.18      1135
           2       0.49      0.70      0.58      1032
           3       0.44      0.52      0.47      1010
           4       0.44      0.70      0.54       982
           5       0.38      0.57      0.46       892
           6       0.72      0.57      0.63       958
           7       0.79      0.35      0.49      1028
           8       0.33      0.73      0.46       974
           9       0.42      0.19      0.26      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.47     10000
weighted avg       0.59      0.48      0.46     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5678
Incorrectly classified: 4322
Test accuracy: 56.78%
              precision    recall  f1-score   support

           0       0.81      0.71      0.76       980
           1       0.90      0.52      0.66      1135
           2       0.56      0.54      0.55      1032
           3       0.47      0.59      0.52      1010
           4       0.54      0.50      0.52       982
           5       0.46      0.56      0.50       892
           6       0.78      0.69      0.73       958
           7       0.80      0.49      0.61      1028
           8       0.38      0.69      0.49       974
           9       0.42      0.40      0.41      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.58     10000
weighted avg       0.62      0.57      0.58     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4922
Incorrectly classified: 5078
Test accuracy: 49.22%
              precision    recall  f1-score   support

           0       0.73      0.73      0.73       980
           1       0.88      0.07      0.14      1135
           2       0.44      0.63      0.52      1032
           3       0.41      0.67      0.51      1010
           4       0.50      0.33      0.40       982
           5       0.42      0.55      0.47       892
           6       0.71      0.60      0.65       958
           7       0.66      0.41      0.51      1028
           8       0.33      0.63      0.43       974
           9       0.55      0.36      0.44      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.56      0.50      0.48     10000
weighted avg       0.57      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4608
Incorrectly classified: 5392
Test accuracy: 46.08%
              precision    recall  f1-score   support

           0       0.67      0.60      0.64       980
           1       0.89      0.12      0.22      1135
           2       0.68      0.44      0.53      1032
           3       0.46      0.54      0.50      1010
           4       0.45      0.55      0.50       982
           5       0.37      0.54      0.44       892
           6       0.66      0.31      0.42       958
           7       0.36      0.77      0.49      1028
           8       0.42      0.51      0.46       974
           9       0.35      0.27      0.30      1009

   micro avg       0.46      0.46      0.46     10000
   macro avg       0.53      0.47      0.45     10000
weighted avg       0.54      0.46      0.45     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9365
Incorrectly classified: 635
Adversarial accuracy: 93.65%
              precision    recall  f1-score   support

           0       0.95      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.94      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.91      0.94      0.93       982
           5       0.94      0.88      0.91       892
           6       0.96      0.95      0.95       958
           7       0.94      0.94      0.94      1028
           8       0.90      0.92      0.91       974
           9       0.91      0.90      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8818
Incorrectly classified: 1182
Test accuracy: 88.18%
              precision    recall  f1-score   support

           0       0.92      0.93      0.93       980
           1       0.97      0.97      0.97      1135
           2       0.89      0.89      0.89      1032
           3       0.85      0.86      0.86      1010
           4       0.85      0.87      0.86       982
           5       0.84      0.79      0.81       892
           6       0.91      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.82      0.85      0.83       974
           9       0.84      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8857
Incorrectly classified: 1143
Test accuracy: 88.57%
              precision    recall  f1-score   support

           0       0.94      0.94      0.94       980
           1       0.97      0.96      0.97      1135
           2       0.92      0.89      0.90      1032
           3       0.86      0.86      0.86      1010
           4       0.84      0.91      0.87       982
           5       0.85      0.84      0.84       892
           6       0.92      0.89      0.91       958
           7       0.89      0.89      0.89      1028
           8       0.82      0.87      0.84       974
           9       0.84      0.79      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8803
Incorrectly classified: 1197
Test accuracy: 88.03%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.97      0.98      0.98      1135
           2       0.88      0.89      0.88      1032
           3       0.82      0.84      0.83      1010
           4       0.84      0.87      0.86       982
           5       0.83      0.82      0.83       892
           6       0.94      0.90      0.92       958
           7       0.93      0.88      0.90      1028
           8       0.81      0.85      0.83       974
           9       0.83      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8767
Incorrectly classified: 1233
Test accuracy: 87.67%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.85      0.88      1032
           3       0.85      0.79      0.82      1010
           4       0.85      0.88      0.86       982
           5       0.81      0.82      0.81       892
           6       0.93      0.90      0.91       958
           7       0.88      0.89      0.89      1028
           8       0.83      0.84      0.84       974
           9       0.79      0.86      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8817
Incorrectly classified: 1183
Test accuracy: 88.17%
              precision    recall  f1-score   support

           0       0.92      0.94      0.93       980
           1       0.98      0.96      0.97      1135
           2       0.92      0.87      0.90      1032
           3       0.83      0.85      0.84      1010
           4       0.86      0.87      0.86       982
           5       0.85      0.80      0.83       892
           6       0.95      0.88      0.91       958
           7       0.88      0.90      0.89      1028
           8       0.81      0.87      0.84       974
           9       0.82      0.85      0.84      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8789
Incorrectly classified: 1211
Test accuracy: 87.89%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.98      0.97      0.98      1135
           2       0.90      0.91      0.91      1032
           3       0.84      0.89      0.86      1010
           4       0.80      0.88      0.84       982
           5       0.88      0.79      0.83       892
           6       0.92      0.91      0.92       958
           7       0.87      0.91      0.89      1028
           8       0.82      0.84      0.83       974
           9       0.83      0.76      0.79      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9220
Incorrectly classified: 780
Adversarial accuracy: 92.20%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.98      0.97      1135
           2       0.94      0.91      0.93      1032
           3       0.90      0.91      0.91      1010
           4       0.88      0.93      0.90       982
           5       0.90      0.90      0.90       892
           6       0.95      0.94      0.95       958
           7       0.91      0.92      0.92      1028
           8       0.92      0.90      0.91       974
           9       0.89      0.84      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8639
Incorrectly classified: 1361
Test accuracy: 86.39%
              precision    recall  f1-score   support

           0       0.89      0.92      0.91       980
           1       0.95      0.95      0.95      1135
           2       0.87      0.87      0.87      1032
           3       0.85      0.85      0.85      1010
           4       0.82      0.87      0.85       982
           5       0.80      0.81      0.81       892
           6       0.91      0.90      0.90       958
           7       0.87      0.88      0.88      1028
           8       0.82      0.82      0.82       974
           9       0.83      0.77      0.80      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8646
Incorrectly classified: 1354
Test accuracy: 86.46%
              precision    recall  f1-score   support

           0       0.94      0.93      0.94       980
           1       0.96      0.95      0.95      1135
           2       0.90      0.86      0.88      1032
           3       0.83      0.84      0.84      1010
           4       0.79      0.89      0.84       982
           5       0.81      0.86      0.84       892
           6       0.92      0.90      0.91       958
           7       0.84      0.87      0.85      1028
           8       0.83      0.85      0.84       974
           9       0.82      0.69      0.75      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.86      0.86     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8605
Incorrectly classified: 1395
Test accuracy: 86.05%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.96      1135
           2       0.85      0.86      0.85      1032
           3       0.80      0.82      0.81      1010
           4       0.80      0.87      0.83       982
           5       0.80      0.86      0.83       892
           6       0.94      0.90      0.92       958
           7       0.89      0.88      0.88      1028
           8       0.82      0.79      0.81       974
           9       0.82      0.73      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8566
Incorrectly classified: 1434
Test accuracy: 85.66%
              precision    recall  f1-score   support

           0       0.94      0.92      0.93       980
           1       0.96      0.94      0.95      1135
           2       0.90      0.79      0.84      1032
           3       0.84      0.79      0.81      1010
           4       0.81      0.86      0.84       982
           5       0.78      0.85      0.81       892
           6       0.91      0.90      0.91       958
           7       0.85      0.89      0.87      1028
           8       0.81      0.82      0.81       974
           9       0.77      0.80      0.78      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8620
Incorrectly classified: 1380
Test accuracy: 86.20%
              precision    recall  f1-score   support

           0       0.92      0.91      0.91       980
           1       0.96      0.95      0.96      1135
           2       0.91      0.84      0.87      1032
           3       0.82      0.86      0.84      1010
           4       0.81      0.86      0.83       982
           5       0.80      0.83      0.81       892
           6       0.94      0.85      0.89       958
           7       0.86      0.90      0.88      1028
           8       0.82      0.84      0.83       974
           9       0.79      0.76      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8545
Incorrectly classified: 1455
Test accuracy: 85.45%
              precision    recall  f1-score   support

           0       0.92      0.89      0.91       980
           1       0.96      0.96      0.96      1135
           2       0.87      0.89      0.88      1032
           3       0.82      0.86      0.84      1010
           4       0.77      0.85      0.81       982
           5       0.83      0.80      0.82       892
           6       0.90      0.90      0.90       958
           7       0.83      0.87      0.85      1028
           8       0.83      0.79      0.81       974
           9       0.80      0.70      0.75      1009

   micro avg       0.85      0.85      0.85     10000
   macro avg       0.85      0.85      0.85     10000
weighted avg       0.85      0.85      0.85     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  6 , size_proj =  12 ) ===

Loading time: --- 9.500893115997314 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)
Correctly classified: 9773
Incorrectly classified: 227
Test accuracy: 97.73%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9627
Incorrectly classified: 373
Test accuracy: 96.27%
              precision    recall  f1-score   support

           0       0.96      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.96      0.96      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.96      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.96      0.95       974
           9       0.96      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9644
Incorrectly classified: 356
Test accuracy: 96.44%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.97      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.97      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9633
Incorrectly classified: 367
Test accuracy: 96.33%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.96      0.97      0.97       982
           5       0.95      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.95      0.95      0.95       974
           9       0.95      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9601
Incorrectly classified: 399
Test accuracy: 96.01%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.95      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.94      0.96      0.95       892
           6       0.97      0.98      0.97       958
           7       0.96      0.95      0.96      1028
           8       0.95      0.94      0.94       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9615
Incorrectly classified: 385
Test accuracy: 96.15%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.95      0.96      0.96       982
           5       0.96      0.94      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.94      0.96      1028
           8       0.93      0.97      0.95       974
           9       0.95      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9640
Incorrectly classified: 360
Test accuracy: 96.40%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.96      1032
           3       0.95      0.96      0.96      1010
           4       0.97      0.95      0.96       982
           5       0.96      0.96      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.95      0.96       974
           9       0.96      0.95      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 3007
Incorrectly classified: 6993
Adversarial accuracy: 30.07%
              precision    recall  f1-score   support

           0       0.68      0.46      0.55       980
           1       0.00      0.00      0.00      1135
           2       0.53      0.61      0.57      1032
           3       0.35      0.44      0.39      1010
           4       0.20      0.11      0.14       982
           5       0.32      0.31      0.31       892
           6       0.56      0.35      0.43       958
           7       0.55      0.07      0.12      1028
           8       0.15      0.64      0.24       974
           9       0.13      0.07      0.09      1009

   micro avg       0.30      0.30      0.30     10000
   macro avg       0.34      0.31      0.28     10000
weighted avg       0.34      0.30      0.28     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2574
Incorrectly classified: 7426
Test accuracy: 25.74%
              precision    recall  f1-score   support

           0       0.48      0.33      0.39       980
           1       0.18      0.01      0.01      1135
           2       0.34      0.56      0.42      1032
           3       0.25      0.43      0.32      1010
           4       0.20      0.12      0.15       982
           5       0.31      0.25      0.27       892
           6       0.37      0.25      0.30       958
           7       0.55      0.17      0.26      1028
           8       0.14      0.33      0.20       974
           9       0.12      0.17      0.14      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.25     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2743
Incorrectly classified: 7257
Test accuracy: 27.43%
              precision    recall  f1-score   support

           0       0.59      0.29      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.60      0.50      1032
           3       0.33      0.41      0.37      1010
           4       0.22      0.12      0.16       982
           5       0.32      0.30      0.31       892
           6       0.38      0.18      0.25       958
           7       0.35      0.06      0.10      1028
           8       0.17      0.65      0.27       974
           9       0.17      0.16      0.16      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.29      0.28      0.25     10000
weighted avg       0.29      0.27      0.25     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2795
Incorrectly classified: 7205
Test accuracy: 27.95%
              precision    recall  f1-score   support

           0       0.55      0.48      0.51       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.38      0.45      1032
           3       0.25      0.18      0.21      1010
           4       0.26      0.18      0.21       982
           5       0.24      0.39      0.29       892
           6       0.54      0.31      0.39       958
           7       0.53      0.15      0.23      1028
           8       0.16      0.63      0.26       974
           9       0.20      0.15      0.17      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.33      0.29      0.27     10000
weighted avg       0.32      0.28      0.27     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2357
Incorrectly classified: 7643
Test accuracy: 23.57%
              precision    recall  f1-score   support

           0       0.58      0.36      0.44       980
           1       0.04      0.00      0.00      1135
           2       0.32      0.43      0.37      1032
           3       0.22      0.31      0.26      1010
           4       0.24      0.09      0.13       982
           5       0.19      0.27      0.22       892
           6       0.45      0.29      0.35       958
           7       0.41      0.08      0.13      1028
           8       0.13      0.45      0.20       974
           9       0.19      0.13      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.23     10000
weighted avg       0.27      0.24      0.22     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2582
Incorrectly classified: 7418
Test accuracy: 25.82%
              precision    recall  f1-score   support

           0       0.58      0.32      0.41       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.48      0.45      1032
           3       0.39      0.30      0.34      1010
           4       0.20      0.14      0.16       982
           5       0.22      0.31      0.26       892
           6       0.36      0.45      0.40       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.53      0.22       974
           9       0.10      0.05      0.06      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2413
Incorrectly classified: 7587
Test accuracy: 24.13%
              precision    recall  f1-score   support

           0       0.46      0.35      0.39       980
           1       0.29      0.00      0.00      1135
           2       0.44      0.47      0.46      1032
           3       0.25      0.51      0.33      1010
           4       0.15      0.13      0.14       982
           5       0.25      0.22      0.23       892
           6       0.52      0.22      0.31       958
           7       0.31      0.05      0.09      1028
           8       0.13      0.43      0.20       974
           9       0.11      0.06      0.08      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.22     10000
weighted avg       0.29      0.24      0.22     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 6137
Incorrectly classified: 3863
Adversarial accuracy: 61.37%
              precision    recall  f1-score   support

           0       0.89      0.83      0.86       980
           1       0.89      0.14      0.24      1135
           2       0.58      0.86      0.69      1032
           3       0.66      0.71      0.68      1010
           4       0.56      0.59      0.57       982
           5       0.62      0.64      0.63       892
           6       0.85      0.77      0.81       958
           7       0.88      0.54      0.67      1028
           8       0.36      0.81      0.50       974
           9       0.49      0.33      0.40      1009

   micro avg       0.61      0.61      0.61     10000
   macro avg       0.68      0.62      0.61     10000
weighted avg       0.68      0.61      0.60     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5698
Incorrectly classified: 4302
Test accuracy: 56.98%
              precision    recall  f1-score   support

           0       0.74      0.84      0.79       980
           1       0.91      0.19      0.31      1135
           2       0.55      0.81      0.65      1032
           3       0.53      0.60      0.56      1010
           4       0.53      0.36      0.43       982
           5       0.54      0.50      0.52       892
           6       0.73      0.68      0.71       958
           7       0.78      0.59      0.67      1028
           8       0.43      0.66      0.52       974
           9       0.40      0.52      0.45      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.56     10000
weighted avg       0.62      0.57      0.56     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5208
Incorrectly classified: 4792
Test accuracy: 52.08%
              precision    recall  f1-score   support

           0       0.83      0.75      0.79       980
           1       0.90      0.05      0.09      1135
           2       0.41      0.86      0.56      1032
           3       0.53      0.66      0.59      1010
           4       0.72      0.25      0.37       982
           5       0.52      0.64      0.58       892
           6       0.86      0.56      0.68       958
           7       0.76      0.33      0.47      1028
           8       0.31      0.74      0.44       974
           9       0.51      0.45      0.48      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.64      0.53      0.50     10000
weighted avg       0.64      0.52      0.50     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5925
Incorrectly classified: 4075
Test accuracy: 59.25%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.95      0.40      0.56      1135
           2       0.56      0.72      0.63      1032
           3       0.78      0.37      0.50      1010
           4       0.48      0.69      0.57       982
           5       0.44      0.71      0.54       892
           6       0.72      0.79      0.75       958
           7       0.83      0.61      0.70      1028
           8       0.44      0.72      0.55       974
           9       0.39      0.27      0.32      1009

   micro avg       0.59      0.59      0.59     10000
   macro avg       0.65      0.60      0.59     10000
weighted avg       0.65      0.59      0.59     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5253
Incorrectly classified: 4747
Test accuracy: 52.53%
              precision    recall  f1-score   support

           0       0.92      0.63      0.75       980
           1       0.85      0.24      0.37      1135
           2       0.49      0.74      0.59      1032
           3       0.54      0.57      0.55      1010
           4       0.54      0.57      0.56       982
           5       0.48      0.37      0.42       892
           6       0.75      0.67      0.71       958
           7       0.80      0.41      0.54      1028
           8       0.31      0.78      0.44       974
           9       0.39      0.31      0.35      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.53     10000
weighted avg       0.61      0.53      0.53     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4883
Incorrectly classified: 5117
Test accuracy: 48.83%
              precision    recall  f1-score   support

           0       0.90      0.66      0.76       980
           1       0.86      0.10      0.19      1135
           2       0.53      0.71      0.61      1032
           3       0.51      0.52      0.51      1010
           4       0.49      0.45      0.47       982
           5       0.44      0.50      0.47       892
           6       0.83      0.62      0.71       958
           7       0.84      0.35      0.49      1028
           8       0.25      0.80      0.39       974
           9       0.40      0.24      0.31      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.49     10000
weighted avg       0.61      0.49      0.48     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5136
Incorrectly classified: 4864
Test accuracy: 51.36%
              precision    recall  f1-score   support

           0       0.80      0.63      0.70       980
           1       0.91      0.18      0.30      1135
           2       0.51      0.66      0.58      1032
           3       0.42      0.84      0.56      1010
           4       0.45      0.64      0.52       982
           5       0.57      0.51      0.54       892
           6       0.77      0.63      0.69       958
           7       0.81      0.30      0.44      1028
           8       0.34      0.61      0.44       974
           9       0.35      0.19      0.25      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.59      0.52      0.50     10000
weighted avg       0.60      0.51      0.50     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9559
Incorrectly classified: 441
Adversarial accuracy: 95.59%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.96      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.95      0.95      0.95       982
           5       0.96      0.93      0.95       892
           6       0.96      0.97      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.94      0.95      0.94       974
           9       0.94      0.93      0.93      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9264
Incorrectly classified: 736
Test accuracy: 92.64%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.91      0.91      1010
           4       0.92      0.91      0.92       982
           5       0.92      0.88      0.90       892
           6       0.94      0.94      0.94       958
           7       0.96      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.89      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.96      0.97      1135
           2       0.92      0.94      0.93      1032
           3       0.87      0.92      0.90      1010
           4       0.93      0.91      0.92       982
           5       0.94      0.88      0.91       892
           6       0.94      0.94      0.94       958
           7       0.93      0.92      0.92      1028
           8       0.86      0.91      0.88       974
           9       0.89      0.88      0.89      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9235
Incorrectly classified: 765
Test accuracy: 92.35%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.93      0.94      1032
           3       0.92      0.88      0.90      1010
           4       0.87      0.94      0.91       982
           5       0.90      0.90      0.90       892
           6       0.95      0.94      0.95       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.89      0.85      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9206
Incorrectly classified: 794
Test accuracy: 92.06%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.87      0.88      1010
           4       0.91      0.92      0.92       982
           5       0.88      0.91      0.89       892
           6       0.93      0.96      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.89      0.89      0.89       974
           9       0.89      0.87      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9192
Incorrectly classified: 808
Test accuracy: 91.92%
              precision    recall  f1-score   support

           0       0.95      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.90      0.90      0.90      1010
           4       0.90      0.90      0.90       982
           5       0.91      0.86      0.89       892
           6       0.94      0.94      0.94       958
           7       0.95      0.91      0.92      1028
           8       0.85      0.94      0.89       974
           9       0.87      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9230
Incorrectly classified: 770
Test accuracy: 92.30%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.89      0.91      0.90      1010
           4       0.90      0.91      0.90       982
           5       0.93      0.87      0.90       892
           6       0.93      0.96      0.94       958
           7       0.95      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9419
Incorrectly classified: 581
Adversarial accuracy: 94.19%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.94      0.94      0.94      1010
           4       0.91      0.94      0.92       982
           5       0.93      0.94      0.93       892
           6       0.95      0.97      0.96       958
           7       0.94      0.93      0.94      1028
           8       0.94      0.92      0.93       974
           9       0.92      0.88      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9108
Incorrectly classified: 892
Test accuracy: 91.08%
              precision    recall  f1-score   support

           0       0.93      0.96      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.92      0.91      1032
           3       0.90      0.88      0.89      1010
           4       0.87      0.91      0.89       982
           5       0.87      0.91      0.89       892
           6       0.94      0.94      0.94       958
           7       0.93      0.90      0.92      1028
           8       0.90      0.89      0.89       974
           9       0.88      0.83      0.85      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9065
Incorrectly classified: 935
Test accuracy: 90.65%
              precision    recall  f1-score   support

           0       0.95      0.94      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.89      0.92      0.91      1032
           3       0.86      0.90      0.88      1010
           4       0.89      0.91      0.90       982
           5       0.89      0.90      0.90       892
           6       0.94      0.94      0.94       958
           7       0.90      0.91      0.90      1028
           8       0.87      0.88      0.87       974
           9       0.89      0.80      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9051
Incorrectly classified: 949
Test accuracy: 90.51%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.94      0.91      0.92      1032
           3       0.90      0.88      0.89      1010
           4       0.83      0.92      0.88       982
           5       0.86      0.90      0.88       892
           6       0.94      0.93      0.94       958
           7       0.92      0.92      0.92      1028
           8       0.90      0.87      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.91      0.91      0.90     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8988
Incorrectly classified: 1012
Test accuracy: 89.88%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.91      0.90      1032
           3       0.89      0.85      0.87      1010
           4       0.87      0.90      0.88       982
           5       0.82      0.91      0.86       892
           6       0.92      0.96      0.94       958
           7       0.90      0.91      0.91      1028
           8       0.90      0.84      0.87       974
           9       0.86      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9010
Incorrectly classified: 990
Test accuracy: 90.10%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.90      0.91      1032
           3       0.88      0.89      0.88      1010
           4       0.85      0.88      0.86       982
           5       0.87      0.88      0.88       892
           6       0.94      0.93      0.93       958
           7       0.92      0.90      0.91      1028
           8       0.86      0.91      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9027
Incorrectly classified: 973
Test accuracy: 90.27%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.90      0.90      0.90      1032
           3       0.87      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.90      0.89      0.90       892
           6       0.91      0.96      0.93       958
           7       0.92      0.89      0.90      1028
           8       0.90      0.87      0.89       974
           9       0.86      0.78      0.82      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  6 , size_proj =  16 ) ===

Loading time: --- 9.865964889526367 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)
Correctly classified: 9792
Incorrectly classified: 208
Test accuracy: 97.92%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.97      0.97      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9706
Incorrectly classified: 294
Test accuracy: 97.06%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.96      0.98      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9713
Incorrectly classified: 287
Test accuracy: 97.13%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.96      0.98      0.97       958
           7       0.99      0.97      0.98      1028
           8       0.96      0.96      0.96       974
           9       0.96      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.96      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.97      1028
           8       0.96      0.95      0.96       974
           9       0.95      0.96      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9708
Incorrectly classified: 292
Test accuracy: 97.08%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.97      0.98      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.95      0.95       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 2814
Incorrectly classified: 7186
Adversarial accuracy: 28.14%
              precision    recall  f1-score   support

           0       0.66      0.32      0.43       980
           1       0.00      0.00      0.00      1135
           2       0.47      0.57      0.52      1032
           3       0.31      0.40      0.35      1010
           4       0.20      0.10      0.13       982
           5       0.34      0.34      0.34       892
           6       0.53      0.35      0.43       958
           7       0.50      0.04      0.08      1028
           8       0.14      0.59      0.23       974
           9       0.17      0.15      0.16      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.33      0.29      0.27     10000
weighted avg       0.33      0.28      0.26     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2635
Incorrectly classified: 7365
Test accuracy: 26.35%
              precision    recall  f1-score   support

           0       0.58      0.33      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.61      0.42      1032
           3       0.24      0.32      0.28      1010
           4       0.23      0.15      0.19       982
           5       0.31      0.34      0.32       892
           6       0.35      0.35      0.35       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.35      0.20       974
           9       0.16      0.16      0.16      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.27      0.25     10000
weighted avg       0.28      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2529
Incorrectly classified: 7471
Test accuracy: 25.29%
              precision    recall  f1-score   support

           0       0.61      0.24      0.35       980
           1       0.09      0.00      0.00      1135
           2       0.47      0.47      0.47      1032
           3       0.35      0.27      0.31      1010
           4       0.22      0.13      0.17       982
           5       0.29      0.28      0.28       892
           6       0.43      0.34      0.38       958
           7       0.25      0.01      0.02      1028
           8       0.14      0.57      0.22       974
           9       0.18      0.25      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2731
Incorrectly classified: 7269
Test accuracy: 27.31%
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       980
           1       0.11      0.00      0.00      1135
           2       0.56      0.21      0.31      1032
           3       0.24      0.31      0.27      1010
           4       0.37      0.22      0.27       982
           5       0.25      0.40      0.31       892
           6       0.45      0.25      0.32       958
           7       0.43      0.05      0.09      1028
           8       0.16      0.61      0.25       974
           9       0.30      0.34      0.32      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.34      0.28      0.26     10000
weighted avg       0.34      0.27      0.25     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2264
Incorrectly classified: 7736
Test accuracy: 22.64%
              precision    recall  f1-score   support

           0       0.56      0.25      0.34       980
           1       0.06      0.00      0.00      1135
           2       0.33      0.46      0.38      1032
           3       0.24      0.33      0.28      1010
           4       0.26      0.08      0.12       982
           5       0.22      0.17      0.19       892
           6       0.54      0.28      0.37       958
           7       0.34      0.06      0.11      1028
           8       0.12      0.51      0.19       974
           9       0.18      0.15      0.17      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.29      0.23      0.21     10000
weighted avg       0.28      0.23      0.21     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2685
Incorrectly classified: 7315
Test accuracy: 26.85%
              precision    recall  f1-score   support

           0       0.70      0.24      0.35       980
           1       1.00      0.00      0.00      1135
           2       0.44      0.57      0.50      1032
           3       0.33      0.37      0.35      1010
           4       0.22      0.15      0.18       982
           5       0.32      0.31      0.32       892
           6       0.48      0.34      0.40       958
           7       0.57      0.09      0.15      1028
           8       0.14      0.56      0.22       974
           9       0.12      0.10      0.11      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.43      0.27      0.26     10000
weighted avg       0.44      0.27      0.25     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2505
Incorrectly classified: 7495
Test accuracy: 25.05%
              precision    recall  f1-score   support

           0       0.57      0.21      0.31       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.59      0.42      1032
           3       0.24      0.51      0.33      1010
           4       0.16      0.10      0.12       982
           5       0.21      0.36      0.27       892
           6       0.48      0.27      0.34       958
           7       0.47      0.08      0.13      1028
           8       0.15      0.35      0.21       974
           9       0.15      0.08      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.28      0.25      0.22     10000
weighted avg       0.27      0.25      0.22     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 5840
Incorrectly classified: 4160
Adversarial accuracy: 58.40%
              precision    recall  f1-score   support

           0       0.89      0.80      0.84       980
           1       0.74      0.05      0.09      1135
           2       0.55      0.83      0.66      1032
           3       0.53      0.76      0.63      1010
           4       0.58      0.49      0.53       982
           5       0.61      0.69      0.65       892
           6       0.86      0.73      0.79       958
           7       0.87      0.43      0.57      1028
           8       0.36      0.76      0.49       974
           9       0.47      0.39      0.43      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.65      0.59      0.57     10000
weighted avg       0.65      0.58      0.56     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5283
Incorrectly classified: 4717
Test accuracy: 52.83%
              precision    recall  f1-score   support

           0       0.84      0.76      0.80       980
           1       0.87      0.06      0.11      1135
           2       0.41      0.87      0.56      1032
           3       0.42      0.62      0.50      1010
           4       0.52      0.45      0.48       982
           5       0.56      0.64      0.60       892
           6       0.75      0.74      0.75       958
           7       0.82      0.38      0.52      1028
           8       0.41      0.56      0.48       974
           9       0.39      0.28      0.32      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.54      0.51     10000
weighted avg       0.60      0.53      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5296
Incorrectly classified: 4704
Test accuracy: 52.96%
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       980
           1       0.85      0.11      0.19      1135
           2       0.56      0.80      0.66      1032
           3       0.58      0.58      0.58      1010
           4       0.59      0.28      0.38       982
           5       0.49      0.68      0.57       892
           6       0.89      0.64      0.74       958
           7       0.82      0.21      0.34      1028
           8       0.28      0.80      0.41       974
           9       0.46      0.44      0.45      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.64      0.54      0.52     10000
weighted avg       0.64      0.53      0.51     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5666
Incorrectly classified: 4334
Test accuracy: 56.66%
              precision    recall  f1-score   support

           0       0.88      0.77      0.82       980
           1       0.86      0.11      0.20      1135
           2       0.65      0.65      0.65      1032
           3       0.64      0.57      0.60      1010
           4       0.50      0.72      0.59       982
           5       0.49      0.75      0.59       892
           6       0.80      0.74      0.77       958
           7       0.85      0.43      0.57      1028
           8       0.35      0.80      0.48       974
           9       0.37      0.24      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.64      0.57      0.55     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5431
Incorrectly classified: 4569
Test accuracy: 54.31%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.89      0.32      0.47      1135
           2       0.52      0.64      0.58      1032
           3       0.43      0.72      0.54      1010
           4       0.64      0.26      0.37       982
           5       0.55      0.47      0.51       892
           6       0.82      0.61      0.70       958
           7       0.72      0.45      0.55      1028
           8       0.35      0.72      0.47       974
           9       0.42      0.56      0.48      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.54      0.54     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4878
Incorrectly classified: 5122
Test accuracy: 48.78%
              precision    recall  f1-score   support

           0       0.91      0.61      0.73       980
           1       0.83      0.03      0.06      1135
           2       0.54      0.71      0.61      1032
           3       0.46      0.60      0.52      1010
           4       0.49      0.39      0.43       982
           5       0.46      0.64      0.54       892
           6       0.83      0.57      0.67       958
           7       0.83      0.30      0.44      1028
           8       0.28      0.75      0.40       974
           9       0.40      0.37      0.38      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4936
Incorrectly classified: 5064
Test accuracy: 49.36%
              precision    recall  f1-score   support

           0       0.88      0.48      0.62       980
           1       0.79      0.05      0.10      1135
           2       0.40      0.72      0.51      1032
           3       0.34      0.87      0.49      1010
           4       0.54      0.46      0.50       982
           5       0.50      0.54      0.52       892
           6       0.81      0.67      0.73       958
           7       0.77      0.39      0.52      1028
           8       0.42      0.45      0.43       974
           9       0.46      0.37      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.59      0.50      0.48     10000
weighted avg       0.59      0.49      0.48     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9615
Incorrectly classified: 385
Adversarial accuracy: 96.15%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.95      0.96      1010
           4       0.95      0.96      0.95       982
           5       0.96      0.95      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9393
Incorrectly classified: 607
Test accuracy: 93.93%
              precision    recall  f1-score   support

           0       0.98      0.96      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.93      0.92      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.90      0.92      0.91       892
           6       0.95      0.96      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.92      0.93      0.92       974
           9       0.92      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9415
Incorrectly classified: 585
Test accuracy: 94.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.93      0.91      0.92      1010
           4       0.93      0.94      0.94       982
           5       0.92      0.93      0.92       892
           6       0.94      0.97      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9407
Incorrectly classified: 593
Test accuracy: 94.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.95      0.96      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.91      0.94      0.93       892
           6       0.93      0.97      0.95       958
           7       0.94      0.95      0.95      1028
           8       0.92      0.91      0.92       974
           9       0.93      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9347
Incorrectly classified: 653
Test accuracy: 93.47%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.91      0.92      0.91      1010
           4       0.95      0.91      0.93       982
           5       0.93      0.89      0.91       892
           6       0.95      0.97      0.96       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.91      0.91       974
           9       0.88      0.92      0.90      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9384
Incorrectly classified: 616
Test accuracy: 93.84%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.92      0.93       982
           5       0.94      0.89      0.91       892
           6       0.96      0.95      0.96       958
           7       0.94      0.95      0.95      1028
           8       0.89      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9363
Incorrectly classified: 637
Test accuracy: 93.63%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.97      0.98      1135
           2       0.92      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.95      0.93       982
           5       0.94      0.90      0.92       892
           6       0.95      0.95      0.95       958
           7       0.96      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9460
Incorrectly classified: 540
Adversarial accuracy: 94.60%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.94      0.94      0.94      1010
           4       0.91      0.95      0.93       982
           5       0.93      0.96      0.94       892
           6       0.95      0.97      0.96       958
           7       0.95      0.94      0.94      1028
           8       0.96      0.92      0.94       974
           9       0.93      0.87      0.90      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9217
Incorrectly classified: 783
Test accuracy: 92.17%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.90      0.91      1010
           4       0.86      0.94      0.89       982
           5       0.86      0.94      0.90       892
           6       0.94      0.95      0.94       958
           7       0.94      0.92      0.93      1028
           8       0.94      0.89      0.91       974
           9       0.89      0.82      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.89      0.89      1010
           4       0.88      0.93      0.90       982
           5       0.88      0.92      0.90       892
           6       0.93      0.96      0.95       958
           7       0.93      0.92      0.93      1028
           8       0.91      0.90      0.91       974
           9       0.91      0.83      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.89      0.90      1010
           4       0.86      0.94      0.90       982
           5       0.87      0.95      0.90       892
           6       0.93      0.96      0.94       958
           7       0.92      0.93      0.93      1028
           8       0.93      0.89      0.91       974
           9       0.90      0.81      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.90      0.91      0.90      1010
           4       0.91      0.92      0.92       982
           5       0.90      0.91      0.90       892
           6       0.94      0.96      0.95       958
           7       0.92      0.90      0.91      1028
           8       0.91      0.86      0.89       974
           9       0.88      0.88      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9211
Incorrectly classified: 789
Test accuracy: 92.11%
              precision    recall  f1-score   support

           0       0.97      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.92      0.92      1032
           3       0.89      0.93      0.91      1010
           4       0.87      0.91      0.89       982
           5       0.91      0.92      0.91       892
           6       0.95      0.94      0.95       958
           7       0.91      0.94      0.93      1028
           8       0.90      0.90      0.90       974
           9       0.89      0.82      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.95      0.96      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.90      0.94      0.92      1032
           3       0.89      0.91      0.90      1010
           4       0.84      0.95      0.89       982
           5       0.91      0.92      0.92       892
           6       0.94      0.95      0.95       958
           7       0.94      0.91      0.92      1028
           8       0.92      0.86      0.89       974
           9       0.92      0.81      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  6 , size_proj =  20 ) ===

Loading time: --- 9.625228643417358 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)
Correctly classified: 9830
Incorrectly classified: 170
Test accuracy: 98.30%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.99      0.99      0.99       958
           7       0.98      0.97      0.98      1028
           8       0.97      0.98      0.98       974
           9       0.98      0.97      0.98      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9748
Incorrectly classified: 252
Test accuracy: 97.48%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9773
Incorrectly classified: 227
Test accuracy: 97.73%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.98       892
           6       0.99      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9749
Incorrectly classified: 251
Test accuracy: 97.49%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.97      0.99      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.98      0.95      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9768
Incorrectly classified: 232
Test accuracy: 97.68%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.96      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9758
Incorrectly classified: 242
Test accuracy: 97.58%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.96      0.96      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 2475
Incorrectly classified: 7525
Adversarial accuracy: 24.75%
              precision    recall  f1-score   support

           0       0.67      0.31      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.53      0.47      0.50      1032
           3       0.32      0.39      0.35      1010
           4       0.17      0.10      0.13       982
           5       0.35      0.20      0.26       892
           6       0.58      0.23      0.33       958
           7       0.54      0.03      0.06      1028
           8       0.13      0.72      0.22       974
           9       0.10      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.34      0.25      0.23     10000
weighted avg       0.33      0.25      0.23     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2500
Incorrectly classified: 7500
Test accuracy: 25.00%
              precision    recall  f1-score   support

           0       0.62      0.38      0.47       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.52      0.50      1032
           3       0.26      0.43      0.32      1010
           4       0.17      0.12      0.14       982
           5       0.29      0.21      0.25       892
           6       0.48      0.23      0.31       958
           7       0.48      0.08      0.14      1028
           8       0.12      0.49      0.19       974
           9       0.09      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2132
Incorrectly classified: 7868
Test accuracy: 21.32%
              precision    recall  f1-score   support

           0       0.68      0.13      0.22       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.49      0.43      1032
           3       0.31      0.28      0.29      1010
           4       0.22      0.09      0.13       982
           5       0.27      0.10      0.15       892
           6       0.58      0.19      0.29       958
           7       0.42      0.02      0.04      1028
           8       0.12      0.74      0.21       974
           9       0.20      0.11      0.14      1009

   micro avg       0.21      0.21      0.21     10000
   macro avg       0.32      0.22      0.19     10000
weighted avg       0.31      0.21      0.19     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2351
Incorrectly classified: 7649
Test accuracy: 23.51%
              precision    recall  f1-score   support

           0       0.59      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.34      0.42      1032
           3       0.25      0.32      0.28      1010
           4       0.24      0.10      0.14       982
           5       0.25      0.23      0.24       892
           6       0.57      0.25      0.34       958
           7       0.48      0.03      0.05      1028
           8       0.14      0.73      0.24       974
           9       0.13      0.11      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.32      0.24      0.22     10000
weighted avg       0.31      0.24      0.22     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2387
Incorrectly classified: 7613
Test accuracy: 23.87%
              precision    recall  f1-score   support

           0       0.49      0.18      0.26       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.43      0.40      1032
           3       0.21      0.37      0.27      1010
           4       0.19      0.13      0.16       982
           5       0.24      0.21      0.23       892
           6       0.55      0.34      0.42       958
           7       0.35      0.14      0.20      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.14      0.14      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.27      0.24      0.23     10000
weighted avg       0.26      0.24      0.23     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2452
Incorrectly classified: 7548
Test accuracy: 24.52%
              precision    recall  f1-score   support

           0       0.66      0.35      0.46       980
           1       0.00      0.00      0.00      1135
           2       0.55      0.43      0.48      1032
           3       0.32      0.34      0.33      1010
           4       0.24      0.24      0.24       982
           5       0.32      0.22      0.26       892
           6       0.42      0.23      0.29       958
           7       0.57      0.05      0.09      1028
           8       0.13      0.60      0.21       974
           9       0.04      0.03      0.04      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.24     10000
weighted avg       0.32      0.25      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2166
Incorrectly classified: 7834
Test accuracy: 21.66%
              precision    recall  f1-score   support

           0       0.57      0.19      0.28       980
           1       0.00      0.00      0.00      1135
           2       0.44      0.41      0.42      1032
           3       0.28      0.39      0.33      1010
           4       0.14      0.08      0.10       982
           5       0.25      0.21      0.23       892
           6       0.58      0.12      0.19       958
           7       0.46      0.05      0.09      1028
           8       0.11      0.58      0.19       974
           9       0.24      0.18      0.20      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.31      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 5575
Incorrectly classified: 4425
Adversarial accuracy: 55.75%
              precision    recall  f1-score   support

           0       0.89      0.81      0.85       980
           1       0.82      0.09      0.16      1135
           2       0.59      0.78      0.68      1032
           3       0.55      0.81      0.66      1010
           4       0.49      0.54      0.52       982
           5       0.67      0.48      0.56       892
           6       0.87      0.64      0.74       958
           7       0.81      0.40      0.53      1028
           8       0.32      0.84      0.47       974
           9       0.36      0.25      0.30      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.64      0.56      0.55     10000
weighted avg       0.64      0.56      0.54     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5187
Incorrectly classified: 4813
Test accuracy: 51.87%
              precision    recall  f1-score   support

           0       0.85      0.80      0.83       980
           1       0.80      0.04      0.07      1135
           2       0.51      0.83      0.63      1032
           3       0.57      0.68      0.62      1010
           4       0.49      0.39      0.43       982
           5       0.57      0.39      0.47       892
           6       0.81      0.66      0.73       958
           7       0.75      0.36      0.48      1028
           8       0.29      0.77      0.42       974
           9       0.36      0.32      0.34      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.50     10000
weighted avg       0.60      0.52      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4908
Incorrectly classified: 5092
Test accuracy: 49.08%
              precision    recall  f1-score   support

           0       0.89      0.70      0.79       980
           1       0.81      0.07      0.12      1135
           2       0.52      0.75      0.61      1032
           3       0.53      0.67      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.63      0.28      0.39       892
           6       0.86      0.62      0.72       958
           7       0.85      0.31      0.46      1028
           8       0.26      0.87      0.41       974
           9       0.32      0.24      0.28      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.62      0.49      0.48     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5655
Incorrectly classified: 4345
Test accuracy: 56.55%
              precision    recall  f1-score   support

           0       0.84      0.83      0.83       980
           1       0.93      0.19      0.32      1135
           2       0.61      0.69      0.65      1032
           3       0.58      0.66      0.62      1010
           4       0.50      0.62      0.55       982
           5       0.57      0.63      0.60       892
           6       0.81      0.66      0.73       958
           7       0.78      0.42      0.54      1028
           8       0.34      0.77      0.48       974
           9       0.34      0.25      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.63      0.57      0.56     10000
weighted avg       0.63      0.57      0.56     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5180
Incorrectly classified: 4820
Test accuracy: 51.80%
              precision    recall  f1-score   support

           0       0.88      0.57      0.69       980
           1       0.82      0.13      0.23      1135
           2       0.46      0.64      0.53      1032
           3       0.43      0.86      0.57      1010
           4       0.49      0.44      0.47       982
           5       0.59      0.37      0.46       892
           6       0.85      0.59      0.69       958
           7       0.69      0.60      0.64      1028
           8       0.35      0.74      0.47       974
           9       0.43      0.27      0.33      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.51     10000
weighted avg       0.60      0.52      0.51     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5235
Incorrectly classified: 4765
Test accuracy: 52.35%
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       980
           1       0.89      0.24      0.37      1135
           2       0.62      0.67      0.64      1032
           3       0.45      0.73      0.56      1010
           4       0.46      0.62      0.53       982
           5       0.55      0.46      0.50       892
           6       0.84      0.47      0.61       958
           7       0.78      0.29      0.42      1028
           8       0.30      0.76      0.43       974
           9       0.37      0.24      0.29      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.61      0.53      0.52     10000
weighted avg       0.62      0.52      0.52     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5036
Incorrectly classified: 4964
Test accuracy: 50.36%
              precision    recall  f1-score   support

           0       0.88      0.54      0.67       980
           1       0.88      0.18      0.30      1135
           2       0.57      0.69      0.62      1032
           3       0.47      0.80      0.59      1010
           4       0.46      0.51      0.48       982
           5       0.49      0.53      0.51       892
           6       0.86      0.48      0.62       958
           7       0.71      0.19      0.30      1028
           8       0.33      0.81      0.47       974
           9       0.38      0.37      0.38      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.60      0.51      0.49     10000
weighted avg       0.61      0.50      0.49     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9644
Incorrectly classified: 356
Adversarial accuracy: 96.44%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.95      0.97      0.96      1010
           4       0.95      0.96      0.96       982
           5       0.98      0.93      0.96       892
           6       0.97      0.98      0.97       958
           7       0.98      0.95      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.94      0.95      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9478
Incorrectly classified: 522
Test accuracy: 94.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.94      0.94      0.94       982
           5       0.94      0.92      0.93       892
           6       0.95      0.96      0.96       958
           7       0.96      0.95      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.93      0.92      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9434
Incorrectly classified: 566
Test accuracy: 94.34%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.96      0.90      0.93       892
           6       0.96      0.97      0.97       958
           7       0.97      0.92      0.94      1028
           8       0.88      0.97      0.92       974
           9       0.92      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9500
Incorrectly classified: 500
Test accuracy: 95.00%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.93      0.94      0.94      1010
           4       0.94      0.94      0.94       982
           5       0.95      0.93      0.94       892
           6       0.96      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.92      0.94      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9452
Incorrectly classified: 548
Test accuracy: 94.52%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.90      0.96      0.93      1010
           4       0.92      0.95      0.94       982
           5       0.95      0.90      0.92       892
           6       0.94      0.97      0.96       958
           7       0.93      0.95      0.94      1028
           8       0.95      0.90      0.92       974
           9       0.94      0.89      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9458
Incorrectly classified: 542
Test accuracy: 94.58%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.97      0.88      0.92       892
           6       0.97      0.95      0.96       958
           7       0.97      0.93      0.95      1028
           8       0.90      0.95      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9459
Incorrectly classified: 541
Test accuracy: 94.59%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.95      1032
           3       0.92      0.95      0.93      1010
           4       0.94      0.92      0.93       982
           5       0.95      0.90      0.93       892
           6       0.97      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.93      0.94      0.94       974
           9       0.88      0.93      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9536
Incorrectly classified: 464
Adversarial accuracy: 95.36%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.96      0.96      1032
           3       0.94      0.96      0.95      1010
           4       0.92      0.95      0.94       982
           5       0.96      0.95      0.95       892
           6       0.96      0.97      0.97       958
           7       0.96      0.94      0.95      1028
           8       0.95      0.94      0.95       974
           9       0.93      0.90      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  6 random projections in  one_channel mode: 
Projected data dimensions: (6, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9290
Incorrectly classified: 710
Test accuracy: 92.90%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.97      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.93      0.92      1010
           4       0.87      0.93      0.90       982
           5       0.89      0.93      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.91      0.91       974
           9       0.92      0.84      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9289
Incorrectly classified: 711
Test accuracy: 92.89%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.84      0.95      0.89       982
           5       0.94      0.93      0.93       892
           6       0.97      0.96      0.96       958
           7       0.94      0.91      0.93      1028
           8       0.89      0.94      0.92       974
           9       0.92      0.79      0.85      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9354
Incorrectly classified: 646
Test accuracy: 93.54%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.92      0.95      0.93       892
           6       0.96      0.96      0.96       958
           7       0.95      0.91      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.89      0.87      0.88      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.94      0.93     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9256
Incorrectly classified: 744
Test accuracy: 92.56%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.89      0.94      0.91      1010
           4       0.87      0.95      0.90       982
           5       0.93      0.92      0.92       892
           6       0.94      0.97      0.95       958
           7       0.89      0.94      0.92      1028
           8       0.95      0.87      0.91       974
           9       0.93      0.79      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.92      0.92     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9294
Incorrectly classified: 706
Test accuracy: 92.94%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.84      0.95      0.89       982
           5       0.95      0.90      0.93       892
           6       0.96      0.95      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.93      0.92       974
           9       0.90      0.84      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9307
Incorrectly classified: 693
Test accuracy: 93.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.94      0.92      1010
           4       0.89      0.91      0.90       982
           5       0.94      0.92      0.93       892
           6       0.96      0.95      0.96       958
           7       0.95      0.92      0.93      1028
           8       0.93      0.91      0.92       974
           9       0.87      0.88      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  9 , size_proj =  8 ) ===

Loading time: --- 18.211692333221436 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)
Correctly classified: 9690
Incorrectly classified: 310
Test accuracy: 96.90%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.96      0.97      0.97       982
           5       0.98      0.96      0.97       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.96      0.94      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.89      0.90       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.95      1028
           8       0.90      0.92      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9365
Incorrectly classified: 635
Test accuracy: 93.65%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.94       982
           5       0.91      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.90      0.92      0.91       974
           9       0.93      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9383
Incorrectly classified: 617
Test accuracy: 93.83%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.99      0.99      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.93       982
           5       0.91      0.91      0.91       892
           6       0.97      0.95      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.90      0.92      0.91       974
           9       0.94      0.90      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9362
Incorrectly classified: 638
Test accuracy: 93.62%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.93      0.92      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.91      0.91      0.91       892
           6       0.96      0.95      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.88      0.93      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.91      0.93      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.91      0.91       892
           6       0.97      0.94      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.90      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9376
Incorrectly classified: 624
Test accuracy: 93.76%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.94      0.89      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.95      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9378
Incorrectly classified: 622
Test accuracy: 93.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.99      0.98      1135
           2       0.97      0.90      0.93      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.94      0.92      0.93       892
           6       0.94      0.95      0.94       958
           7       0.94      0.94      0.94      1028
           8       0.88      0.94      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9366
Incorrectly classified: 634
Test accuracy: 93.66%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.99      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.93      0.92       982
           5       0.93      0.90      0.92       892
           6       0.92      0.95      0.94       958
           7       0.97      0.92      0.94      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9380
Incorrectly classified: 620
Test accuracy: 93.80%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.94      0.93       982
           5       0.92      0.93      0.92       892
           6       0.94      0.96      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 3041
Incorrectly classified: 6959
Adversarial accuracy: 30.41%
              precision    recall  f1-score   support

           0       0.71      0.46      0.56       980
           1       1.00      0.00      0.00      1135
           2       0.57      0.52      0.54      1032
           3       0.38      0.43      0.41      1010
           4       0.20      0.15      0.17       982
           5       0.34      0.29      0.31       892
           6       0.59      0.33      0.43       958
           7       0.56      0.10      0.17      1028
           8       0.16      0.74      0.27       974
           9       0.12      0.07      0.09      1009

   micro avg       0.30      0.30      0.30     10000
   macro avg       0.46      0.31      0.29     10000
weighted avg       0.47      0.30      0.29     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2436
Incorrectly classified: 7564
Test accuracy: 24.36%
              precision    recall  f1-score   support

           0       0.43      0.30      0.35       980
           1       0.60      0.01      0.02      1135
           2       0.38      0.45      0.41      1032
           3       0.23      0.51      0.32      1010
           4       0.11      0.06      0.08       982
           5       0.15      0.08      0.11       892
           6       0.34      0.24      0.28       958
           7       0.42      0.08      0.13      1028
           8       0.18      0.50      0.26       974
           9       0.18      0.21      0.19      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.30      0.25      0.22     10000
weighted avg       0.31      0.24      0.21     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2311
Incorrectly classified: 7689
Test accuracy: 23.11%
              precision    recall  f1-score   support

           0       0.52      0.31      0.39       980
           1       0.12      0.00      0.00      1135
           2       0.39      0.43      0.41      1032
           3       0.22      0.28      0.25      1010
           4       0.21      0.12      0.15       982
           5       0.26      0.21      0.24       892
           6       0.41      0.31      0.36       958
           7       0.40      0.07      0.12      1028
           8       0.13      0.49      0.20       974
           9       0.12      0.11      0.11      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.28      0.23      0.22     10000
weighted avg       0.28      0.23      0.22     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2158
Incorrectly classified: 7842
Test accuracy: 21.58%
              precision    recall  f1-score   support

           0       0.79      0.20      0.32       980
           1       0.16      0.00      0.01      1135
           2       0.35      0.34      0.34      1032
           3       0.19      0.27      0.22      1010
           4       0.19      0.15      0.17       982
           5       0.27      0.29      0.28       892
           6       0.49      0.21      0.29       958
           7       0.23      0.02      0.03      1028
           8       0.14      0.65      0.23       974
           9       0.19      0.09      0.12      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.30      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.44      0.33      0.38       980
           1       0.56      0.08      0.14      1135
           2       0.29      0.37      0.33      1032
           3       0.23      0.22      0.22      1010
           4       0.21      0.15      0.18       982
           5       0.15      0.26      0.19       892
           6       0.35      0.29      0.32       958
           7       0.36      0.22      0.27      1028
           8       0.15      0.39      0.22       974
           9       0.20      0.13      0.16      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.24     10000
weighted avg       0.30      0.24      0.24     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.46      0.39      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.34      0.43      0.38      1032
           3       0.24      0.27      0.26      1010
           4       0.21      0.20      0.20       982
           5       0.17      0.35      0.23       892
           6       0.38      0.22      0.27       958
           7       0.26      0.10      0.14      1028
           8       0.18      0.42      0.25       974
           9       0.14      0.10      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.24      0.25      0.23     10000
weighted avg       0.23      0.24      0.22     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2385
Incorrectly classified: 7615
Test accuracy: 23.85%
              precision    recall  f1-score   support

           0       0.37      0.36      0.37       980
           1       0.17      0.00      0.00      1135
           2       0.53      0.34      0.42      1032
           3       0.27      0.44      0.33      1010
           4       0.15      0.10      0.12       982
           5       0.22      0.41      0.29       892
           6       0.33      0.07      0.12       958
           7       0.17      0.19      0.18      1028
           8       0.16      0.37      0.22       974
           9       0.20      0.15      0.17      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.22     10000
weighted avg       0.26      0.24      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2508
Incorrectly classified: 7492
Test accuracy: 25.08%
              precision    recall  f1-score   support

           0       0.52      0.26      0.34       980
           1       0.13      0.00      0.00      1135
           2       0.44      0.29      0.35      1032
           3       0.28      0.27      0.27      1010
           4       0.20      0.30      0.24       982
           5       0.27      0.11      0.16       892
           6       0.43      0.21      0.29       958
           7       0.50      0.22      0.31      1028
           8       0.16      0.63      0.26       974
           9       0.18      0.23      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2535
Incorrectly classified: 7465
Test accuracy: 25.35%
              precision    recall  f1-score   support

           0       0.50      0.26      0.34       980
           1       0.11      0.00      0.00      1135
           2       0.40      0.30      0.35      1032
           3       0.36      0.36      0.36      1010
           4       0.19      0.27      0.22       982
           5       0.29      0.19      0.23       892
           6       0.37      0.32      0.35       958
           7       0.62      0.10      0.17      1028
           8       0.18      0.64      0.28       974
           9       0.10      0.13      0.11      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.26      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2458
Incorrectly classified: 7542
Test accuracy: 24.58%
              precision    recall  f1-score   support

           0       0.46      0.33      0.38       980
           1       0.50      0.01      0.02      1135
           2       0.31      0.52      0.39      1032
           3       0.33      0.23      0.27      1010
           4       0.25      0.08      0.12       982
           5       0.17      0.31      0.22       892
           6       0.28      0.40      0.33       958
           7       0.52      0.09      0.15      1028
           8       0.15      0.47      0.23       974
           9       0.25      0.06      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.22     10000
weighted avg       0.33      0.25      0.22     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 6258
Incorrectly classified: 3742
Adversarial accuracy: 62.58%
              precision    recall  f1-score   support

           0       0.88      0.84      0.86       980
           1       0.93      0.10      0.19      1135
           2       0.66      0.77      0.71      1032
           3       0.64      0.76      0.69      1010
           4       0.59      0.67      0.63       982
           5       0.65      0.67      0.66       892
           6       0.89      0.70      0.78       958
           7       0.85      0.60      0.70      1028
           8       0.36      0.87      0.51       974
           9       0.55      0.36      0.44      1009

   micro avg       0.63      0.63      0.63     10000
   macro avg       0.70      0.63      0.62     10000
weighted avg       0.70      0.63      0.61     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4815
Incorrectly classified: 5185
Test accuracy: 48.15%
              precision    recall  f1-score   support

           0       0.73      0.65      0.69       980
           1       0.90      0.19      0.32      1135
           2       0.55      0.52      0.54      1032
           3       0.47      0.68      0.56      1010
           4       0.50      0.37      0.43       982
           5       0.54      0.35      0.42       892
           6       0.67      0.52      0.58       958
           7       0.75      0.32      0.45      1028
           8       0.28      0.81      0.42       974
           9       0.38      0.44      0.41      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.48     10000
weighted avg       0.58      0.48      0.48     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4918
Incorrectly classified: 5082
Test accuracy: 49.18%
              precision    recall  f1-score   support

           0       0.87      0.62      0.72       980
           1       0.97      0.11      0.20      1135
           2       0.53      0.70      0.60      1032
           3       0.42      0.68      0.52      1010
           4       0.64      0.32      0.43       982
           5       0.39      0.58      0.47       892
           6       0.79      0.66      0.72       958
           7       0.76      0.17      0.28      1028
           8       0.31      0.65      0.42       974
           9       0.40      0.50      0.45      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4812
Incorrectly classified: 5188
Test accuracy: 48.12%
              precision    recall  f1-score   support

           0       0.93      0.45      0.61       980
           1       0.90      0.10      0.18      1135
           2       0.49      0.70      0.58      1032
           3       0.44      0.52      0.47      1010
           4       0.44      0.70      0.54       982
           5       0.38      0.57      0.46       892
           6       0.72      0.57      0.63       958
           7       0.79      0.35      0.49      1028
           8       0.33      0.73      0.46       974
           9       0.42      0.19      0.26      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.47     10000
weighted avg       0.59      0.48      0.46     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5678
Incorrectly classified: 4322
Test accuracy: 56.78%
              precision    recall  f1-score   support

           0       0.81      0.71      0.76       980
           1       0.90      0.52      0.66      1135
           2       0.56      0.54      0.55      1032
           3       0.47      0.59      0.52      1010
           4       0.54      0.50      0.52       982
           5       0.46      0.56      0.50       892
           6       0.78      0.69      0.73       958
           7       0.80      0.49      0.61      1028
           8       0.38      0.69      0.49       974
           9       0.42      0.40      0.41      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.58     10000
weighted avg       0.62      0.57      0.58     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4922
Incorrectly classified: 5078
Test accuracy: 49.22%
              precision    recall  f1-score   support

           0       0.73      0.73      0.73       980
           1       0.88      0.07      0.14      1135
           2       0.44      0.63      0.52      1032
           3       0.41      0.67      0.51      1010
           4       0.50      0.33      0.40       982
           5       0.42      0.55      0.47       892
           6       0.71      0.60      0.65       958
           7       0.66      0.41      0.51      1028
           8       0.33      0.63      0.43       974
           9       0.55      0.36      0.44      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.56      0.50      0.48     10000
weighted avg       0.57      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4608
Incorrectly classified: 5392
Test accuracy: 46.08%
              precision    recall  f1-score   support

           0       0.67      0.60      0.64       980
           1       0.89      0.12      0.22      1135
           2       0.68      0.44      0.53      1032
           3       0.46      0.54      0.50      1010
           4       0.45      0.55      0.50       982
           5       0.37      0.54      0.44       892
           6       0.66      0.31      0.42       958
           7       0.36      0.77      0.49      1028
           8       0.42      0.51      0.46       974
           9       0.35      0.27      0.30      1009

   micro avg       0.46      0.46      0.46     10000
   macro avg       0.53      0.47      0.45     10000
weighted avg       0.54      0.46      0.45     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5081
Incorrectly classified: 4919
Test accuracy: 50.81%
              precision    recall  f1-score   support

           0       0.73      0.66      0.69       980
           1       0.91      0.26      0.41      1135
           2       0.56      0.50      0.53      1032
           3       0.61      0.62      0.61      1010
           4       0.40      0.66      0.50       982
           5       0.66      0.17      0.27       892
           6       0.76      0.44      0.56       958
           7       0.69      0.63      0.66      1028
           8       0.29      0.77      0.42       974
           9       0.40      0.38      0.39      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.60      0.51      0.50     10000
weighted avg       0.61      0.51      0.51     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4756
Incorrectly classified: 5244
Test accuracy: 47.56%
              precision    recall  f1-score   support

           0       0.85      0.70      0.77       980
           1       0.80      0.08      0.14      1135
           2       0.57      0.56      0.57      1032
           3       0.49      0.61      0.54      1010
           4       0.43      0.55      0.49       982
           5       0.48      0.48      0.48       892
           6       0.71      0.53      0.61       958
           7       0.88      0.36      0.52      1028
           8       0.25      0.79      0.38       974
           9       0.30      0.17      0.21      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.48      0.47     10000
weighted avg       0.58      0.48      0.47     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4367
Incorrectly classified: 5633
Test accuracy: 43.67%
              precision    recall  f1-score   support

           0       0.72      0.67      0.69       980
           1       0.92      0.08      0.14      1135
           2       0.44      0.79      0.56      1032
           3       0.50      0.35      0.41      1010
           4       0.63      0.18      0.28       982
           5       0.34      0.67      0.45       892
           6       0.79      0.51      0.61       958
           7       0.84      0.27      0.41      1028
           8       0.23      0.69      0.35       974
           9       0.48      0.24      0.32      1009

   micro avg       0.44      0.44      0.44     10000
   macro avg       0.59      0.44      0.42     10000
weighted avg       0.60      0.44      0.42     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9411
Incorrectly classified: 589
Adversarial accuracy: 94.11%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.94      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.92      0.95      0.93       982
           5       0.94      0.90      0.92       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.94      1028
           8       0.90      0.93      0.92       974
           9       0.92      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8818
Incorrectly classified: 1182
Test accuracy: 88.18%
              precision    recall  f1-score   support

           0       0.92      0.93      0.93       980
           1       0.97      0.97      0.97      1135
           2       0.89      0.89      0.89      1032
           3       0.85      0.86      0.86      1010
           4       0.85      0.87      0.86       982
           5       0.84      0.79      0.81       892
           6       0.91      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.82      0.85      0.83       974
           9       0.84      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8857
Incorrectly classified: 1143
Test accuracy: 88.57%
              precision    recall  f1-score   support

           0       0.94      0.94      0.94       980
           1       0.97      0.96      0.97      1135
           2       0.92      0.89      0.90      1032
           3       0.86      0.86      0.86      1010
           4       0.84      0.91      0.87       982
           5       0.85      0.84      0.84       892
           6       0.92      0.89      0.91       958
           7       0.89      0.89      0.89      1028
           8       0.82      0.87      0.84       974
           9       0.84      0.79      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8803
Incorrectly classified: 1197
Test accuracy: 88.03%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.97      0.98      0.98      1135
           2       0.88      0.89      0.88      1032
           3       0.82      0.84      0.83      1010
           4       0.84      0.87      0.86       982
           5       0.83      0.82      0.83       892
           6       0.94      0.90      0.92       958
           7       0.93      0.88      0.90      1028
           8       0.81      0.85      0.83       974
           9       0.83      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8767
Incorrectly classified: 1233
Test accuracy: 87.67%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.85      0.88      1032
           3       0.85      0.79      0.82      1010
           4       0.85      0.88      0.86       982
           5       0.81      0.82      0.81       892
           6       0.93      0.90      0.91       958
           7       0.88      0.89      0.89      1028
           8       0.83      0.84      0.84       974
           9       0.79      0.86      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8817
Incorrectly classified: 1183
Test accuracy: 88.17%
              precision    recall  f1-score   support

           0       0.92      0.94      0.93       980
           1       0.98      0.96      0.97      1135
           2       0.92      0.87      0.90      1032
           3       0.83      0.85      0.84      1010
           4       0.86      0.87      0.86       982
           5       0.85      0.80      0.83       892
           6       0.95      0.88      0.91       958
           7       0.88      0.90      0.89      1028
           8       0.81      0.87      0.84       974
           9       0.82      0.85      0.84      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8789
Incorrectly classified: 1211
Test accuracy: 87.89%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.98      0.97      0.98      1135
           2       0.90      0.91      0.91      1032
           3       0.84      0.89      0.86      1010
           4       0.80      0.88      0.84       982
           5       0.88      0.79      0.83       892
           6       0.92      0.91      0.92       958
           7       0.87      0.91      0.89      1028
           8       0.82      0.84      0.83       974
           9       0.83      0.76      0.79      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8823
Incorrectly classified: 1177
Test accuracy: 88.23%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.98      0.97      0.97      1135
           2       0.94      0.83      0.88      1032
           3       0.86      0.83      0.84      1010
           4       0.81      0.91      0.86       982
           5       0.86      0.84      0.85       892
           6       0.93      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.77      0.90      0.83       974
           9       0.85      0.81      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.88      0.88     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8860
Incorrectly classified: 1140
Test accuracy: 88.60%
              precision    recall  f1-score   support

           0       0.93      0.94      0.94       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.90      0.90      1032
           3       0.87      0.85      0.86      1010
           4       0.83      0.87      0.85       982
           5       0.86      0.84      0.85       892
           6       0.89      0.92      0.90       958
           7       0.94      0.86      0.90      1028
           8       0.83      0.87      0.85       974
           9       0.80      0.82      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8869
Incorrectly classified: 1131
Test accuracy: 88.69%
              precision    recall  f1-score   support

           0       0.95      0.92      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.89      0.90      1032
           3       0.86      0.85      0.86      1010
           4       0.86      0.87      0.86       982
           5       0.84      0.85      0.84       892
           6       0.89      0.92      0.90       958
           7       0.91      0.90      0.91      1028
           8       0.84      0.85      0.84       974
           9       0.83      0.83      0.83      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9317
Incorrectly classified: 683
Adversarial accuracy: 93.17%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.95      0.92      0.94      1032
           3       0.91      0.92      0.92      1010
           4       0.89      0.95      0.92       982
           5       0.91      0.91      0.91       892
           6       0.95      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.92      0.91      0.92       974
           9       0.92      0.86      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8639
Incorrectly classified: 1361
Test accuracy: 86.39%
              precision    recall  f1-score   support

           0       0.89      0.92      0.91       980
           1       0.95      0.95      0.95      1135
           2       0.87      0.87      0.87      1032
           3       0.85      0.85      0.85      1010
           4       0.82      0.87      0.85       982
           5       0.80      0.81      0.81       892
           6       0.91      0.90      0.90       958
           7       0.87      0.88      0.88      1028
           8       0.82      0.82      0.82       974
           9       0.83      0.77      0.80      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8646
Incorrectly classified: 1354
Test accuracy: 86.46%
              precision    recall  f1-score   support

           0       0.94      0.93      0.94       980
           1       0.96      0.95      0.95      1135
           2       0.90      0.86      0.88      1032
           3       0.83      0.84      0.84      1010
           4       0.79      0.89      0.84       982
           5       0.81      0.86      0.84       892
           6       0.92      0.90      0.91       958
           7       0.84      0.87      0.85      1028
           8       0.83      0.85      0.84       974
           9       0.82      0.69      0.75      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.86      0.86     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8605
Incorrectly classified: 1395
Test accuracy: 86.05%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.96      1135
           2       0.85      0.86      0.85      1032
           3       0.80      0.82      0.81      1010
           4       0.80      0.87      0.83       982
           5       0.80      0.86      0.83       892
           6       0.94      0.90      0.92       958
           7       0.89      0.88      0.88      1028
           8       0.82      0.79      0.81       974
           9       0.82      0.73      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8566
Incorrectly classified: 1434
Test accuracy: 85.66%
              precision    recall  f1-score   support

           0       0.94      0.92      0.93       980
           1       0.96      0.94      0.95      1135
           2       0.90      0.79      0.84      1032
           3       0.84      0.79      0.81      1010
           4       0.81      0.86      0.84       982
           5       0.78      0.85      0.81       892
           6       0.91      0.90      0.91       958
           7       0.85      0.89      0.87      1028
           8       0.81      0.82      0.81       974
           9       0.77      0.80      0.78      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8620
Incorrectly classified: 1380
Test accuracy: 86.20%
              precision    recall  f1-score   support

           0       0.92      0.91      0.91       980
           1       0.96      0.95      0.96      1135
           2       0.91      0.84      0.87      1032
           3       0.82      0.86      0.84      1010
           4       0.81      0.86      0.83       982
           5       0.80      0.83      0.81       892
           6       0.94      0.85      0.89       958
           7       0.86      0.90      0.88      1028
           8       0.82      0.84      0.83       974
           9       0.79      0.76      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8545
Incorrectly classified: 1455
Test accuracy: 85.45%
              precision    recall  f1-score   support

           0       0.92      0.89      0.91       980
           1       0.96      0.96      0.96      1135
           2       0.87      0.89      0.88      1032
           3       0.82      0.86      0.84      1010
           4       0.77      0.85      0.81       982
           5       0.83      0.80      0.82       892
           6       0.90      0.90      0.90       958
           7       0.83      0.87      0.85      1028
           8       0.83      0.79      0.81       974
           9       0.80      0.70      0.75      1009

   micro avg       0.85      0.85      0.85     10000
   macro avg       0.85      0.85      0.85     10000
weighted avg       0.85      0.85      0.85     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8734
Incorrectly classified: 1266
Test accuracy: 87.34%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.97      1135
           2       0.92      0.81      0.87      1032
           3       0.83      0.85      0.84      1010
           4       0.80      0.91      0.85       982
           5       0.83      0.85      0.84       892
           6       0.92      0.89      0.90       958
           7       0.89      0.89      0.89      1028
           8       0.79      0.86      0.83       974
           9       0.86      0.77      0.81      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.87      0.87     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8655
Incorrectly classified: 1345
Test accuracy: 86.55%
              precision    recall  f1-score   support

           0       0.92      0.93      0.92       980
           1       0.96      0.96      0.96      1135
           2       0.90      0.86      0.88      1032
           3       0.86      0.84      0.85      1010
           4       0.79      0.87      0.83       982
           5       0.83      0.84      0.83       892
           6       0.88      0.92      0.90       958
           7       0.91      0.83      0.87      1028
           8       0.82      0.84      0.83       974
           9       0.78      0.75      0.76      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8714
Incorrectly classified: 1286
Test accuracy: 87.14%
              precision    recall  f1-score   support

           0       0.95      0.92      0.93       980
           1       0.96      0.96      0.96      1135
           2       0.88      0.85      0.87      1032
           3       0.84      0.85      0.85      1010
           4       0.82      0.86      0.84       982
           5       0.80      0.88      0.84       892
           6       0.88      0.91      0.90       958
           7       0.88      0.90      0.89      1028
           8       0.86      0.79      0.83       974
           9       0.82      0.77      0.80      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  9 , size_proj =  12 ) ===

Loading time: --- 19.182512998580933 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)
Correctly classified: 9772
Incorrectly classified: 228
Test accuracy: 97.72%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9627
Incorrectly classified: 373
Test accuracy: 96.27%
              precision    recall  f1-score   support

           0       0.96      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.96      0.96      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.96      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.96      0.95       974
           9       0.96      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9644
Incorrectly classified: 356
Test accuracy: 96.44%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.97      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.97      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9633
Incorrectly classified: 367
Test accuracy: 96.33%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.96      0.97      0.97       982
           5       0.95      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.95      0.95      0.95       974
           9       0.95      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9601
Incorrectly classified: 399
Test accuracy: 96.01%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.95      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.94      0.96      0.95       892
           6       0.97      0.98      0.97       958
           7       0.96      0.95      0.96      1028
           8       0.95      0.94      0.94       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9615
Incorrectly classified: 385
Test accuracy: 96.15%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.95      0.96      0.96       982
           5       0.96      0.94      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.94      0.96      1028
           8       0.93      0.97      0.95       974
           9       0.95      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9640
Incorrectly classified: 360
Test accuracy: 96.40%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.96      1032
           3       0.95      0.96      0.96      1010
           4       0.97      0.95      0.96       982
           5       0.96      0.96      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.95      0.96       974
           9       0.96      0.95      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9593
Incorrectly classified: 407
Test accuracy: 95.93%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.94      0.95      1032
           3       0.95      0.95      0.95      1010
           4       0.95      0.97      0.96       982
           5       0.94      0.96      0.95       892
           6       0.96      0.98      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.93      0.94      0.94       974
           9       0.97      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9600
Incorrectly classified: 400
Test accuracy: 96.00%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.93      0.96      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.97      0.95      0.96       892
           6       0.97      0.96      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.94      0.95       974
           9       0.94      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9610
Incorrectly classified: 390
Test accuracy: 96.10%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.95      1032
           3       0.97      0.94      0.96      1010
           4       0.94      0.98      0.96       982
           5       0.96      0.95      0.95       892
           6       0.96      0.98      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.91      0.96      0.94       974
           9       0.97      0.92      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 3040
Incorrectly classified: 6960
Adversarial accuracy: 30.40%
              precision    recall  f1-score   support

           0       0.69      0.45      0.54       980
           1       0.00      0.00      0.00      1135
           2       0.57      0.60      0.59      1032
           3       0.35      0.43      0.39      1010
           4       0.19      0.14      0.16       982
           5       0.34      0.30      0.32       892
           6       0.58      0.38      0.46       958
           7       0.56      0.06      0.11      1028
           8       0.16      0.70      0.26       974
           9       0.06      0.03      0.04      1009

   micro avg       0.30      0.30      0.30     10000
   macro avg       0.35      0.31      0.29     10000
weighted avg       0.35      0.30      0.28     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2574
Incorrectly classified: 7426
Test accuracy: 25.74%
              precision    recall  f1-score   support

           0       0.48      0.33      0.39       980
           1       0.18      0.01      0.01      1135
           2       0.34      0.56      0.42      1032
           3       0.25      0.43      0.32      1010
           4       0.20      0.12      0.15       982
           5       0.31      0.25      0.27       892
           6       0.37      0.25      0.30       958
           7       0.55      0.17      0.26      1028
           8       0.14      0.33      0.20       974
           9       0.12      0.17      0.14      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.25     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2743
Incorrectly classified: 7257
Test accuracy: 27.43%
              precision    recall  f1-score   support

           0       0.59      0.29      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.60      0.50      1032
           3       0.33      0.41      0.37      1010
           4       0.22      0.12      0.16       982
           5       0.32      0.30      0.31       892
           6       0.38      0.18      0.25       958
           7       0.35      0.06      0.10      1028
           8       0.17      0.65      0.27       974
           9       0.17      0.16      0.16      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.29      0.28      0.25     10000
weighted avg       0.29      0.27      0.25     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2795
Incorrectly classified: 7205
Test accuracy: 27.95%
              precision    recall  f1-score   support

           0       0.55      0.48      0.51       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.38      0.45      1032
           3       0.25      0.18      0.21      1010
           4       0.26      0.18      0.21       982
           5       0.24      0.39      0.29       892
           6       0.54      0.31      0.39       958
           7       0.53      0.15      0.23      1028
           8       0.16      0.63      0.26       974
           9       0.20      0.15      0.17      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.33      0.29      0.27     10000
weighted avg       0.32      0.28      0.27     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2357
Incorrectly classified: 7643
Test accuracy: 23.57%
              precision    recall  f1-score   support

           0       0.58      0.36      0.44       980
           1       0.04      0.00      0.00      1135
           2       0.32      0.43      0.37      1032
           3       0.22      0.31      0.26      1010
           4       0.24      0.09      0.13       982
           5       0.19      0.27      0.22       892
           6       0.45      0.29      0.35       958
           7       0.41      0.08      0.13      1028
           8       0.13      0.45      0.20       974
           9       0.19      0.13      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.23     10000
weighted avg       0.27      0.24      0.22     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2582
Incorrectly classified: 7418
Test accuracy: 25.82%
              precision    recall  f1-score   support

           0       0.58      0.32      0.41       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.48      0.45      1032
           3       0.39      0.30      0.34      1010
           4       0.20      0.14      0.16       982
           5       0.22      0.31      0.26       892
           6       0.36      0.45      0.40       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.53      0.22       974
           9       0.10      0.05      0.06      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2413
Incorrectly classified: 7587
Test accuracy: 24.13%
              precision    recall  f1-score   support

           0       0.46      0.35      0.39       980
           1       0.29      0.00      0.00      1135
           2       0.44      0.47      0.46      1032
           3       0.25      0.51      0.33      1010
           4       0.15      0.13      0.14       982
           5       0.25      0.22      0.23       892
           6       0.52      0.22      0.31       958
           7       0.31      0.05      0.09      1028
           8       0.13      0.43      0.20       974
           9       0.11      0.06      0.08      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.22     10000
weighted avg       0.29      0.24      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2367
Incorrectly classified: 7633
Test accuracy: 23.67%
              precision    recall  f1-score   support

           0       0.42      0.17      0.25       980
           1       0.00      0.00      0.00      1135
           2       0.36      0.47      0.41      1032
           3       0.22      0.52      0.31      1010
           4       0.18      0.09      0.12       982
           5       0.18      0.09      0.12       892
           6       0.64      0.29      0.40       958
           7       0.50      0.11      0.17      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.16      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.22     10000
weighted avg       0.28      0.24      0.21     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2688
Incorrectly classified: 7312
Test accuracy: 26.88%
              precision    recall  f1-score   support

           0       0.62      0.26      0.37       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.51      0.49      1032
           3       0.32      0.35      0.33      1010
           4       0.21      0.31      0.25       982
           5       0.28      0.26      0.27       892
           6       0.38      0.31      0.34       958
           7       0.46      0.06      0.11      1028
           8       0.17      0.63      0.26       974
           9       0.08      0.04      0.05      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.30      0.27      0.25     10000
weighted avg       0.30      0.27      0.24     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2494
Incorrectly classified: 7506
Test accuracy: 24.94%
              precision    recall  f1-score   support

           0       0.58      0.31      0.40       980
           1       0.20      0.00      0.00      1135
           2       0.38      0.39      0.39      1032
           3       0.23      0.12      0.16      1010
           4       0.25      0.22      0.24       982
           5       0.22      0.40      0.28       892
           6       0.36      0.42      0.39       958
           7       0.58      0.08      0.14      1028
           8       0.16      0.58      0.25       974
           9       0.09      0.04      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.23     10000
weighted avg       0.30      0.25      0.23     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 6205
Incorrectly classified: 3795
Adversarial accuracy: 62.05%
              precision    recall  f1-score   support

           0       0.89      0.86      0.88       980
           1       0.88      0.11      0.20      1135
           2       0.59      0.85      0.70      1032
           3       0.63      0.74      0.68      1010
           4       0.57      0.64      0.60       982
           5       0.66      0.64      0.65       892
           6       0.86      0.77      0.81       958
           7       0.89      0.54      0.67      1028
           8       0.37      0.83      0.51       974
           9       0.52      0.30      0.38      1009

   micro avg       0.62      0.62      0.62     10000
   macro avg       0.69      0.63      0.61     10000
weighted avg       0.69      0.62      0.60     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5698
Incorrectly classified: 4302
Test accuracy: 56.98%
              precision    recall  f1-score   support

           0       0.74      0.84      0.79       980
           1       0.91      0.19      0.31      1135
           2       0.55      0.81      0.65      1032
           3       0.53      0.60      0.56      1010
           4       0.53      0.36      0.43       982
           5       0.54      0.50      0.52       892
           6       0.73      0.68      0.71       958
           7       0.78      0.59      0.67      1028
           8       0.43      0.66      0.52       974
           9       0.40      0.52      0.45      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.56     10000
weighted avg       0.62      0.57      0.56     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5208
Incorrectly classified: 4792
Test accuracy: 52.08%
              precision    recall  f1-score   support

           0       0.83      0.75      0.79       980
           1       0.90      0.05      0.09      1135
           2       0.41      0.86      0.56      1032
           3       0.53      0.66      0.59      1010
           4       0.72      0.25      0.37       982
           5       0.52      0.64      0.58       892
           6       0.86      0.56      0.68       958
           7       0.76      0.33      0.47      1028
           8       0.31      0.74      0.44       974
           9       0.51      0.45      0.48      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.64      0.53      0.50     10000
weighted avg       0.64      0.52      0.50     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5925
Incorrectly classified: 4075
Test accuracy: 59.25%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.95      0.40      0.56      1135
           2       0.56      0.72      0.63      1032
           3       0.78      0.37      0.50      1010
           4       0.48      0.69      0.57       982
           5       0.44      0.71      0.54       892
           6       0.72      0.79      0.75       958
           7       0.83      0.61      0.70      1028
           8       0.44      0.72      0.55       974
           9       0.39      0.27      0.32      1009

   micro avg       0.59      0.59      0.59     10000
   macro avg       0.65      0.60      0.59     10000
weighted avg       0.65      0.59      0.59     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5253
Incorrectly classified: 4747
Test accuracy: 52.53%
              precision    recall  f1-score   support

           0       0.92      0.63      0.75       980
           1       0.85      0.24      0.37      1135
           2       0.49      0.74      0.59      1032
           3       0.54      0.57      0.55      1010
           4       0.54      0.57      0.56       982
           5       0.48      0.37      0.42       892
           6       0.75      0.67      0.71       958
           7       0.80      0.41      0.54      1028
           8       0.31      0.78      0.44       974
           9       0.39      0.31      0.35      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.53     10000
weighted avg       0.61      0.53      0.53     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4883
Incorrectly classified: 5117
Test accuracy: 48.83%
              precision    recall  f1-score   support

           0       0.90      0.66      0.76       980
           1       0.86      0.10      0.19      1135
           2       0.53      0.71      0.61      1032
           3       0.51      0.52      0.51      1010
           4       0.49      0.45      0.47       982
           5       0.44      0.50      0.47       892
           6       0.83      0.62      0.71       958
           7       0.84      0.35      0.49      1028
           8       0.25      0.80      0.39       974
           9       0.40      0.24      0.31      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.49     10000
weighted avg       0.61      0.49      0.48     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5136
Incorrectly classified: 4864
Test accuracy: 51.36%
              precision    recall  f1-score   support

           0       0.80      0.63      0.70       980
           1       0.91      0.18      0.30      1135
           2       0.51      0.66      0.58      1032
           3       0.42      0.84      0.56      1010
           4       0.45      0.64      0.52       982
           5       0.57      0.51      0.54       892
           6       0.77      0.63      0.69       958
           7       0.81      0.30      0.44      1028
           8       0.34      0.61      0.44       974
           9       0.35      0.19      0.25      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.59      0.52      0.50     10000
weighted avg       0.60      0.51      0.50     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4906
Incorrectly classified: 5094
Test accuracy: 49.06%
              precision    recall  f1-score   support

           0       0.78      0.80      0.79       980
           1       0.82      0.07      0.12      1135
           2       0.55      0.58      0.57      1032
           3       0.29      0.89      0.44      1010
           4       0.55      0.39      0.46       982
           5       0.54      0.31      0.39       892
           6       0.87      0.51      0.65       958
           7       0.74      0.43      0.55      1028
           8       0.39      0.58      0.47       974
           9       0.44      0.38      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.49      0.48     10000
weighted avg       0.60      0.49      0.48     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5616
Incorrectly classified: 4384
Test accuracy: 56.16%
              precision    recall  f1-score   support

           0       0.87      0.76      0.81       980
           1       0.92      0.16      0.27      1135
           2       0.48      0.81      0.60      1032
           3       0.53      0.65      0.58      1010
           4       0.48      0.73      0.58       982
           5       0.57      0.50      0.53       892
           6       0.75      0.71      0.73       958
           7       0.84      0.49      0.61      1028
           8       0.39      0.73      0.51       974
           9       0.37      0.13      0.19      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.62      0.57      0.54     10000
weighted avg       0.62      0.56      0.54     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5027
Incorrectly classified: 4973
Test accuracy: 50.27%
              precision    recall  f1-score   support

           0       0.86      0.78      0.82       980
           1       0.94      0.16      0.28      1135
           2       0.62      0.71      0.66      1032
           3       0.47      0.18      0.26      1010
           4       0.58      0.47      0.52       982
           5       0.38      0.67      0.49       892
           6       0.79      0.69      0.74       958
           7       0.87      0.29      0.43      1028
           8       0.26      0.87      0.40       974
           9       0.55      0.30      0.39      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.63      0.51      0.50     10000
weighted avg       0.64      0.50      0.49     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9568
Incorrectly classified: 432
Adversarial accuracy: 95.68%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.98      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.95      0.95      0.95       982
           5       0.97      0.94      0.95       892
           6       0.96      0.97      0.96       958
           7       0.96      0.94      0.95      1028
           8       0.94      0.95      0.94       974
           9       0.94      0.93      0.93      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9264
Incorrectly classified: 736
Test accuracy: 92.64%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.91      0.91      1010
           4       0.92      0.91      0.92       982
           5       0.92      0.88      0.90       892
           6       0.94      0.94      0.94       958
           7       0.96      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.89      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.96      0.97      1135
           2       0.92      0.94      0.93      1032
           3       0.87      0.92      0.90      1010
           4       0.93      0.91      0.92       982
           5       0.94      0.88      0.91       892
           6       0.94      0.94      0.94       958
           7       0.93      0.92      0.92      1028
           8       0.86      0.91      0.88       974
           9       0.89      0.88      0.89      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9235
Incorrectly classified: 765
Test accuracy: 92.35%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.93      0.94      1032
           3       0.92      0.88      0.90      1010
           4       0.87      0.94      0.91       982
           5       0.90      0.90      0.90       892
           6       0.95      0.94      0.95       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.89      0.85      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9206
Incorrectly classified: 794
Test accuracy: 92.06%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.87      0.88      1010
           4       0.91      0.92      0.92       982
           5       0.88      0.91      0.89       892
           6       0.93      0.96      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.89      0.89      0.89       974
           9       0.89      0.87      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9192
Incorrectly classified: 808
Test accuracy: 91.92%
              precision    recall  f1-score   support

           0       0.95      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.90      0.90      0.90      1010
           4       0.90      0.90      0.90       982
           5       0.91      0.86      0.89       892
           6       0.94      0.94      0.94       958
           7       0.95      0.91      0.92      1028
           8       0.85      0.94      0.89       974
           9       0.87      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9230
Incorrectly classified: 770
Test accuracy: 92.30%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.89      0.91      0.90      1010
           4       0.90      0.91      0.90       982
           5       0.93      0.87      0.90       892
           6       0.93      0.96      0.94       958
           7       0.95      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9215
Incorrectly classified: 785
Test accuracy: 92.15%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.91      0.93      1032
           3       0.88      0.90      0.89      1010
           4       0.90      0.93      0.91       982
           5       0.90      0.89      0.89       892
           6       0.93      0.97      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.87      0.90      0.88       974
           9       0.91      0.86      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9214
Incorrectly classified: 786
Test accuracy: 92.14%
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.98      0.97      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.88      0.92      0.90      1010
           4       0.92      0.89      0.90       982
           5       0.94      0.88      0.91       892
           6       0.94      0.93      0.93       958
           7       0.94      0.91      0.93      1028
           8       0.90      0.89      0.89       974
           9       0.86      0.89      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9161
Incorrectly classified: 839
Test accuracy: 91.61%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.93      0.92      0.92      1032
           3       0.93      0.84      0.88      1010
           4       0.86      0.95      0.90       982
           5       0.91      0.86      0.88       892
           6       0.93      0.95      0.94       958
           7       0.94      0.93      0.94      1028
           8       0.81      0.94      0.87       974
           9       0.93      0.82      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.91     10000
weighted avg       0.92      0.92      0.92     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9434
Incorrectly classified: 566
Adversarial accuracy: 94.34%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.94      0.95      1032
           3       0.94      0.94      0.94      1010
           4       0.91      0.95      0.93       982
           5       0.93      0.94      0.94       892
           6       0.95      0.96      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.94      0.93      0.93       974
           9       0.93      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9108
Incorrectly classified: 892
Test accuracy: 91.08%
              precision    recall  f1-score   support

           0       0.93      0.96      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.92      0.91      1032
           3       0.90      0.88      0.89      1010
           4       0.87      0.91      0.89       982
           5       0.87      0.91      0.89       892
           6       0.94      0.94      0.94       958
           7       0.93      0.90      0.92      1028
           8       0.90      0.89      0.89       974
           9       0.88      0.83      0.85      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9065
Incorrectly classified: 935
Test accuracy: 90.65%
              precision    recall  f1-score   support

           0       0.95      0.94      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.89      0.92      0.91      1032
           3       0.86      0.90      0.88      1010
           4       0.89      0.91      0.90       982
           5       0.89      0.90      0.90       892
           6       0.94      0.94      0.94       958
           7       0.90      0.91      0.90      1028
           8       0.87      0.88      0.87       974
           9       0.89      0.80      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9051
Incorrectly classified: 949
Test accuracy: 90.51%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.94      0.91      0.92      1032
           3       0.90      0.88      0.89      1010
           4       0.83      0.92      0.88       982
           5       0.86      0.90      0.88       892
           6       0.94      0.93      0.94       958
           7       0.92      0.92      0.92      1028
           8       0.90      0.87      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.91      0.91      0.90     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8988
Incorrectly classified: 1012
Test accuracy: 89.88%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.91      0.90      1032
           3       0.89      0.85      0.87      1010
           4       0.87      0.90      0.88       982
           5       0.82      0.91      0.86       892
           6       0.92      0.96      0.94       958
           7       0.90      0.91      0.91      1028
           8       0.90      0.84      0.87       974
           9       0.86      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9010
Incorrectly classified: 990
Test accuracy: 90.10%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.90      0.91      1032
           3       0.88      0.89      0.88      1010
           4       0.85      0.88      0.86       982
           5       0.87      0.88      0.88       892
           6       0.94      0.93      0.93       958
           7       0.92      0.90      0.91      1028
           8       0.86      0.91      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9027
Incorrectly classified: 973
Test accuracy: 90.27%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.90      0.90      0.90      1032
           3       0.87      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.90      0.89      0.90       892
           6       0.91      0.96      0.93       958
           7       0.92      0.89      0.90      1028
           8       0.90      0.87      0.89       974
           9       0.86      0.78      0.82      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9071
Incorrectly classified: 929
Test accuracy: 90.71%
              precision    recall  f1-score   support

           0       0.95      0.95      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.89      0.91      1032
           3       0.89      0.89      0.89      1010
           4       0.85      0.92      0.88       982
           5       0.87      0.92      0.89       892
           6       0.92      0.96      0.94       958
           7       0.91      0.92      0.91      1028
           8       0.88      0.88      0.88       974
           9       0.91      0.78      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9059
Incorrectly classified: 941
Test accuracy: 90.59%
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.91      0.92      1032
           3       0.86      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.91      0.89      0.90       892
           6       0.93      0.93      0.93       958
           7       0.92      0.91      0.91      1028
           8       0.92      0.84      0.88       974
           9       0.86      0.81      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.90      0.90     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9075
Incorrectly classified: 925
Test accuracy: 90.75%
              precision    recall  f1-score   support

           0       0.96      0.95      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.92      0.87      0.89      1010
           4       0.83      0.94      0.88       982
           5       0.89      0.89      0.89       892
           6       0.93      0.94      0.93       958
           7       0.92      0.93      0.93      1028
           8       0.84      0.91      0.87       974
           9       0.90      0.77      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  9 , size_proj =  16 ) ===

Loading time: --- 18.477579832077026 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)
Correctly classified: 9804
Incorrectly classified: 196
Test accuracy: 98.04%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.99      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.97      0.97      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9706
Incorrectly classified: 294
Test accuracy: 97.06%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.96      0.98      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9713
Incorrectly classified: 287
Test accuracy: 97.13%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.96      0.98      0.97       958
           7       0.99      0.97      0.98      1028
           8       0.96      0.96      0.96       974
           9       0.96      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.96      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.97      1028
           8       0.96      0.95      0.96       974
           9       0.95      0.96      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9708
Incorrectly classified: 292
Test accuracy: 97.08%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.97      0.98      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.95      0.95       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9721
Incorrectly classified: 279
Test accuracy: 97.21%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.99      0.96      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9711
Incorrectly classified: 289
Test accuracy: 97.11%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.98      0.96       892
           6       0.97      0.98      0.97       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.96      0.97      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 2820
Incorrectly classified: 7180
Adversarial accuracy: 28.20%
              precision    recall  f1-score   support

           0       0.66      0.34      0.44       980
           1       0.00      0.00      0.00      1135
           2       0.51      0.58      0.54      1032
           3       0.33      0.38      0.35      1010
           4       0.20      0.11      0.14       982
           5       0.34      0.33      0.34       892
           6       0.57      0.36      0.44       958
           7       0.51      0.04      0.08      1028
           8       0.14      0.64      0.23       974
           9       0.13      0.09      0.11      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.34      0.29      0.27     10000
weighted avg       0.33      0.28      0.26     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2635
Incorrectly classified: 7365
Test accuracy: 26.35%
              precision    recall  f1-score   support

           0       0.58      0.33      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.61      0.42      1032
           3       0.24      0.32      0.28      1010
           4       0.23      0.15      0.19       982
           5       0.31      0.34      0.32       892
           6       0.35      0.35      0.35       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.35      0.20       974
           9       0.16      0.16      0.16      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.27      0.25     10000
weighted avg       0.28      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2529
Incorrectly classified: 7471
Test accuracy: 25.29%
              precision    recall  f1-score   support

           0       0.61      0.24      0.35       980
           1       0.09      0.00      0.00      1135
           2       0.47      0.47      0.47      1032
           3       0.35      0.27      0.31      1010
           4       0.22      0.13      0.17       982
           5       0.29      0.28      0.28       892
           6       0.43      0.34      0.38       958
           7       0.25      0.01      0.02      1028
           8       0.14      0.57      0.22       974
           9       0.18      0.25      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2731
Incorrectly classified: 7269
Test accuracy: 27.31%
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       980
           1       0.11      0.00      0.00      1135
           2       0.56      0.21      0.31      1032
           3       0.24      0.31      0.27      1010
           4       0.37      0.22      0.27       982
           5       0.25      0.40      0.31       892
           6       0.45      0.25      0.32       958
           7       0.43      0.05      0.09      1028
           8       0.16      0.61      0.25       974
           9       0.30      0.34      0.32      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.34      0.28      0.26     10000
weighted avg       0.34      0.27      0.25     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2264
Incorrectly classified: 7736
Test accuracy: 22.64%
              precision    recall  f1-score   support

           0       0.56      0.25      0.34       980
           1       0.06      0.00      0.00      1135
           2       0.33      0.46      0.38      1032
           3       0.24      0.33      0.28      1010
           4       0.26      0.08      0.12       982
           5       0.22      0.17      0.19       892
           6       0.54      0.28      0.37       958
           7       0.34      0.06      0.11      1028
           8       0.12      0.51      0.19       974
           9       0.18      0.15      0.17      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.29      0.23      0.21     10000
weighted avg       0.28      0.23      0.21     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2685
Incorrectly classified: 7315
Test accuracy: 26.85%
              precision    recall  f1-score   support

           0       0.70      0.24      0.35       980
           1       1.00      0.00      0.00      1135
           2       0.44      0.57      0.50      1032
           3       0.33      0.37      0.35      1010
           4       0.22      0.15      0.18       982
           5       0.32      0.31      0.32       892
           6       0.48      0.34      0.40       958
           7       0.57      0.09      0.15      1028
           8       0.14      0.56      0.22       974
           9       0.12      0.10      0.11      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.43      0.27      0.26     10000
weighted avg       0.44      0.27      0.25     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2505
Incorrectly classified: 7495
Test accuracy: 25.05%
              precision    recall  f1-score   support

           0       0.57      0.21      0.31       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.59      0.42      1032
           3       0.24      0.51      0.33      1010
           4       0.16      0.10      0.12       982
           5       0.21      0.36      0.27       892
           6       0.48      0.27      0.34       958
           7       0.47      0.08      0.13      1028
           8       0.15      0.35      0.21       974
           9       0.15      0.08      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.28      0.25      0.22     10000
weighted avg       0.27      0.25      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2486
Incorrectly classified: 7514
Test accuracy: 24.86%
              precision    recall  f1-score   support

           0       0.58      0.29      0.38       980
           1       0.00      0.00      0.00      1135
           2       0.50      0.45      0.48      1032
           3       0.33      0.44      0.38      1010
           4       0.14      0.08      0.10       982
           5       0.39      0.24      0.29       892
           6       0.48      0.34      0.40       958
           7       0.45      0.03      0.05      1028
           8       0.13      0.62      0.22       974
           9       0.05      0.05      0.05      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2547
Incorrectly classified: 7453
Test accuracy: 25.47%
              precision    recall  f1-score   support

           0       0.59      0.27      0.37       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.53      0.44      1032
           3       0.23      0.26      0.25      1010
           4       0.20      0.15      0.17       982
           5       0.21      0.31      0.25       892
           6       0.50      0.33      0.40       958
           7       0.49      0.08      0.14      1028
           8       0.16      0.59      0.25       974
           9       0.15      0.07      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.25      0.23     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2628
Incorrectly classified: 7372
Test accuracy: 26.28%
              precision    recall  f1-score   support

           0       0.54      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.47      0.41      1032
           3       0.31      0.21      0.25      1010
           4       0.25      0.17      0.20       982
           5       0.25      0.32      0.28       892
           6       0.52      0.34      0.41       958
           7       0.54      0.18      0.27      1028
           8       0.13      0.55      0.21       974
           9       0.22      0.14      0.17      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.31      0.27      0.26     10000
weighted avg       0.31      0.26      0.26     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 5865
Incorrectly classified: 4135
Adversarial accuracy: 58.65%
              precision    recall  f1-score   support

           0       0.90      0.82      0.86       980
           1       0.80      0.05      0.10      1135
           2       0.54      0.85      0.66      1032
           3       0.53      0.74      0.62      1010
           4       0.56      0.54      0.55       982
           5       0.62      0.70      0.66       892
           6       0.86      0.75      0.80       958
           7       0.87      0.42      0.57      1028
           8       0.37      0.77      0.50       974
           9       0.48      0.31      0.38      1009

   micro avg       0.59      0.59      0.59     10000
   macro avg       0.65      0.60      0.57     10000
weighted avg       0.65      0.59      0.56     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5283
Incorrectly classified: 4717
Test accuracy: 52.83%
              precision    recall  f1-score   support

           0       0.84      0.76      0.80       980
           1       0.87      0.06      0.11      1135
           2       0.41      0.87      0.56      1032
           3       0.42      0.62      0.50      1010
           4       0.52      0.45      0.48       982
           5       0.56      0.64      0.60       892
           6       0.75      0.74      0.75       958
           7       0.82      0.38      0.52      1028
           8       0.41      0.56      0.48       974
           9       0.39      0.28      0.32      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.54      0.51     10000
weighted avg       0.60      0.53      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5296
Incorrectly classified: 4704
Test accuracy: 52.96%
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       980
           1       0.85      0.11      0.19      1135
           2       0.56      0.80      0.66      1032
           3       0.58      0.58      0.58      1010
           4       0.59      0.28      0.38       982
           5       0.49      0.68      0.57       892
           6       0.89      0.64      0.74       958
           7       0.82      0.21      0.34      1028
           8       0.28      0.80      0.41       974
           9       0.46      0.44      0.45      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.64      0.54      0.52     10000
weighted avg       0.64      0.53      0.51     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5666
Incorrectly classified: 4334
Test accuracy: 56.66%
              precision    recall  f1-score   support

           0       0.88      0.77      0.82       980
           1       0.86      0.11      0.20      1135
           2       0.65      0.65      0.65      1032
           3       0.64      0.57      0.60      1010
           4       0.50      0.72      0.59       982
           5       0.49      0.75      0.59       892
           6       0.80      0.74      0.77       958
           7       0.85      0.43      0.57      1028
           8       0.35      0.80      0.48       974
           9       0.37      0.24      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.64      0.57      0.55     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5431
Incorrectly classified: 4569
Test accuracy: 54.31%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.89      0.32      0.47      1135
           2       0.52      0.64      0.58      1032
           3       0.43      0.72      0.54      1010
           4       0.64      0.26      0.37       982
           5       0.55      0.47      0.51       892
           6       0.82      0.61      0.70       958
           7       0.72      0.45      0.55      1028
           8       0.35      0.72      0.47       974
           9       0.42      0.56      0.48      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.54      0.54     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4878
Incorrectly classified: 5122
Test accuracy: 48.78%
              precision    recall  f1-score   support

           0       0.91      0.61      0.73       980
           1       0.83      0.03      0.06      1135
           2       0.54      0.71      0.61      1032
           3       0.46      0.60      0.52      1010
           4       0.49      0.39      0.43       982
           5       0.46      0.64      0.54       892
           6       0.83      0.57      0.67       958
           7       0.83      0.30      0.44      1028
           8       0.28      0.75      0.40       974
           9       0.40      0.37      0.38      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4936
Incorrectly classified: 5064
Test accuracy: 49.36%
              precision    recall  f1-score   support

           0       0.88      0.48      0.62       980
           1       0.79      0.05      0.10      1135
           2       0.40      0.72      0.51      1032
           3       0.34      0.87      0.49      1010
           4       0.54      0.46      0.50       982
           5       0.50      0.54      0.52       892
           6       0.81      0.67      0.73       958
           7       0.77      0.39      0.52      1028
           8       0.42      0.45      0.43       974
           9       0.46      0.37      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.59      0.50      0.48     10000
weighted avg       0.59      0.49      0.48     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5256
Incorrectly classified: 4744
Test accuracy: 52.56%
              precision    recall  f1-score   support

           0       0.84      0.77      0.80       980
           1       0.87      0.07      0.14      1135
           2       0.46      0.79      0.58      1032
           3       0.48      0.76      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.55      0.54      0.55       892
           6       0.80      0.72      0.76       958
           7       0.83      0.23      0.36      1028
           8       0.38      0.74      0.50       974
           9       0.34      0.28      0.31      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.53      0.50     10000
weighted avg       0.61      0.53      0.50     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5457
Incorrectly classified: 4543
Test accuracy: 54.57%
              precision    recall  f1-score   support

           0       0.89      0.78      0.83       980
           1       0.83      0.06      0.12      1135
           2       0.49      0.80      0.61      1032
           3       0.41      0.67      0.51      1010
           4       0.49      0.59      0.53       982
           5       0.58      0.59      0.59       892
           6       0.81      0.77      0.79       958
           7       0.83      0.42      0.56      1028
           8       0.38      0.71      0.49       974
           9       0.40      0.15      0.22      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.61      0.55      0.52     10000
weighted avg       0.61      0.55      0.52     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5489
Incorrectly classified: 4511
Test accuracy: 54.89%
              precision    recall  f1-score   support

           0       0.88      0.79      0.83       980
           1       0.93      0.13      0.23      1135
           2       0.47      0.76      0.58      1032
           3       0.56      0.52      0.54      1010
           4       0.58      0.45      0.50       982
           5       0.47      0.73      0.57       892
           6       0.85      0.67      0.75       958
           7       0.86      0.46      0.60      1028
           8       0.31      0.77      0.44       974
           9       0.64      0.29      0.39      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.65      0.56      0.54     10000
weighted avg       0.66      0.55      0.54     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9637
Incorrectly classified: 363
Adversarial accuracy: 96.37%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.95      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.96      0.95      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.95      0.96      0.95       974
           9       0.95      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9393
Incorrectly classified: 607
Test accuracy: 93.93%
              precision    recall  f1-score   support

           0       0.98      0.96      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.93      0.92      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.90      0.92      0.91       892
           6       0.95      0.96      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.92      0.93      0.92       974
           9       0.92      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9415
Incorrectly classified: 585
Test accuracy: 94.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.93      0.91      0.92      1010
           4       0.93      0.94      0.94       982
           5       0.92      0.93      0.92       892
           6       0.94      0.97      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9407
Incorrectly classified: 593
Test accuracy: 94.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.95      0.96      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.91      0.94      0.93       892
           6       0.93      0.97      0.95       958
           7       0.94      0.95      0.95      1028
           8       0.92      0.91      0.92       974
           9       0.93      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9347
Incorrectly classified: 653
Test accuracy: 93.47%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.91      0.92      0.91      1010
           4       0.95      0.91      0.93       982
           5       0.93      0.89      0.91       892
           6       0.95      0.97      0.96       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.91      0.91       974
           9       0.88      0.92      0.90      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9384
Incorrectly classified: 616
Test accuracy: 93.84%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.92      0.93       982
           5       0.94      0.89      0.91       892
           6       0.96      0.95      0.96       958
           7       0.94      0.95      0.95      1028
           8       0.89      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9363
Incorrectly classified: 637
Test accuracy: 93.63%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.97      0.98      1135
           2       0.92      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.95      0.93       982
           5       0.94      0.90      0.92       892
           6       0.95      0.95      0.95       958
           7       0.96      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9382
Incorrectly classified: 618
Test accuracy: 93.82%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.92      0.94      0.93       982
           5       0.96      0.89      0.92       892
           6       0.95      0.95      0.95       958
           7       0.97      0.91      0.94      1028
           8       0.90      0.93      0.92       974
           9       0.90      0.90      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9419
Incorrectly classified: 581
Test accuracy: 94.19%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.94      0.90      0.92      1010
           4       0.94      0.94      0.94       982
           5       0.90      0.94      0.92       892
           6       0.95      0.97      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.93      0.92      0.93       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9406
Incorrectly classified: 594
Test accuracy: 94.06%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.95      0.91      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.91      0.93      0.92       892
           6       0.96      0.96      0.96       958
           7       0.94      0.95      0.94      1028
           8       0.90      0.94      0.92       974
           9       0.91      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9509
Incorrectly classified: 491
Adversarial accuracy: 95.09%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.95      0.94      0.95      1010
           4       0.92      0.95      0.94       982
           5       0.93      0.96      0.94       892
           6       0.95      0.97      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.95      0.93      0.94       974
           9       0.94      0.89      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9217
Incorrectly classified: 783
Test accuracy: 92.17%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.90      0.91      1010
           4       0.86      0.94      0.89       982
           5       0.86      0.94      0.90       892
           6       0.94      0.95      0.94       958
           7       0.94      0.92      0.93      1028
           8       0.94      0.89      0.91       974
           9       0.89      0.82      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.89      0.89      1010
           4       0.88      0.93      0.90       982
           5       0.88      0.92      0.90       892
           6       0.93      0.96      0.95       958
           7       0.93      0.92      0.93      1028
           8       0.91      0.90      0.91       974
           9       0.91      0.83      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.89      0.90      1010
           4       0.86      0.94      0.90       982
           5       0.87      0.95      0.90       892
           6       0.93      0.96      0.94       958
           7       0.92      0.93      0.93      1028
           8       0.93      0.89      0.91       974
           9       0.90      0.81      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.90      0.91      0.90      1010
           4       0.91      0.92      0.92       982
           5       0.90      0.91      0.90       892
           6       0.94      0.96      0.95       958
           7       0.92      0.90      0.91      1028
           8       0.91      0.86      0.89       974
           9       0.88      0.88      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9211
Incorrectly classified: 789
Test accuracy: 92.11%
              precision    recall  f1-score   support

           0       0.97      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.92      0.92      1032
           3       0.89      0.93      0.91      1010
           4       0.87      0.91      0.89       982
           5       0.91      0.92      0.91       892
           6       0.95      0.94      0.95       958
           7       0.91      0.94      0.93      1028
           8       0.90      0.90      0.90       974
           9       0.89      0.82      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.95      0.96      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.90      0.94      0.92      1032
           3       0.89      0.91      0.90      1010
           4       0.84      0.95      0.89       982
           5       0.91      0.92      0.92       892
           6       0.94      0.95      0.95       958
           7       0.94      0.91      0.92      1028
           8       0.92      0.86      0.89       974
           9       0.92      0.81      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9229
Incorrectly classified: 771
Test accuracy: 92.29%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.90      0.93      0.91      1032
           3       0.90      0.92      0.91      1010
           4       0.86      0.92      0.89       982
           5       0.93      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.95      0.90      0.92      1028
           8       0.92      0.91      0.92       974
           9       0.89      0.84      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9197
Incorrectly classified: 803
Test accuracy: 91.97%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.92      0.93      0.92      1032
           3       0.92      0.87      0.90      1010
           4       0.88      0.93      0.90       982
           5       0.85      0.94      0.89       892
           6       0.93      0.95      0.94       958
           7       0.93      0.92      0.93      1028
           8       0.93      0.88      0.91       974
           9       0.90      0.84      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9282
Incorrectly classified: 718
Test accuracy: 92.82%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.94      0.92      1032
           3       0.94      0.90      0.92      1010
           4       0.91      0.93      0.92       982
           5       0.89      0.94      0.91       892
           6       0.96      0.95      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.92      0.90      0.91       974
           9       0.90      0.86      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  9 , size_proj =  20 ) ===

Loading time: --- 19.39140295982361 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)
Correctly classified: 9830
Incorrectly classified: 170
Test accuracy: 98.30%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.98      0.98      1028
           8       0.98      0.98      0.98       974
           9       0.98      0.97      0.98      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9748
Incorrectly classified: 252
Test accuracy: 97.48%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9773
Incorrectly classified: 227
Test accuracy: 97.73%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.98       892
           6       0.99      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9749
Incorrectly classified: 251
Test accuracy: 97.49%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.97      0.99      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.98      0.95      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9768
Incorrectly classified: 232
Test accuracy: 97.68%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.96      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9758
Incorrectly classified: 242
Test accuracy: 97.58%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.96      0.96      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9776
Incorrectly classified: 224
Test accuracy: 97.76%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.99      0.97      0.98      1010
           4       0.98      0.99      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.98      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.95      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9764
Incorrectly classified: 236
Test accuracy: 97.64%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.97      0.97       892
           6       0.99      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9770
Incorrectly classified: 230
Test accuracy: 97.70%
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 2458
Incorrectly classified: 7542
Adversarial accuracy: 24.58%
              precision    recall  f1-score   support

           0       0.64      0.31      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.52      0.47      0.49      1032
           3       0.32      0.36      0.34      1010
           4       0.14      0.09      0.11       982
           5       0.36      0.20      0.26       892
           6       0.58      0.25      0.35       958
           7       0.59      0.05      0.08      1028
           8       0.13      0.71      0.22       974
           9       0.09      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.34      0.25      0.23     10000
weighted avg       0.33      0.25      0.23     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2500
Incorrectly classified: 7500
Test accuracy: 25.00%
              precision    recall  f1-score   support

           0       0.62      0.38      0.47       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.52      0.50      1032
           3       0.26      0.43      0.32      1010
           4       0.17      0.12      0.14       982
           5       0.29      0.21      0.25       892
           6       0.48      0.23      0.31       958
           7       0.48      0.08      0.14      1028
           8       0.12      0.49      0.19       974
           9       0.09      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2132
Incorrectly classified: 7868
Test accuracy: 21.32%
              precision    recall  f1-score   support

           0       0.68      0.13      0.22       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.49      0.43      1032
           3       0.31      0.28      0.29      1010
           4       0.22      0.09      0.13       982
           5       0.27      0.10      0.15       892
           6       0.58      0.19      0.29       958
           7       0.42      0.02      0.04      1028
           8       0.12      0.74      0.21       974
           9       0.20      0.11      0.14      1009

   micro avg       0.21      0.21      0.21     10000
   macro avg       0.32      0.22      0.19     10000
weighted avg       0.31      0.21      0.19     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2351
Incorrectly classified: 7649
Test accuracy: 23.51%
              precision    recall  f1-score   support

           0       0.59      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.34      0.42      1032
           3       0.25      0.32      0.28      1010
           4       0.24      0.10      0.14       982
           5       0.25      0.23      0.24       892
           6       0.57      0.25      0.34       958
           7       0.48      0.03      0.05      1028
           8       0.14      0.73      0.24       974
           9       0.13      0.11      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.32      0.24      0.22     10000
weighted avg       0.31      0.24      0.22     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2387
Incorrectly classified: 7613
Test accuracy: 23.87%
              precision    recall  f1-score   support

           0       0.49      0.18      0.26       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.43      0.40      1032
           3       0.21      0.37      0.27      1010
           4       0.19      0.13      0.16       982
           5       0.24      0.21      0.23       892
           6       0.55      0.34      0.42       958
           7       0.35      0.14      0.20      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.14      0.14      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.27      0.24      0.23     10000
weighted avg       0.26      0.24      0.23     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2452
Incorrectly classified: 7548
Test accuracy: 24.52%
              precision    recall  f1-score   support

           0       0.66      0.35      0.46       980
           1       0.00      0.00      0.00      1135
           2       0.55      0.43      0.48      1032
           3       0.32      0.34      0.33      1010
           4       0.24      0.24      0.24       982
           5       0.32      0.22      0.26       892
           6       0.42      0.23      0.29       958
           7       0.57      0.05      0.09      1028
           8       0.13      0.60      0.21       974
           9       0.04      0.03      0.04      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.24     10000
weighted avg       0.32      0.25      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2166
Incorrectly classified: 7834
Test accuracy: 21.66%
              precision    recall  f1-score   support

           0       0.57      0.19      0.28       980
           1       0.00      0.00      0.00      1135
           2       0.44      0.41      0.42      1032
           3       0.28      0.39      0.33      1010
           4       0.14      0.08      0.10       982
           5       0.25      0.21      0.23       892
           6       0.58      0.12      0.19       958
           7       0.46      0.05      0.09      1028
           8       0.11      0.58      0.19       974
           9       0.24      0.18      0.20      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.31      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2309
Incorrectly classified: 7691
Test accuracy: 23.09%
              precision    recall  f1-score   support

           0       0.51      0.33      0.40       980
           1       0.00      0.00      0.00      1135
           2       0.47      0.46      0.46      1032
           3       0.38      0.16      0.23      1010
           4       0.13      0.10      0.12       982
           5       0.36      0.20      0.26       892
           6       0.45      0.20      0.28       958
           7       0.48      0.09      0.15      1028
           8       0.13      0.66      0.22       974
           9       0.12      0.14      0.13      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.30      0.23      0.22     10000
weighted avg       0.30      0.23      0.22     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2184
Incorrectly classified: 7816
Test accuracy: 21.84%
              precision    recall  f1-score   support

           0       0.50      0.21      0.29       980
           1       0.00      0.00      0.00      1135
           2       0.41      0.45      0.43      1032
           3       0.25      0.25      0.25      1010
           4       0.11      0.07      0.08       982
           5       0.18      0.12      0.15       892
           6       0.53      0.29      0.38       958
           7       0.55      0.05      0.10      1028
           8       0.14      0.63      0.22       974
           9       0.13      0.14      0.13      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.28      0.22      0.20     10000
weighted avg       0.28      0.22      0.20     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2451
Incorrectly classified: 7549
Test accuracy: 24.51%
              precision    recall  f1-score   support

           0       0.57      0.34      0.42       980
           1       0.17      0.00      0.00      1135
           2       0.43      0.37      0.40      1032
           3       0.21      0.38      0.27      1010
           4       0.26      0.23      0.25       982
           5       0.30      0.28      0.29       892
           6       0.48      0.27      0.35       958
           7       0.43      0.10      0.16      1028
           8       0.13      0.47      0.20       974
           9       0.08      0.05      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 5688
Incorrectly classified: 4312
Adversarial accuracy: 56.88%
              precision    recall  f1-score   support

           0       0.89      0.83      0.86       980
           1       0.80      0.07      0.13      1135
           2       0.59      0.79      0.68      1032
           3       0.58      0.80      0.67      1010
           4       0.50      0.59      0.54       982
           5       0.70      0.49      0.58       892
           6       0.86      0.69      0.77       958
           7       0.83      0.40      0.54      1028
           8       0.33      0.85      0.48       974
           9       0.39      0.25      0.30      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.65      0.58      0.55     10000
weighted avg       0.65      0.57      0.55     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5187
Incorrectly classified: 4813
Test accuracy: 51.87%
              precision    recall  f1-score   support

           0       0.85      0.80      0.83       980
           1       0.80      0.04      0.07      1135
           2       0.51      0.83      0.63      1032
           3       0.57      0.68      0.62      1010
           4       0.49      0.39      0.43       982
           5       0.57      0.39      0.47       892
           6       0.81      0.66      0.73       958
           7       0.75      0.36      0.48      1028
           8       0.29      0.77      0.42       974
           9       0.36      0.32      0.34      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.50     10000
weighted avg       0.60      0.52      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4908
Incorrectly classified: 5092
Test accuracy: 49.08%
              precision    recall  f1-score   support

           0       0.89      0.70      0.79       980
           1       0.81      0.07      0.12      1135
           2       0.52      0.75      0.61      1032
           3       0.53      0.67      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.63      0.28      0.39       892
           6       0.86      0.62      0.72       958
           7       0.85      0.31      0.46      1028
           8       0.26      0.87      0.41       974
           9       0.32      0.24      0.28      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.62      0.49      0.48     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5655
Incorrectly classified: 4345
Test accuracy: 56.55%
              precision    recall  f1-score   support

           0       0.84      0.83      0.83       980
           1       0.93      0.19      0.32      1135
           2       0.61      0.69      0.65      1032
           3       0.58      0.66      0.62      1010
           4       0.50      0.62      0.55       982
           5       0.57      0.63      0.60       892
           6       0.81      0.66      0.73       958
           7       0.78      0.42      0.54      1028
           8       0.34      0.77      0.48       974
           9       0.34      0.25      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.63      0.57      0.56     10000
weighted avg       0.63      0.57      0.56     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5180
Incorrectly classified: 4820
Test accuracy: 51.80%
              precision    recall  f1-score   support

           0       0.88      0.57      0.69       980
           1       0.82      0.13      0.23      1135
           2       0.46      0.64      0.53      1032
           3       0.43      0.86      0.57      1010
           4       0.49      0.44      0.47       982
           5       0.59      0.37      0.46       892
           6       0.85      0.59      0.69       958
           7       0.69      0.60      0.64      1028
           8       0.35      0.74      0.47       974
           9       0.43      0.27      0.33      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.51     10000
weighted avg       0.60      0.52      0.51     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5235
Incorrectly classified: 4765
Test accuracy: 52.35%
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       980
           1       0.89      0.24      0.37      1135
           2       0.62      0.67      0.64      1032
           3       0.45      0.73      0.56      1010
           4       0.46      0.62      0.53       982
           5       0.55      0.46      0.50       892
           6       0.84      0.47      0.61       958
           7       0.78      0.29      0.42      1028
           8       0.30      0.76      0.43       974
           9       0.37      0.24      0.29      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.61      0.53      0.52     10000
weighted avg       0.62      0.52      0.52     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5036
Incorrectly classified: 4964
Test accuracy: 50.36%
              precision    recall  f1-score   support

           0       0.88      0.54      0.67       980
           1       0.88      0.18      0.30      1135
           2       0.57      0.69      0.62      1032
           3       0.47      0.80      0.59      1010
           4       0.46      0.51      0.48       982
           5       0.49      0.53      0.51       892
           6       0.86      0.48      0.62       958
           7       0.71      0.19      0.30      1028
           8       0.33      0.81      0.47       974
           9       0.38      0.37      0.38      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.60      0.51      0.49     10000
weighted avg       0.61      0.50      0.49     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5701
Incorrectly classified: 4299
Test accuracy: 57.01%
              precision    recall  f1-score   support

           0       0.84      0.85      0.85       980
           1       0.92      0.19      0.32      1135
           2       0.51      0.79      0.62      1032
           3       0.64      0.54      0.59      1010
           4       0.52      0.68      0.59       982
           5       0.61      0.49      0.54       892
           6       0.83      0.70      0.76       958
           7       0.85      0.49      0.62      1028
           8       0.34      0.80      0.47       974
           9       0.39      0.23      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.65      0.57      0.56     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5269
Incorrectly classified: 4731
Test accuracy: 52.69%
              precision    recall  f1-score   support

           0       0.87      0.77      0.82       980
           1       0.83      0.11      0.19      1135
           2       0.50      0.79      0.61      1032
           3       0.47      0.69      0.56      1010
           4       0.52      0.44      0.48       982
           5       0.60      0.38      0.47       892
           6       0.80      0.75      0.78       958
           7       0.79      0.20      0.32      1028
           8       0.34      0.78      0.47       974
           9       0.38      0.42      0.40      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.51     10000
weighted avg       0.61      0.53      0.50     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5251
Incorrectly classified: 4749
Test accuracy: 52.51%
              precision    recall  f1-score   support

           0       0.89      0.75      0.82       980
           1       0.76      0.03      0.06      1135
           2       0.62      0.53      0.58      1032
           3       0.51      0.79      0.62      1010
           4       0.48      0.63      0.54       982
           5       0.61      0.49      0.54       892
           6       0.84      0.67      0.74       958
           7       0.84      0.41      0.55      1028
           8       0.27      0.83      0.41       974
           9       0.47      0.21      0.29      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.63      0.53      0.52     10000
weighted avg       0.63      0.53      0.51     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9659
Incorrectly classified: 341
Adversarial accuracy: 96.59%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.95      0.97      0.96       982
           5       0.98      0.94      0.96       892
           6       0.97      0.98      0.98       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.94      0.94      0.94      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9478
Incorrectly classified: 522
Test accuracy: 94.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.94      0.94      0.94       982
           5       0.94      0.92      0.93       892
           6       0.95      0.96      0.96       958
           7       0.96      0.95      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.93      0.92      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9434
Incorrectly classified: 566
Test accuracy: 94.34%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.96      0.90      0.93       892
           6       0.96      0.97      0.97       958
           7       0.97      0.92      0.94      1028
           8       0.88      0.97      0.92       974
           9       0.92      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9500
Incorrectly classified: 500
Test accuracy: 95.00%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.93      0.94      0.94      1010
           4       0.94      0.94      0.94       982
           5       0.95      0.93      0.94       892
           6       0.96      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.92      0.94      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9452
Incorrectly classified: 548
Test accuracy: 94.52%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.90      0.96      0.93      1010
           4       0.92      0.95      0.94       982
           5       0.95      0.90      0.92       892
           6       0.94      0.97      0.96       958
           7       0.93      0.95      0.94      1028
           8       0.95      0.90      0.92       974
           9       0.94      0.89      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9458
Incorrectly classified: 542
Test accuracy: 94.58%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.97      0.88      0.92       892
           6       0.97      0.95      0.96       958
           7       0.97      0.93      0.95      1028
           8       0.90      0.95      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9459
Incorrectly classified: 541
Test accuracy: 94.59%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.95      1032
           3       0.92      0.95      0.93      1010
           4       0.94      0.92      0.93       982
           5       0.95      0.90      0.93       892
           6       0.97      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.93      0.94      0.94       974
           9       0.88      0.93      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9492
Incorrectly classified: 508
Test accuracy: 94.92%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.96      0.93      0.95      1010
           4       0.92      0.95      0.94       982
           5       0.96      0.91      0.94       892
           6       0.97      0.96      0.96       958
           7       0.93      0.96      0.95      1028
           8       0.92      0.96      0.94       974
           9       0.94      0.89      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9492
Incorrectly classified: 508
Test accuracy: 94.92%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.97      0.96      1032
           3       0.94      0.93      0.93      1010
           4       0.93      0.95      0.94       982
           5       0.97      0.89      0.93       892
           6       0.96      0.97      0.96       958
           7       0.96      0.95      0.96      1028
           8       0.90      0.95      0.93       974
           9       0.93      0.93      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9512
Incorrectly classified: 488
Test accuracy: 95.12%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.97      0.98      1135
           2       0.96      0.95      0.95      1032
           3       0.93      0.95      0.94      1010
           4       0.92      0.96      0.94       982
           5       0.96      0.92      0.94       892
           6       0.97      0.96      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.90      0.95      0.92       974
           9       0.95      0.91      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9556
Incorrectly classified: 444
Adversarial accuracy: 95.56%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.95      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.92      0.96      0.94       982
           5       0.96      0.95      0.95       892
           6       0.96      0.97      0.97       958
           7       0.95      0.95      0.95      1028
           8       0.95      0.95      0.95       974
           9       0.94      0.90      0.92      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  9 random projections in  one_channel mode: 
Projected data dimensions: (9, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9290
Incorrectly classified: 710
Test accuracy: 92.90%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.97      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.93      0.92      1010
           4       0.87      0.93      0.90       982
           5       0.89      0.93      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.91      0.91       974
           9       0.92      0.84      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9289
Incorrectly classified: 711
Test accuracy: 92.89%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.84      0.95      0.89       982
           5       0.94      0.93      0.93       892
           6       0.97      0.96      0.96       958
           7       0.94      0.91      0.93      1028
           8       0.89      0.94      0.92       974
           9       0.92      0.79      0.85      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9354
Incorrectly classified: 646
Test accuracy: 93.54%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.92      0.95      0.93       892
           6       0.96      0.96      0.96       958
           7       0.95      0.91      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.89      0.87      0.88      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.94      0.93     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9256
Incorrectly classified: 744
Test accuracy: 92.56%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.89      0.94      0.91      1010
           4       0.87      0.95      0.90       982
           5       0.93      0.92      0.92       892
           6       0.94      0.97      0.95       958
           7       0.89      0.94      0.92      1028
           8       0.95      0.87      0.91       974
           9       0.93      0.79      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.92      0.92     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9294
Incorrectly classified: 706
Test accuracy: 92.94%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.84      0.95      0.89       982
           5       0.95      0.90      0.93       892
           6       0.96      0.95      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.93      0.92       974
           9       0.90      0.84      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9307
Incorrectly classified: 693
Test accuracy: 93.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.94      0.92      1010
           4       0.89      0.91      0.90       982
           5       0.94      0.92      0.93       892
           6       0.96      0.95      0.96       958
           7       0.95      0.92      0.93      1028
           8       0.93      0.91      0.92       974
           9       0.87      0.88      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9315
Incorrectly classified: 685
Test accuracy: 93.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.94      0.93      1032
           3       0.94      0.92      0.93      1010
           4       0.87      0.94      0.90       982
           5       0.93      0.92      0.92       892
           6       0.95      0.95      0.95       958
           7       0.91      0.95      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.92      0.81      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9350
Incorrectly classified: 650
Test accuracy: 93.50%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.95      0.94      1032
           3       0.94      0.93      0.93      1010
           4       0.88      0.94      0.91       982
           5       0.95      0.93      0.94       892
           6       0.95      0.96      0.96       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.92      0.91       974
           9       0.91      0.86      0.89      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.94      0.93     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9334
Incorrectly classified: 666
Test accuracy: 93.34%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.91      0.94      0.93      1010
           4       0.87      0.96      0.91       982
           5       0.92      0.94      0.93       892
           6       0.96      0.95      0.96       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.93      0.92       974
           9       0.93      0.81      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  12 , size_proj =  8 ) ===

Loading time: --- 30.06746482849121 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)
Correctly classified: 9703
Incorrectly classified: 297
Test accuracy: 97.03%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.96      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.95      0.97      0.96       974
           9       0.96      0.94      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.89      0.90       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.95      1028
           8       0.90      0.92      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9365
Incorrectly classified: 635
Test accuracy: 93.65%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.94       982
           5       0.91      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.90      0.92      0.91       974
           9       0.93      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9383
Incorrectly classified: 617
Test accuracy: 93.83%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.99      0.99      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.93       982
           5       0.91      0.91      0.91       892
           6       0.97      0.95      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.90      0.92      0.91       974
           9       0.94      0.90      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9362
Incorrectly classified: 638
Test accuracy: 93.62%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.93      0.92      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.91      0.91      0.91       892
           6       0.96      0.95      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.88      0.93      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.91      0.93      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.91      0.91       892
           6       0.97      0.94      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.90      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9376
Incorrectly classified: 624
Test accuracy: 93.76%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.94      0.89      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.95      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9378
Incorrectly classified: 622
Test accuracy: 93.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.99      0.98      1135
           2       0.97      0.90      0.93      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.94      0.92      0.93       892
           6       0.94      0.95      0.94       958
           7       0.94      0.94      0.94      1028
           8       0.88      0.94      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9366
Incorrectly classified: 634
Test accuracy: 93.66%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.99      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.93      0.92       982
           5       0.93      0.90      0.92       892
           6       0.92      0.95      0.94       958
           7       0.97      0.92      0.94      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9380
Incorrectly classified: 620
Test accuracy: 93.80%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.94      0.93       982
           5       0.92      0.93      0.92       892
           6       0.94      0.96      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9392
Incorrectly classified: 608
Test accuracy: 93.92%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.90      0.93      1032
           3       0.91      0.95      0.93      1010
           4       0.94      0.94      0.94       982
           5       0.93      0.92      0.92       892
           6       0.96      0.95      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.91      0.92      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9387
Incorrectly classified: 613
Test accuracy: 93.87%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.95      0.93      0.94       982
           5       0.93      0.89      0.91       892
           6       0.96      0.95      0.95       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.92      0.92      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9414
Incorrectly classified: 586
Test accuracy: 94.14%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.95      0.93      1010
           4       0.94      0.93      0.94       982
           5       0.94      0.92      0.93       892
           6       0.96      0.95      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.94      0.89      0.91       974
           9       0.91      0.93      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 3093
Incorrectly classified: 6907
Adversarial accuracy: 30.93%
              precision    recall  f1-score   support

           0       0.71      0.47      0.57       980
           1       0.00      0.00      0.00      1135
           2       0.55      0.54      0.54      1032
           3       0.37      0.47      0.41      1010
           4       0.19      0.14      0.16       982
           5       0.35      0.28      0.31       892
           6       0.62      0.33      0.43       958
           7       0.60      0.13      0.21      1028
           8       0.17      0.71      0.27       974
           9       0.12      0.08      0.10      1009

   micro avg       0.31      0.31      0.31     10000
   macro avg       0.37      0.31      0.30     10000
weighted avg       0.36      0.31      0.29     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2436
Incorrectly classified: 7564
Test accuracy: 24.36%
              precision    recall  f1-score   support

           0       0.43      0.30      0.35       980
           1       0.60      0.01      0.02      1135
           2       0.38      0.45      0.41      1032
           3       0.23      0.51      0.32      1010
           4       0.11      0.06      0.08       982
           5       0.15      0.08      0.11       892
           6       0.34      0.24      0.28       958
           7       0.42      0.08      0.13      1028
           8       0.18      0.50      0.26       974
           9       0.18      0.21      0.19      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.30      0.25      0.22     10000
weighted avg       0.31      0.24      0.21     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2311
Incorrectly classified: 7689
Test accuracy: 23.11%
              precision    recall  f1-score   support

           0       0.52      0.31      0.39       980
           1       0.12      0.00      0.00      1135
           2       0.39      0.43      0.41      1032
           3       0.22      0.28      0.25      1010
           4       0.21      0.12      0.15       982
           5       0.26      0.21      0.24       892
           6       0.41      0.31      0.36       958
           7       0.40      0.07      0.12      1028
           8       0.13      0.49      0.20       974
           9       0.12      0.11      0.11      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.28      0.23      0.22     10000
weighted avg       0.28      0.23      0.22     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2158
Incorrectly classified: 7842
Test accuracy: 21.58%
              precision    recall  f1-score   support

           0       0.79      0.20      0.32       980
           1       0.16      0.00      0.01      1135
           2       0.35      0.34      0.34      1032
           3       0.19      0.27      0.22      1010
           4       0.19      0.15      0.17       982
           5       0.27      0.29      0.28       892
           6       0.49      0.21      0.29       958
           7       0.23      0.02      0.03      1028
           8       0.14      0.65      0.23       974
           9       0.19      0.09      0.12      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.30      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.44      0.33      0.38       980
           1       0.56      0.08      0.14      1135
           2       0.29      0.37      0.33      1032
           3       0.23      0.22      0.22      1010
           4       0.21      0.15      0.18       982
           5       0.15      0.26      0.19       892
           6       0.35      0.29      0.32       958
           7       0.36      0.22      0.27      1028
           8       0.15      0.39      0.22       974
           9       0.20      0.13      0.16      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.24     10000
weighted avg       0.30      0.24      0.24     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.46      0.39      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.34      0.43      0.38      1032
           3       0.24      0.27      0.26      1010
           4       0.21      0.20      0.20       982
           5       0.17      0.35      0.23       892
           6       0.38      0.22      0.27       958
           7       0.26      0.10      0.14      1028
           8       0.18      0.42      0.25       974
           9       0.14      0.10      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.24      0.25      0.23     10000
weighted avg       0.23      0.24      0.22     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2385
Incorrectly classified: 7615
Test accuracy: 23.85%
              precision    recall  f1-score   support

           0       0.37      0.36      0.37       980
           1       0.17      0.00      0.00      1135
           2       0.53      0.34      0.42      1032
           3       0.27      0.44      0.33      1010
           4       0.15      0.10      0.12       982
           5       0.22      0.41      0.29       892
           6       0.33      0.07      0.12       958
           7       0.17      0.19      0.18      1028
           8       0.16      0.37      0.22       974
           9       0.20      0.15      0.17      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.22     10000
weighted avg       0.26      0.24      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2508
Incorrectly classified: 7492
Test accuracy: 25.08%
              precision    recall  f1-score   support

           0       0.52      0.26      0.34       980
           1       0.13      0.00      0.00      1135
           2       0.44      0.29      0.35      1032
           3       0.28      0.27      0.27      1010
           4       0.20      0.30      0.24       982
           5       0.27      0.11      0.16       892
           6       0.43      0.21      0.29       958
           7       0.50      0.22      0.31      1028
           8       0.16      0.63      0.26       974
           9       0.18      0.23      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2535
Incorrectly classified: 7465
Test accuracy: 25.35%
              precision    recall  f1-score   support

           0       0.50      0.26      0.34       980
           1       0.11      0.00      0.00      1135
           2       0.40      0.30      0.35      1032
           3       0.36      0.36      0.36      1010
           4       0.19      0.27      0.22       982
           5       0.29      0.19      0.23       892
           6       0.37      0.32      0.35       958
           7       0.62      0.10      0.17      1028
           8       0.18      0.64      0.28       974
           9       0.10      0.13      0.11      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.26      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2458
Incorrectly classified: 7542
Test accuracy: 24.58%
              precision    recall  f1-score   support

           0       0.46      0.33      0.38       980
           1       0.50      0.01      0.02      1135
           2       0.31      0.52      0.39      1032
           3       0.33      0.23      0.27      1010
           4       0.25      0.08      0.12       982
           5       0.17      0.31      0.22       892
           6       0.28      0.40      0.33       958
           7       0.52      0.09      0.15      1028
           8       0.15      0.47      0.23       974
           9       0.25      0.06      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.22     10000
weighted avg       0.33      0.25      0.22     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2505
Incorrectly classified: 7495
Test accuracy: 25.05%
              precision    recall  f1-score   support

           0       0.38      0.33      0.35       980
           1       0.12      0.00      0.00      1135
           2       0.28      0.29      0.29      1032
           3       0.27      0.45      0.34      1010
           4       0.18      0.07      0.10       982
           5       0.21      0.43      0.29       892
           6       0.34      0.13      0.19       958
           7       0.40      0.16      0.23      1028
           8       0.16      0.45      0.24       974
           9       0.33      0.24      0.28      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.27      0.26      0.23     10000
weighted avg       0.27      0.25      0.23     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2493
Incorrectly classified: 7507
Test accuracy: 24.93%
              precision    recall  f1-score   support

           0       0.46      0.26      0.33       980
           1       0.03      0.00      0.00      1135
           2       0.29      0.62      0.40      1032
           3       0.20      0.25      0.22      1010
           4       0.25      0.28      0.26       982
           5       0.30      0.21      0.25       892
           6       0.32      0.28      0.30       958
           7       0.48      0.11      0.18      1028
           8       0.19      0.46      0.27       974
           9       0.07      0.05      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.26      0.25      0.23     10000
weighted avg       0.25      0.25      0.22     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2406
Incorrectly classified: 7594
Test accuracy: 24.06%
              precision    recall  f1-score   support

           0       0.53      0.31      0.39       980
           1       0.05      0.00      0.00      1135
           2       0.30      0.33      0.32      1032
           3       0.18      0.45      0.26      1010
           4       0.21      0.12      0.15       982
           5       0.14      0.11      0.12       892
           6       0.50      0.22      0.31       958
           7       0.34      0.26      0.30      1028
           8       0.16      0.34      0.22       974
           9       0.21      0.26      0.24      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.23     10000
weighted avg       0.26      0.24      0.23     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 6356
Incorrectly classified: 3644
Adversarial accuracy: 63.56%
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       980
           1       0.92      0.10      0.18      1135
           2       0.66      0.80      0.72      1032
           3       0.67      0.81      0.73      1010
           4       0.60      0.65      0.62       982
           5       0.71      0.64      0.67       892
           6       0.90      0.72      0.80       958
           7       0.86      0.61      0.71      1028
           8       0.36      0.89      0.51       974
           9       0.57      0.36      0.44      1009

   micro avg       0.64      0.64      0.64     10000
   macro avg       0.71      0.64      0.63     10000
weighted avg       0.72      0.64      0.62     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4815
Incorrectly classified: 5185
Test accuracy: 48.15%
              precision    recall  f1-score   support

           0       0.73      0.65      0.69       980
           1       0.90      0.19      0.32      1135
           2       0.55      0.52      0.54      1032
           3       0.47      0.68      0.56      1010
           4       0.50      0.37      0.43       982
           5       0.54      0.35      0.42       892
           6       0.67      0.52      0.58       958
           7       0.75      0.32      0.45      1028
           8       0.28      0.81      0.42       974
           9       0.38      0.44      0.41      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.48     10000
weighted avg       0.58      0.48      0.48     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4918
Incorrectly classified: 5082
Test accuracy: 49.18%
              precision    recall  f1-score   support

           0       0.87      0.62      0.72       980
           1       0.97      0.11      0.20      1135
           2       0.53      0.70      0.60      1032
           3       0.42      0.68      0.52      1010
           4       0.64      0.32      0.43       982
           5       0.39      0.58      0.47       892
           6       0.79      0.66      0.72       958
           7       0.76      0.17      0.28      1028
           8       0.31      0.65      0.42       974
           9       0.40      0.50      0.45      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4812
Incorrectly classified: 5188
Test accuracy: 48.12%
              precision    recall  f1-score   support

           0       0.93      0.45      0.61       980
           1       0.90      0.10      0.18      1135
           2       0.49      0.70      0.58      1032
           3       0.44      0.52      0.47      1010
           4       0.44      0.70      0.54       982
           5       0.38      0.57      0.46       892
           6       0.72      0.57      0.63       958
           7       0.79      0.35      0.49      1028
           8       0.33      0.73      0.46       974
           9       0.42      0.19      0.26      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.47     10000
weighted avg       0.59      0.48      0.46     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5678
Incorrectly classified: 4322
Test accuracy: 56.78%
              precision    recall  f1-score   support

           0       0.81      0.71      0.76       980
           1       0.90      0.52      0.66      1135
           2       0.56      0.54      0.55      1032
           3       0.47      0.59      0.52      1010
           4       0.54      0.50      0.52       982
           5       0.46      0.56      0.50       892
           6       0.78      0.69      0.73       958
           7       0.80      0.49      0.61      1028
           8       0.38      0.69      0.49       974
           9       0.42      0.40      0.41      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.58     10000
weighted avg       0.62      0.57      0.58     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4922
Incorrectly classified: 5078
Test accuracy: 49.22%
              precision    recall  f1-score   support

           0       0.73      0.73      0.73       980
           1       0.88      0.07      0.14      1135
           2       0.44      0.63      0.52      1032
           3       0.41      0.67      0.51      1010
           4       0.50      0.33      0.40       982
           5       0.42      0.55      0.47       892
           6       0.71      0.60      0.65       958
           7       0.66      0.41      0.51      1028
           8       0.33      0.63      0.43       974
           9       0.55      0.36      0.44      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.56      0.50      0.48     10000
weighted avg       0.57      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4608
Incorrectly classified: 5392
Test accuracy: 46.08%
              precision    recall  f1-score   support

           0       0.67      0.60      0.64       980
           1       0.89      0.12      0.22      1135
           2       0.68      0.44      0.53      1032
           3       0.46      0.54      0.50      1010
           4       0.45      0.55      0.50       982
           5       0.37      0.54      0.44       892
           6       0.66      0.31      0.42       958
           7       0.36      0.77      0.49      1028
           8       0.42      0.51      0.46       974
           9       0.35      0.27      0.30      1009

   micro avg       0.46      0.46      0.46     10000
   macro avg       0.53      0.47      0.45     10000
weighted avg       0.54      0.46      0.45     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5081
Incorrectly classified: 4919
Test accuracy: 50.81%
              precision    recall  f1-score   support

           0       0.73      0.66      0.69       980
           1       0.91      0.26      0.41      1135
           2       0.56      0.50      0.53      1032
           3       0.61      0.62      0.61      1010
           4       0.40      0.66      0.50       982
           5       0.66      0.17      0.27       892
           6       0.76      0.44      0.56       958
           7       0.69      0.63      0.66      1028
           8       0.29      0.77      0.42       974
           9       0.40      0.38      0.39      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.60      0.51      0.50     10000
weighted avg       0.61      0.51      0.51     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4756
Incorrectly classified: 5244
Test accuracy: 47.56%
              precision    recall  f1-score   support

           0       0.85      0.70      0.77       980
           1       0.80      0.08      0.14      1135
           2       0.57      0.56      0.57      1032
           3       0.49      0.61      0.54      1010
           4       0.43      0.55      0.49       982
           5       0.48      0.48      0.48       892
           6       0.71      0.53      0.61       958
           7       0.88      0.36      0.52      1028
           8       0.25      0.79      0.38       974
           9       0.30      0.17      0.21      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.48      0.47     10000
weighted avg       0.58      0.48      0.47     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4367
Incorrectly classified: 5633
Test accuracy: 43.67%
              precision    recall  f1-score   support

           0       0.72      0.67      0.69       980
           1       0.92      0.08      0.14      1135
           2       0.44      0.79      0.56      1032
           3       0.50      0.35      0.41      1010
           4       0.63      0.18      0.28       982
           5       0.34      0.67      0.45       892
           6       0.79      0.51      0.61       958
           7       0.84      0.27      0.41      1028
           8       0.23      0.69      0.35       974
           9       0.48      0.24      0.32      1009

   micro avg       0.44      0.44      0.44     10000
   macro avg       0.59      0.44      0.42     10000
weighted avg       0.60      0.44      0.42     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4663
Incorrectly classified: 5337
Test accuracy: 46.63%
              precision    recall  f1-score   support

           0       0.79      0.57      0.66       980
           1       0.95      0.08      0.14      1135
           2       0.61      0.57      0.59      1032
           3       0.60      0.66      0.63      1010
           4       0.52      0.42      0.47       982
           5       0.53      0.47      0.50       892
           6       0.83      0.52      0.64       958
           7       0.85      0.28      0.42      1028
           8       0.21      0.85      0.34       974
           9       0.44      0.32      0.37      1009

   micro avg       0.47      0.47      0.47     10000
   macro avg       0.63      0.47      0.48     10000
weighted avg       0.64      0.47      0.47     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5105
Incorrectly classified: 4895
Test accuracy: 51.05%
              precision    recall  f1-score   support

           0       0.81      0.68      0.74       980
           1       0.88      0.22      0.35      1135
           2       0.41      0.82      0.54      1032
           3       0.62      0.64      0.63      1010
           4       0.60      0.36      0.45       982
           5       0.52      0.44      0.48       892
           6       0.77      0.64      0.70       958
           7       0.78      0.33      0.46      1028
           8       0.27      0.74      0.40       974
           9       0.49      0.27      0.35      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.62      0.51      0.51     10000
weighted avg       0.62      0.51      0.51     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5372
Incorrectly classified: 4628
Test accuracy: 53.72%
              precision    recall  f1-score   support

           0       0.77      0.77      0.77       980
           1       0.94      0.19      0.31      1135
           2       0.46      0.69      0.55      1032
           3       0.44      0.84      0.58      1010
           4       0.52      0.51      0.52       982
           5       0.59      0.33      0.42       892
           6       0.82      0.53      0.64       958
           7       0.61      0.55      0.58      1028
           8       0.43      0.60      0.50       974
           9       0.42      0.39      0.40      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.60      0.54      0.53     10000
weighted avg       0.60      0.54      0.52     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9439
Incorrectly classified: 561
Adversarial accuracy: 94.39%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.95      0.94      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.92      0.95      0.94       982
           5       0.95      0.90      0.93       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.92      0.91      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8818
Incorrectly classified: 1182
Test accuracy: 88.18%
              precision    recall  f1-score   support

           0       0.92      0.93      0.93       980
           1       0.97      0.97      0.97      1135
           2       0.89      0.89      0.89      1032
           3       0.85      0.86      0.86      1010
           4       0.85      0.87      0.86       982
           5       0.84      0.79      0.81       892
           6       0.91      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.82      0.85      0.83       974
           9       0.84      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8857
Incorrectly classified: 1143
Test accuracy: 88.57%
              precision    recall  f1-score   support

           0       0.94      0.94      0.94       980
           1       0.97      0.96      0.97      1135
           2       0.92      0.89      0.90      1032
           3       0.86      0.86      0.86      1010
           4       0.84      0.91      0.87       982
           5       0.85      0.84      0.84       892
           6       0.92      0.89      0.91       958
           7       0.89      0.89      0.89      1028
           8       0.82      0.87      0.84       974
           9       0.84      0.79      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8803
Incorrectly classified: 1197
Test accuracy: 88.03%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.97      0.98      0.98      1135
           2       0.88      0.89      0.88      1032
           3       0.82      0.84      0.83      1010
           4       0.84      0.87      0.86       982
           5       0.83      0.82      0.83       892
           6       0.94      0.90      0.92       958
           7       0.93      0.88      0.90      1028
           8       0.81      0.85      0.83       974
           9       0.83      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8767
Incorrectly classified: 1233
Test accuracy: 87.67%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.85      0.88      1032
           3       0.85      0.79      0.82      1010
           4       0.85      0.88      0.86       982
           5       0.81      0.82      0.81       892
           6       0.93      0.90      0.91       958
           7       0.88      0.89      0.89      1028
           8       0.83      0.84      0.84       974
           9       0.79      0.86      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8817
Incorrectly classified: 1183
Test accuracy: 88.17%
              precision    recall  f1-score   support

           0       0.92      0.94      0.93       980
           1       0.98      0.96      0.97      1135
           2       0.92      0.87      0.90      1032
           3       0.83      0.85      0.84      1010
           4       0.86      0.87      0.86       982
           5       0.85      0.80      0.83       892
           6       0.95      0.88      0.91       958
           7       0.88      0.90      0.89      1028
           8       0.81      0.87      0.84       974
           9       0.82      0.85      0.84      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8789
Incorrectly classified: 1211
Test accuracy: 87.89%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.98      0.97      0.98      1135
           2       0.90      0.91      0.91      1032
           3       0.84      0.89      0.86      1010
           4       0.80      0.88      0.84       982
           5       0.88      0.79      0.83       892
           6       0.92      0.91      0.92       958
           7       0.87      0.91      0.89      1028
           8       0.82      0.84      0.83       974
           9       0.83      0.76      0.79      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8823
Incorrectly classified: 1177
Test accuracy: 88.23%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.98      0.97      0.97      1135
           2       0.94      0.83      0.88      1032
           3       0.86      0.83      0.84      1010
           4       0.81      0.91      0.86       982
           5       0.86      0.84      0.85       892
           6       0.93      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.77      0.90      0.83       974
           9       0.85      0.81      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.88      0.88     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8860
Incorrectly classified: 1140
Test accuracy: 88.60%
              precision    recall  f1-score   support

           0       0.93      0.94      0.94       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.90      0.90      1032
           3       0.87      0.85      0.86      1010
           4       0.83      0.87      0.85       982
           5       0.86      0.84      0.85       892
           6       0.89      0.92      0.90       958
           7       0.94      0.86      0.90      1028
           8       0.83      0.87      0.85       974
           9       0.80      0.82      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8869
Incorrectly classified: 1131
Test accuracy: 88.69%
              precision    recall  f1-score   support

           0       0.95      0.92      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.89      0.90      1032
           3       0.86      0.85      0.86      1010
           4       0.86      0.87      0.86       982
           5       0.84      0.85      0.84       892
           6       0.89      0.92      0.90       958
           7       0.91      0.90      0.91      1028
           8       0.84      0.85      0.84       974
           9       0.83      0.83      0.83      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8894
Incorrectly classified: 1106
Test accuracy: 88.94%
              precision    recall  f1-score   support

           0       0.91      0.95      0.93       980
           1       0.98      0.97      0.97      1135
           2       0.94      0.82      0.88      1032
           3       0.83      0.89      0.86      1010
           4       0.88      0.89      0.89       982
           5       0.86      0.87      0.86       892
           6       0.93      0.91      0.92       958
           7       0.92      0.88      0.90      1028
           8       0.81      0.86      0.83       974
           9       0.83      0.85      0.84      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8864
Incorrectly classified: 1136
Test accuracy: 88.64%
              precision    recall  f1-score   support

           0       0.93      0.94      0.94       980
           1       0.98      0.96      0.97      1135
           2       0.87      0.91      0.89      1032
           3       0.84      0.84      0.84      1010
           4       0.91      0.87      0.89       982
           5       0.87      0.80      0.83       892
           6       0.93      0.92      0.92       958
           7       0.92      0.87      0.90      1028
           8       0.79      0.86      0.82       974
           9       0.82      0.86      0.84      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.88      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8931
Incorrectly classified: 1069
Test accuracy: 89.31%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.98      0.97      0.98      1135
           2       0.90      0.90      0.90      1032
           3       0.82      0.89      0.85      1010
           4       0.90      0.86      0.88       982
           5       0.84      0.84      0.84       892
           6       0.94      0.90      0.92       958
           7       0.90      0.91      0.91      1028
           8       0.89      0.82      0.85       974
           9       0.82      0.87      0.84      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9345
Incorrectly classified: 655
Adversarial accuracy: 93.45%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.95      0.93      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.94      0.92       982
           5       0.93      0.92      0.92       892
           6       0.95      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.92      0.91      0.92       974
           9       0.92      0.87      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8639
Incorrectly classified: 1361
Test accuracy: 86.39%
              precision    recall  f1-score   support

           0       0.89      0.92      0.91       980
           1       0.95      0.95      0.95      1135
           2       0.87      0.87      0.87      1032
           3       0.85      0.85      0.85      1010
           4       0.82      0.87      0.85       982
           5       0.80      0.81      0.81       892
           6       0.91      0.90      0.90       958
           7       0.87      0.88      0.88      1028
           8       0.82      0.82      0.82       974
           9       0.83      0.77      0.80      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8646
Incorrectly classified: 1354
Test accuracy: 86.46%
              precision    recall  f1-score   support

           0       0.94      0.93      0.94       980
           1       0.96      0.95      0.95      1135
           2       0.90      0.86      0.88      1032
           3       0.83      0.84      0.84      1010
           4       0.79      0.89      0.84       982
           5       0.81      0.86      0.84       892
           6       0.92      0.90      0.91       958
           7       0.84      0.87      0.85      1028
           8       0.83      0.85      0.84       974
           9       0.82      0.69      0.75      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.86      0.86     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8605
Incorrectly classified: 1395
Test accuracy: 86.05%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.96      1135
           2       0.85      0.86      0.85      1032
           3       0.80      0.82      0.81      1010
           4       0.80      0.87      0.83       982
           5       0.80      0.86      0.83       892
           6       0.94      0.90      0.92       958
           7       0.89      0.88      0.88      1028
           8       0.82      0.79      0.81       974
           9       0.82      0.73      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8566
Incorrectly classified: 1434
Test accuracy: 85.66%
              precision    recall  f1-score   support

           0       0.94      0.92      0.93       980
           1       0.96      0.94      0.95      1135
           2       0.90      0.79      0.84      1032
           3       0.84      0.79      0.81      1010
           4       0.81      0.86      0.84       982
           5       0.78      0.85      0.81       892
           6       0.91      0.90      0.91       958
           7       0.85      0.89      0.87      1028
           8       0.81      0.82      0.81       974
           9       0.77      0.80      0.78      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8620
Incorrectly classified: 1380
Test accuracy: 86.20%
              precision    recall  f1-score   support

           0       0.92      0.91      0.91       980
           1       0.96      0.95      0.96      1135
           2       0.91      0.84      0.87      1032
           3       0.82      0.86      0.84      1010
           4       0.81      0.86      0.83       982
           5       0.80      0.83      0.81       892
           6       0.94      0.85      0.89       958
           7       0.86      0.90      0.88      1028
           8       0.82      0.84      0.83       974
           9       0.79      0.76      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8545
Incorrectly classified: 1455
Test accuracy: 85.45%
              precision    recall  f1-score   support

           0       0.92      0.89      0.91       980
           1       0.96      0.96      0.96      1135
           2       0.87      0.89      0.88      1032
           3       0.82      0.86      0.84      1010
           4       0.77      0.85      0.81       982
           5       0.83      0.80      0.82       892
           6       0.90      0.90      0.90       958
           7       0.83      0.87      0.85      1028
           8       0.83      0.79      0.81       974
           9       0.80      0.70      0.75      1009

   micro avg       0.85      0.85      0.85     10000
   macro avg       0.85      0.85      0.85     10000
weighted avg       0.85      0.85      0.85     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8734
Incorrectly classified: 1266
Test accuracy: 87.34%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.97      1135
           2       0.92      0.81      0.87      1032
           3       0.83      0.85      0.84      1010
           4       0.80      0.91      0.85       982
           5       0.83      0.85      0.84       892
           6       0.92      0.89      0.90       958
           7       0.89      0.89      0.89      1028
           8       0.79      0.86      0.83       974
           9       0.86      0.77      0.81      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.87      0.87     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8655
Incorrectly classified: 1345
Test accuracy: 86.55%
              precision    recall  f1-score   support

           0       0.92      0.93      0.92       980
           1       0.96      0.96      0.96      1135
           2       0.90      0.86      0.88      1032
           3       0.86      0.84      0.85      1010
           4       0.79      0.87      0.83       982
           5       0.83      0.84      0.83       892
           6       0.88      0.92      0.90       958
           7       0.91      0.83      0.87      1028
           8       0.82      0.84      0.83       974
           9       0.78      0.75      0.76      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8714
Incorrectly classified: 1286
Test accuracy: 87.14%
              precision    recall  f1-score   support

           0       0.95      0.92      0.93       980
           1       0.96      0.96      0.96      1135
           2       0.88      0.85      0.87      1032
           3       0.84      0.85      0.85      1010
           4       0.82      0.86      0.84       982
           5       0.80      0.88      0.84       892
           6       0.88      0.91      0.90       958
           7       0.88      0.90      0.89      1028
           8       0.86      0.79      0.83       974
           9       0.82      0.77      0.80      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8688
Incorrectly classified: 1312
Test accuracy: 86.88%
              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.96      0.96      0.96      1135
           2       0.91      0.80      0.85      1032
           3       0.79      0.87      0.83      1010
           4       0.84      0.89      0.86       982
           5       0.82      0.88      0.85       892
           6       0.92      0.89      0.90       958
           7       0.90      0.88      0.89      1028
           8       0.80      0.79      0.80       974
           9       0.82      0.78      0.80      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8753
Incorrectly classified: 1247
Test accuracy: 87.53%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.97      0.95      0.96      1135
           2       0.85      0.90      0.87      1032
           3       0.85      0.84      0.85      1010
           4       0.85      0.87      0.86       982
           5       0.84      0.84      0.84       892
           6       0.92      0.91      0.91       958
           7       0.90      0.87      0.88      1028
           8       0.82      0.83      0.82       974
           9       0.83      0.80      0.81      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8745
Incorrectly classified: 1255
Test accuracy: 87.45%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.97      0.97      0.97      1135
           2       0.88      0.86      0.87      1032
           3       0.80      0.89      0.84      1010
           4       0.86      0.85      0.86       982
           5       0.82      0.85      0.83       892
           6       0.93      0.90      0.91       958
           7       0.86      0.90      0.88      1028
           8       0.89      0.78      0.83       974
           9       0.81      0.81      0.81      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.87      0.87     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  12 , size_proj =  12 ) ===

Loading time: --- 31.794774532318115 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)
Correctly classified: 9774
Incorrectly classified: 226
Test accuracy: 97.74%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.97      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9627
Incorrectly classified: 373
Test accuracy: 96.27%
              precision    recall  f1-score   support

           0       0.96      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.96      0.96      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.96      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.96      0.95       974
           9       0.96      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9644
Incorrectly classified: 356
Test accuracy: 96.44%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.97      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.97      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9633
Incorrectly classified: 367
Test accuracy: 96.33%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.96      0.97      0.97       982
           5       0.95      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.95      0.95      0.95       974
           9       0.95      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9601
Incorrectly classified: 399
Test accuracy: 96.01%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.95      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.94      0.96      0.95       892
           6       0.97      0.98      0.97       958
           7       0.96      0.95      0.96      1028
           8       0.95      0.94      0.94       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9615
Incorrectly classified: 385
Test accuracy: 96.15%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.95      0.96      0.96       982
           5       0.96      0.94      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.94      0.96      1028
           8       0.93      0.97      0.95       974
           9       0.95      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9640
Incorrectly classified: 360
Test accuracy: 96.40%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.96      1032
           3       0.95      0.96      0.96      1010
           4       0.97      0.95      0.96       982
           5       0.96      0.96      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.95      0.96       974
           9       0.96      0.95      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9593
Incorrectly classified: 407
Test accuracy: 95.93%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.94      0.95      1032
           3       0.95      0.95      0.95      1010
           4       0.95      0.97      0.96       982
           5       0.94      0.96      0.95       892
           6       0.96      0.98      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.93      0.94      0.94       974
           9       0.97      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9600
Incorrectly classified: 400
Test accuracy: 96.00%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.93      0.96      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.97      0.95      0.96       892
           6       0.97      0.96      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.94      0.95       974
           9       0.94      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9610
Incorrectly classified: 390
Test accuracy: 96.10%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.95      1032
           3       0.97      0.94      0.96      1010
           4       0.94      0.98      0.96       982
           5       0.96      0.95      0.95       892
           6       0.96      0.98      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.91      0.96      0.94       974
           9       0.97      0.92      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9624
Incorrectly classified: 376
Test accuracy: 96.24%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.95      0.96      1010
           4       0.95      0.97      0.96       982
           5       0.95      0.96      0.95       892
           6       0.98      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.92      0.95      0.94       974
           9       0.96      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9638
Incorrectly classified: 362
Test accuracy: 96.38%
              precision    recall  f1-score   support

           0       0.96      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.95      0.96      0.96      1010
           4       0.95      0.98      0.96       982
           5       0.96      0.96      0.96       892
           6       0.99      0.96      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.95      0.95       974
           9       0.96      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9618
Incorrectly classified: 382
Test accuracy: 96.18%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.95      0.95      1032
           3       0.95      0.96      0.95      1010
           4       0.95      0.96      0.95       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.96      0.96      0.96      1028
           8       0.96      0.94      0.95       974
           9       0.96      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 3038
Incorrectly classified: 6962
Adversarial accuracy: 30.38%
              precision    recall  f1-score   support

           0       0.68      0.46      0.55       980
           1       0.00      0.00      0.00      1135
           2       0.56      0.61      0.58      1032
           3       0.35      0.43      0.39      1010
           4       0.19      0.13      0.15       982
           5       0.35      0.29      0.32       892
           6       0.57      0.35      0.44       958
           7       0.57      0.07      0.13      1028
           8       0.16      0.70      0.26       974
           9       0.06      0.04      0.05      1009

   micro avg       0.30      0.30      0.30     10000
   macro avg       0.35      0.31      0.29     10000
weighted avg       0.34      0.30      0.28     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2574
Incorrectly classified: 7426
Test accuracy: 25.74%
              precision    recall  f1-score   support

           0       0.48      0.33      0.39       980
           1       0.18      0.01      0.01      1135
           2       0.34      0.56      0.42      1032
           3       0.25      0.43      0.32      1010
           4       0.20      0.12      0.15       982
           5       0.31      0.25      0.27       892
           6       0.37      0.25      0.30       958
           7       0.55      0.17      0.26      1028
           8       0.14      0.33      0.20       974
           9       0.12      0.17      0.14      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.25     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2743
Incorrectly classified: 7257
Test accuracy: 27.43%
              precision    recall  f1-score   support

           0       0.59      0.29      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.60      0.50      1032
           3       0.33      0.41      0.37      1010
           4       0.22      0.12      0.16       982
           5       0.32      0.30      0.31       892
           6       0.38      0.18      0.25       958
           7       0.35      0.06      0.10      1028
           8       0.17      0.65      0.27       974
           9       0.17      0.16      0.16      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.29      0.28      0.25     10000
weighted avg       0.29      0.27      0.25     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2795
Incorrectly classified: 7205
Test accuracy: 27.95%
              precision    recall  f1-score   support

           0       0.55      0.48      0.51       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.38      0.45      1032
           3       0.25      0.18      0.21      1010
           4       0.26      0.18      0.21       982
           5       0.24      0.39      0.29       892
           6       0.54      0.31      0.39       958
           7       0.53      0.15      0.23      1028
           8       0.16      0.63      0.26       974
           9       0.20      0.15      0.17      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.33      0.29      0.27     10000
weighted avg       0.32      0.28      0.27     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2357
Incorrectly classified: 7643
Test accuracy: 23.57%
              precision    recall  f1-score   support

           0       0.58      0.36      0.44       980
           1       0.04      0.00      0.00      1135
           2       0.32      0.43      0.37      1032
           3       0.22      0.31      0.26      1010
           4       0.24      0.09      0.13       982
           5       0.19      0.27      0.22       892
           6       0.45      0.29      0.35       958
           7       0.41      0.08      0.13      1028
           8       0.13      0.45      0.20       974
           9       0.19      0.13      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.23     10000
weighted avg       0.27      0.24      0.22     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2582
Incorrectly classified: 7418
Test accuracy: 25.82%
              precision    recall  f1-score   support

           0       0.58      0.32      0.41       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.48      0.45      1032
           3       0.39      0.30      0.34      1010
           4       0.20      0.14      0.16       982
           5       0.22      0.31      0.26       892
           6       0.36      0.45      0.40       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.53      0.22       974
           9       0.10      0.05      0.06      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2413
Incorrectly classified: 7587
Test accuracy: 24.13%
              precision    recall  f1-score   support

           0       0.46      0.35      0.39       980
           1       0.29      0.00      0.00      1135
           2       0.44      0.47      0.46      1032
           3       0.25      0.51      0.33      1010
           4       0.15      0.13      0.14       982
           5       0.25      0.22      0.23       892
           6       0.52      0.22      0.31       958
           7       0.31      0.05      0.09      1028
           8       0.13      0.43      0.20       974
           9       0.11      0.06      0.08      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.22     10000
weighted avg       0.29      0.24      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2367
Incorrectly classified: 7633
Test accuracy: 23.67%
              precision    recall  f1-score   support

           0       0.42      0.17      0.25       980
           1       0.00      0.00      0.00      1135
           2       0.36      0.47      0.41      1032
           3       0.22      0.52      0.31      1010
           4       0.18      0.09      0.12       982
           5       0.18      0.09      0.12       892
           6       0.64      0.29      0.40       958
           7       0.50      0.11      0.17      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.16      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.22     10000
weighted avg       0.28      0.24      0.21     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2688
Incorrectly classified: 7312
Test accuracy: 26.88%
              precision    recall  f1-score   support

           0       0.62      0.26      0.37       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.51      0.49      1032
           3       0.32      0.35      0.33      1010
           4       0.21      0.31      0.25       982
           5       0.28      0.26      0.27       892
           6       0.38      0.31      0.34       958
           7       0.46      0.06      0.11      1028
           8       0.17      0.63      0.26       974
           9       0.08      0.04      0.05      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.30      0.27      0.25     10000
weighted avg       0.30      0.27      0.24     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2494
Incorrectly classified: 7506
Test accuracy: 24.94%
              precision    recall  f1-score   support

           0       0.58      0.31      0.40       980
           1       0.20      0.00      0.00      1135
           2       0.38      0.39      0.39      1032
           3       0.23      0.12      0.16      1010
           4       0.25      0.22      0.24       982
           5       0.22      0.40      0.28       892
           6       0.36      0.42      0.39       958
           7       0.58      0.08      0.14      1028
           8       0.16      0.58      0.25       974
           9       0.09      0.04      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.23     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2662
Incorrectly classified: 7338
Test accuracy: 26.62%
              precision    recall  f1-score   support

           0       0.46      0.30      0.36       980
           1       0.00      0.00      0.00      1135
           2       0.39      0.53      0.45      1032
           3       0.29      0.23      0.26      1010
           4       0.20      0.12      0.15       982
           5       0.29      0.42      0.34       892
           6       0.27      0.32      0.29       958
           7       0.52      0.11      0.19      1028
           8       0.17      0.61      0.27       974
           9       0.16      0.09      0.11      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.28      0.27      0.24     10000
weighted avg       0.27      0.27      0.24     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2495
Incorrectly classified: 7505
Test accuracy: 24.95%
              precision    recall  f1-score   support

           0       0.50      0.40      0.44       980
           1       0.12      0.00      0.01      1135
           2       0.36      0.43      0.39      1032
           3       0.28      0.33      0.30      1010
           4       0.29      0.18      0.22       982
           5       0.21      0.08      0.12       892
           6       0.53      0.20      0.30       958
           7       0.39      0.09      0.14      1028
           8       0.15      0.59      0.24       974
           9       0.15      0.22      0.18      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.25      0.23     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2791
Incorrectly classified: 7209
Test accuracy: 27.91%
              precision    recall  f1-score   support

           0       0.53      0.39      0.45       980
           1       0.00      0.00      0.00      1135
           2       0.43      0.47      0.45      1032
           3       0.26      0.41      0.32      1010
           4       0.26      0.22      0.24       982
           5       0.25      0.26      0.25       892
           6       0.35      0.13      0.19       958
           7       0.26      0.25      0.26      1028
           8       0.22      0.40      0.28       974
           9       0.18      0.30      0.23      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.27      0.28      0.27     10000
weighted avg       0.27      0.28      0.26     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 6285
Incorrectly classified: 3715
Adversarial accuracy: 62.85%
              precision    recall  f1-score   support

           0       0.89      0.87      0.88       980
           1       0.87      0.11      0.20      1135
           2       0.58      0.86      0.69      1032
           3       0.63      0.76      0.69      1010
           4       0.59      0.65      0.62       982
           5       0.68      0.64      0.66       892
           6       0.86      0.78      0.82       958
           7       0.88      0.57      0.69      1028
           8       0.38      0.83      0.52       974
           9       0.54      0.31      0.39      1009

   micro avg       0.63      0.63      0.63     10000
   macro avg       0.69      0.64      0.62     10000
weighted avg       0.69      0.63      0.61     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5698
Incorrectly classified: 4302
Test accuracy: 56.98%
              precision    recall  f1-score   support

           0       0.74      0.84      0.79       980
           1       0.91      0.19      0.31      1135
           2       0.55      0.81      0.65      1032
           3       0.53      0.60      0.56      1010
           4       0.53      0.36      0.43       982
           5       0.54      0.50      0.52       892
           6       0.73      0.68      0.71       958
           7       0.78      0.59      0.67      1028
           8       0.43      0.66      0.52       974
           9       0.40      0.52      0.45      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.56     10000
weighted avg       0.62      0.57      0.56     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5208
Incorrectly classified: 4792
Test accuracy: 52.08%
              precision    recall  f1-score   support

           0       0.83      0.75      0.79       980
           1       0.90      0.05      0.09      1135
           2       0.41      0.86      0.56      1032
           3       0.53      0.66      0.59      1010
           4       0.72      0.25      0.37       982
           5       0.52      0.64      0.58       892
           6       0.86      0.56      0.68       958
           7       0.76      0.33      0.47      1028
           8       0.31      0.74      0.44       974
           9       0.51      0.45      0.48      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.64      0.53      0.50     10000
weighted avg       0.64      0.52      0.50     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5925
Incorrectly classified: 4075
Test accuracy: 59.25%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.95      0.40      0.56      1135
           2       0.56      0.72      0.63      1032
           3       0.78      0.37      0.50      1010
           4       0.48      0.69      0.57       982
           5       0.44      0.71      0.54       892
           6       0.72      0.79      0.75       958
           7       0.83      0.61      0.70      1028
           8       0.44      0.72      0.55       974
           9       0.39      0.27      0.32      1009

   micro avg       0.59      0.59      0.59     10000
   macro avg       0.65      0.60      0.59     10000
weighted avg       0.65      0.59      0.59     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5253
Incorrectly classified: 4747
Test accuracy: 52.53%
              precision    recall  f1-score   support

           0       0.92      0.63      0.75       980
           1       0.85      0.24      0.37      1135
           2       0.49      0.74      0.59      1032
           3       0.54      0.57      0.55      1010
           4       0.54      0.57      0.56       982
           5       0.48      0.37      0.42       892
           6       0.75      0.67      0.71       958
           7       0.80      0.41      0.54      1028
           8       0.31      0.78      0.44       974
           9       0.39      0.31      0.35      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.53     10000
weighted avg       0.61      0.53      0.53     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4883
Incorrectly classified: 5117
Test accuracy: 48.83%
              precision    recall  f1-score   support

           0       0.90      0.66      0.76       980
           1       0.86      0.10      0.19      1135
           2       0.53      0.71      0.61      1032
           3       0.51      0.52      0.51      1010
           4       0.49      0.45      0.47       982
           5       0.44      0.50      0.47       892
           6       0.83      0.62      0.71       958
           7       0.84      0.35      0.49      1028
           8       0.25      0.80      0.39       974
           9       0.40      0.24      0.31      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.49     10000
weighted avg       0.61      0.49      0.48     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5136
Incorrectly classified: 4864
Test accuracy: 51.36%
              precision    recall  f1-score   support

           0       0.80      0.63      0.70       980
           1       0.91      0.18      0.30      1135
           2       0.51      0.66      0.58      1032
           3       0.42      0.84      0.56      1010
           4       0.45      0.64      0.52       982
           5       0.57      0.51      0.54       892
           6       0.77      0.63      0.69       958
           7       0.81      0.30      0.44      1028
           8       0.34      0.61      0.44       974
           9       0.35      0.19      0.25      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.59      0.52      0.50     10000
weighted avg       0.60      0.51      0.50     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4906
Incorrectly classified: 5094
Test accuracy: 49.06%
              precision    recall  f1-score   support

           0       0.78      0.80      0.79       980
           1       0.82      0.07      0.12      1135
           2       0.55      0.58      0.57      1032
           3       0.29      0.89      0.44      1010
           4       0.55      0.39      0.46       982
           5       0.54      0.31      0.39       892
           6       0.87      0.51      0.65       958
           7       0.74      0.43      0.55      1028
           8       0.39      0.58      0.47       974
           9       0.44      0.38      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.49      0.48     10000
weighted avg       0.60      0.49      0.48     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5616
Incorrectly classified: 4384
Test accuracy: 56.16%
              precision    recall  f1-score   support

           0       0.87      0.76      0.81       980
           1       0.92      0.16      0.27      1135
           2       0.48      0.81      0.60      1032
           3       0.53      0.65      0.58      1010
           4       0.48      0.73      0.58       982
           5       0.57      0.50      0.53       892
           6       0.75      0.71      0.73       958
           7       0.84      0.49      0.61      1028
           8       0.39      0.73      0.51       974
           9       0.37      0.13      0.19      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.62      0.57      0.54     10000
weighted avg       0.62      0.56      0.54     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5027
Incorrectly classified: 4973
Test accuracy: 50.27%
              precision    recall  f1-score   support

           0       0.86      0.78      0.82       980
           1       0.94      0.16      0.28      1135
           2       0.62      0.71      0.66      1032
           3       0.47      0.18      0.26      1010
           4       0.58      0.47      0.52       982
           5       0.38      0.67      0.49       892
           6       0.79      0.69      0.74       958
           7       0.87      0.29      0.43      1028
           8       0.26      0.87      0.40       974
           9       0.55      0.30      0.39      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.63      0.51      0.50     10000
weighted avg       0.64      0.50      0.49     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5627
Incorrectly classified: 4373
Test accuracy: 56.27%
              precision    recall  f1-score   support

           0       0.84      0.70      0.76       980
           1       0.91      0.17      0.28      1135
           2       0.55      0.78      0.64      1032
           3       0.58      0.44      0.50      1010
           4       0.57      0.58      0.58       982
           5       0.46      0.74      0.57       892
           6       0.71      0.74      0.73       958
           7       0.73      0.55      0.63      1028
           8       0.36      0.74      0.49       974
           9       0.50      0.28      0.36      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.62      0.57      0.55     10000
weighted avg       0.63      0.56      0.55     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5456
Incorrectly classified: 4544
Test accuracy: 54.56%
              precision    recall  f1-score   support

           0       0.74      0.80      0.77       980
           1       0.86      0.29      0.43      1135
           2       0.53      0.72      0.61      1032
           3       0.55      0.67      0.61      1010
           4       0.60      0.61      0.60       982
           5       0.61      0.30      0.40       892
           6       0.77      0.59      0.67       958
           7       0.80      0.42      0.55      1028
           8       0.30      0.75      0.43       974
           9       0.42      0.33      0.37      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.55      0.54     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5514
Incorrectly classified: 4486
Test accuracy: 55.14%
              precision    recall  f1-score   support

           0       0.86      0.76      0.81       980
           1       0.92      0.07      0.13      1135
           2       0.40      0.81      0.53      1032
           3       0.42      0.75      0.54      1010
           4       0.65      0.49      0.56       982
           5       0.58      0.52      0.55       892
           6       0.77      0.66      0.71       958
           7       0.64      0.54      0.59      1028
           8       0.49      0.56      0.52       974
           9       0.52      0.41      0.46      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.63      0.56      0.54     10000
weighted avg       0.63      0.55      0.53     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9592
Incorrectly classified: 408
Adversarial accuracy: 95.92%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.96      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.95      0.96      0.95       982
           5       0.97      0.94      0.95       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9264
Incorrectly classified: 736
Test accuracy: 92.64%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.91      0.91      1010
           4       0.92      0.91      0.92       982
           5       0.92      0.88      0.90       892
           6       0.94      0.94      0.94       958
           7       0.96      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.89      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.96      0.97      1135
           2       0.92      0.94      0.93      1032
           3       0.87      0.92      0.90      1010
           4       0.93      0.91      0.92       982
           5       0.94      0.88      0.91       892
           6       0.94      0.94      0.94       958
           7       0.93      0.92      0.92      1028
           8       0.86      0.91      0.88       974
           9       0.89      0.88      0.89      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9235
Incorrectly classified: 765
Test accuracy: 92.35%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.93      0.94      1032
           3       0.92      0.88      0.90      1010
           4       0.87      0.94      0.91       982
           5       0.90      0.90      0.90       892
           6       0.95      0.94      0.95       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.89      0.85      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9206
Incorrectly classified: 794
Test accuracy: 92.06%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.87      0.88      1010
           4       0.91      0.92      0.92       982
           5       0.88      0.91      0.89       892
           6       0.93      0.96      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.89      0.89      0.89       974
           9       0.89      0.87      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9192
Incorrectly classified: 808
Test accuracy: 91.92%
              precision    recall  f1-score   support

           0       0.95      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.90      0.90      0.90      1010
           4       0.90      0.90      0.90       982
           5       0.91      0.86      0.89       892
           6       0.94      0.94      0.94       958
           7       0.95      0.91      0.92      1028
           8       0.85      0.94      0.89       974
           9       0.87      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9230
Incorrectly classified: 770
Test accuracy: 92.30%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.89      0.91      0.90      1010
           4       0.90      0.91      0.90       982
           5       0.93      0.87      0.90       892
           6       0.93      0.96      0.94       958
           7       0.95      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9215
Incorrectly classified: 785
Test accuracy: 92.15%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.91      0.93      1032
           3       0.88      0.90      0.89      1010
           4       0.90      0.93      0.91       982
           5       0.90      0.89      0.89       892
           6       0.93      0.97      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.87      0.90      0.88       974
           9       0.91      0.86      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9214
Incorrectly classified: 786
Test accuracy: 92.14%
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.98      0.97      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.88      0.92      0.90      1010
           4       0.92      0.89      0.90       982
           5       0.94      0.88      0.91       892
           6       0.94      0.93      0.93       958
           7       0.94      0.91      0.93      1028
           8       0.90      0.89      0.89       974
           9       0.86      0.89      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9161
Incorrectly classified: 839
Test accuracy: 91.61%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.93      0.92      0.92      1032
           3       0.93      0.84      0.88      1010
           4       0.86      0.95      0.90       982
           5       0.91      0.86      0.88       892
           6       0.93      0.95      0.94       958
           7       0.94      0.93      0.94      1028
           8       0.81      0.94      0.87       974
           9       0.93      0.82      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.91     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9236
Incorrectly classified: 764
Test accuracy: 92.36%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.99      0.97      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.92      0.89      0.90      1010
           4       0.87      0.94      0.90       982
           5       0.92      0.90      0.91       892
           6       0.94      0.94      0.94       958
           7       0.95      0.92      0.93      1028
           8       0.85      0.93      0.89       974
           9       0.91      0.84      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9216
Incorrectly classified: 784
Test accuracy: 92.16%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.99      0.98      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.87      0.93      0.90      1010
           4       0.88      0.95      0.91       982
           5       0.92      0.86      0.89       892
           6       0.96      0.93      0.95       958
           7       0.94      0.91      0.92      1028
           8       0.90      0.89      0.89       974
           9       0.90      0.85      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9229
Incorrectly classified: 771
Test accuracy: 92.29%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.92      0.93      0.92      1032
           3       0.88      0.90      0.89      1010
           4       0.88      0.92      0.90       982
           5       0.92      0.88      0.90       892
           6       0.93      0.94      0.93       958
           7       0.93      0.94      0.94      1028
           8       0.91      0.89      0.90       974
           9       0.91      0.86      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9447
Incorrectly classified: 553
Adversarial accuracy: 94.47%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.94      0.94      0.94      1010
           4       0.91      0.95      0.93       982
           5       0.94      0.94      0.94       892
           6       0.95      0.96      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.94      0.93      0.94       974
           9       0.93      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9108
Incorrectly classified: 892
Test accuracy: 91.08%
              precision    recall  f1-score   support

           0       0.93      0.96      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.92      0.91      1032
           3       0.90      0.88      0.89      1010
           4       0.87      0.91      0.89       982
           5       0.87      0.91      0.89       892
           6       0.94      0.94      0.94       958
           7       0.93      0.90      0.92      1028
           8       0.90      0.89      0.89       974
           9       0.88      0.83      0.85      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9065
Incorrectly classified: 935
Test accuracy: 90.65%
              precision    recall  f1-score   support

           0       0.95      0.94      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.89      0.92      0.91      1032
           3       0.86      0.90      0.88      1010
           4       0.89      0.91      0.90       982
           5       0.89      0.90      0.90       892
           6       0.94      0.94      0.94       958
           7       0.90      0.91      0.90      1028
           8       0.87      0.88      0.87       974
           9       0.89      0.80      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9051
Incorrectly classified: 949
Test accuracy: 90.51%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.94      0.91      0.92      1032
           3       0.90      0.88      0.89      1010
           4       0.83      0.92      0.88       982
           5       0.86      0.90      0.88       892
           6       0.94      0.93      0.94       958
           7       0.92      0.92      0.92      1028
           8       0.90      0.87      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.91      0.91      0.90     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8988
Incorrectly classified: 1012
Test accuracy: 89.88%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.91      0.90      1032
           3       0.89      0.85      0.87      1010
           4       0.87      0.90      0.88       982
           5       0.82      0.91      0.86       892
           6       0.92      0.96      0.94       958
           7       0.90      0.91      0.91      1028
           8       0.90      0.84      0.87       974
           9       0.86      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9010
Incorrectly classified: 990
Test accuracy: 90.10%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.90      0.91      1032
           3       0.88      0.89      0.88      1010
           4       0.85      0.88      0.86       982
           5       0.87      0.88      0.88       892
           6       0.94      0.93      0.93       958
           7       0.92      0.90      0.91      1028
           8       0.86      0.91      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9027
Incorrectly classified: 973
Test accuracy: 90.27%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.90      0.90      0.90      1032
           3       0.87      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.90      0.89      0.90       892
           6       0.91      0.96      0.93       958
           7       0.92      0.89      0.90      1028
           8       0.90      0.87      0.89       974
           9       0.86      0.78      0.82      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9071
Incorrectly classified: 929
Test accuracy: 90.71%
              precision    recall  f1-score   support

           0       0.95      0.95      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.89      0.91      1032
           3       0.89      0.89      0.89      1010
           4       0.85      0.92      0.88       982
           5       0.87      0.92      0.89       892
           6       0.92      0.96      0.94       958
           7       0.91      0.92      0.91      1028
           8       0.88      0.88      0.88       974
           9       0.91      0.78      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9059
Incorrectly classified: 941
Test accuracy: 90.59%
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.91      0.92      1032
           3       0.86      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.91      0.89      0.90       892
           6       0.93      0.93      0.93       958
           7       0.92      0.91      0.91      1028
           8       0.92      0.84      0.88       974
           9       0.86      0.81      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.90      0.90     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9075
Incorrectly classified: 925
Test accuracy: 90.75%
              precision    recall  f1-score   support

           0       0.96      0.95      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.92      0.87      0.89      1010
           4       0.83      0.94      0.88       982
           5       0.89      0.89      0.89       892
           6       0.93      0.94      0.93       958
           7       0.92      0.93      0.93      1028
           8       0.84      0.91      0.87       974
           9       0.90      0.77      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9011
Incorrectly classified: 989
Test accuracy: 90.11%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.97      0.96      0.97      1135
           2       0.92      0.91      0.92      1032
           3       0.90      0.88      0.89      1010
           4       0.78      0.92      0.85       982
           5       0.89      0.91      0.90       892
           6       0.93      0.94      0.94       958
           7       0.92      0.90      0.91      1028
           8       0.87      0.90      0.89       974
           9       0.87      0.71      0.78      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8989
Incorrectly classified: 1011
Test accuracy: 89.89%
              precision    recall  f1-score   support

           0       0.92      0.95      0.94       980
           1       0.97      0.98      0.97      1135
           2       0.91      0.90      0.90      1032
           3       0.86      0.91      0.88      1010
           4       0.80      0.93      0.86       982
           5       0.88      0.89      0.89       892
           6       0.95      0.93      0.94       958
           7       0.92      0.89      0.90      1028
           8       0.91      0.86      0.88       974
           9       0.87      0.74      0.80      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9017
Incorrectly classified: 983
Test accuracy: 90.17%
              precision    recall  f1-score   support

           0       0.97      0.94      0.96       980
           1       0.96      0.98      0.97      1135
           2       0.92      0.91      0.91      1032
           3       0.86      0.89      0.88      1010
           4       0.82      0.92      0.87       982
           5       0.87      0.88      0.88       892
           6       0.93      0.94      0.93       958
           7       0.89      0.92      0.91      1028
           8       0.92      0.87      0.89       974
           9       0.89      0.75      0.82      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  12 , size_proj =  16 ) ===

Loading time: --- 31.40982699394226 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)
Correctly classified: 9808
Incorrectly classified: 192
Test accuracy: 98.08%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.98      0.99      0.98       958
           7       0.98      0.98      0.98      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9706
Incorrectly classified: 294
Test accuracy: 97.06%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.96      0.98      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9713
Incorrectly classified: 287
Test accuracy: 97.13%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.96      0.98      0.97       958
           7       0.99      0.97      0.98      1028
           8       0.96      0.96      0.96       974
           9       0.96      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.96      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.97      1028
           8       0.96      0.95      0.96       974
           9       0.95      0.96      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9708
Incorrectly classified: 292
Test accuracy: 97.08%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.97      0.98      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.95      0.95       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9721
Incorrectly classified: 279
Test accuracy: 97.21%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.99      0.96      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9711
Incorrectly classified: 289
Test accuracy: 97.11%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.98      0.96       892
           6       0.97      0.98      0.97       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.96      0.97      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9742
Incorrectly classified: 258
Test accuracy: 97.42%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.98      0.98      1028
           8       0.96      0.97      0.97       974
           9       0.98      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9739
Incorrectly classified: 261
Test accuracy: 97.39%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.98      0.97      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.97      0.97      0.97       892
           6       0.99      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9722
Incorrectly classified: 278
Test accuracy: 97.22%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.95      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 2790
Incorrectly classified: 7210
Adversarial accuracy: 27.90%
              precision    recall  f1-score   support

           0       0.66      0.35      0.46       980
           1       0.00      0.00      0.00      1135
           2       0.53      0.52      0.52      1032
           3       0.33      0.40      0.36      1010
           4       0.18      0.09      0.12       982
           5       0.36      0.31      0.33       892
           6       0.59      0.34      0.43       958
           7       0.46      0.04      0.07      1028
           8       0.15      0.70      0.24       974
           9       0.13      0.09      0.11      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.34      0.28      0.26     10000
weighted avg       0.33      0.28      0.26     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2635
Incorrectly classified: 7365
Test accuracy: 26.35%
              precision    recall  f1-score   support

           0       0.58      0.33      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.61      0.42      1032
           3       0.24      0.32      0.28      1010
           4       0.23      0.15      0.19       982
           5       0.31      0.34      0.32       892
           6       0.35      0.35      0.35       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.35      0.20       974
           9       0.16      0.16      0.16      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.27      0.25     10000
weighted avg       0.28      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2529
Incorrectly classified: 7471
Test accuracy: 25.29%
              precision    recall  f1-score   support

           0       0.61      0.24      0.35       980
           1       0.09      0.00      0.00      1135
           2       0.47      0.47      0.47      1032
           3       0.35      0.27      0.31      1010
           4       0.22      0.13      0.17       982
           5       0.29      0.28      0.28       892
           6       0.43      0.34      0.38       958
           7       0.25      0.01      0.02      1028
           8       0.14      0.57      0.22       974
           9       0.18      0.25      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2731
Incorrectly classified: 7269
Test accuracy: 27.31%
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       980
           1       0.11      0.00      0.00      1135
           2       0.56      0.21      0.31      1032
           3       0.24      0.31      0.27      1010
           4       0.37      0.22      0.27       982
           5       0.25      0.40      0.31       892
           6       0.45      0.25      0.32       958
           7       0.43      0.05      0.09      1028
           8       0.16      0.61      0.25       974
           9       0.30      0.34      0.32      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.34      0.28      0.26     10000
weighted avg       0.34      0.27      0.25     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2264
Incorrectly classified: 7736
Test accuracy: 22.64%
              precision    recall  f1-score   support

           0       0.56      0.25      0.34       980
           1       0.06      0.00      0.00      1135
           2       0.33      0.46      0.38      1032
           3       0.24      0.33      0.28      1010
           4       0.26      0.08      0.12       982
           5       0.22      0.17      0.19       892
           6       0.54      0.28      0.37       958
           7       0.34      0.06      0.11      1028
           8       0.12      0.51      0.19       974
           9       0.18      0.15      0.17      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.29      0.23      0.21     10000
weighted avg       0.28      0.23      0.21     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2685
Incorrectly classified: 7315
Test accuracy: 26.85%
              precision    recall  f1-score   support

           0       0.70      0.24      0.35       980
           1       1.00      0.00      0.00      1135
           2       0.44      0.57      0.50      1032
           3       0.33      0.37      0.35      1010
           4       0.22      0.15      0.18       982
           5       0.32      0.31      0.32       892
           6       0.48      0.34      0.40       958
           7       0.57      0.09      0.15      1028
           8       0.14      0.56      0.22       974
           9       0.12      0.10      0.11      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.43      0.27      0.26     10000
weighted avg       0.44      0.27      0.25     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2505
Incorrectly classified: 7495
Test accuracy: 25.05%
              precision    recall  f1-score   support

           0       0.57      0.21      0.31       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.59      0.42      1032
           3       0.24      0.51      0.33      1010
           4       0.16      0.10      0.12       982
           5       0.21      0.36      0.27       892
           6       0.48      0.27      0.34       958
           7       0.47      0.08      0.13      1028
           8       0.15      0.35      0.21       974
           9       0.15      0.08      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.28      0.25      0.22     10000
weighted avg       0.27      0.25      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2486
Incorrectly classified: 7514
Test accuracy: 24.86%
              precision    recall  f1-score   support

           0       0.58      0.29      0.38       980
           1       0.00      0.00      0.00      1135
           2       0.50      0.45      0.48      1032
           3       0.33      0.44      0.38      1010
           4       0.14      0.08      0.10       982
           5       0.39      0.24      0.29       892
           6       0.48      0.34      0.40       958
           7       0.45      0.03      0.05      1028
           8       0.13      0.62      0.22       974
           9       0.05      0.05      0.05      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2547
Incorrectly classified: 7453
Test accuracy: 25.47%
              precision    recall  f1-score   support

           0       0.59      0.27      0.37       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.53      0.44      1032
           3       0.23      0.26      0.25      1010
           4       0.20      0.15      0.17       982
           5       0.21      0.31      0.25       892
           6       0.50      0.33      0.40       958
           7       0.49      0.08      0.14      1028
           8       0.16      0.59      0.25       974
           9       0.15      0.07      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.25      0.23     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2628
Incorrectly classified: 7372
Test accuracy: 26.28%
              precision    recall  f1-score   support

           0       0.54      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.47      0.41      1032
           3       0.31      0.21      0.25      1010
           4       0.25      0.17      0.20       982
           5       0.25      0.32      0.28       892
           6       0.52      0.34      0.41       958
           7       0.54      0.18      0.27      1028
           8       0.13      0.55      0.21       974
           9       0.22      0.14      0.17      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.31      0.27      0.26     10000
weighted avg       0.31      0.26      0.26     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2333
Incorrectly classified: 7667
Test accuracy: 23.33%
              precision    recall  f1-score   support

           0       0.54      0.33      0.41       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.30      0.35      1032
           3       0.28      0.35      0.31      1010
           4       0.17      0.09      0.12       982
           5       0.38      0.29      0.33       892
           6       0.52      0.12      0.19       958
           7       0.51      0.03      0.06      1028
           8       0.14      0.80      0.24       974
           9       0.17      0.06      0.09      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.31      0.24      0.21     10000
weighted avg       0.31      0.23      0.21     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2223
Incorrectly classified: 7777
Test accuracy: 22.23%
              precision    recall  f1-score   support

           0       0.64      0.28      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.29      0.36      1032
           3       0.22      0.35      0.27      1010
           4       0.13      0.05      0.07       982
           5       0.25      0.16      0.20       892
           6       0.57      0.08      0.14       958
           7       0.31      0.05      0.09      1028
           8       0.15      0.77      0.25       974
           9       0.19      0.22      0.20      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.29      0.23      0.20     10000
weighted avg       0.29      0.22      0.20     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2617
Incorrectly classified: 7383
Test accuracy: 26.17%
              precision    recall  f1-score   support

           0       0.49      0.30      0.37       980
           1       0.17      0.01      0.01      1135
           2       0.45      0.37      0.41      1032
           3       0.26      0.39      0.31      1010
           4       0.26      0.18      0.21       982
           5       0.29      0.41      0.34       892
           6       0.36      0.26      0.31       958
           7       0.26      0.10      0.14      1028
           8       0.17      0.51      0.25       974
           9       0.15      0.16      0.15      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.27      0.25     10000
weighted avg       0.28      0.26      0.25     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 5979
Incorrectly classified: 4021
Adversarial accuracy: 59.79%
              precision    recall  f1-score   support

           0       0.89      0.83      0.86       980
           1       0.78      0.05      0.10      1135
           2       0.56      0.82      0.67      1032
           3       0.54      0.78      0.64      1010
           4       0.58      0.54      0.56       982
           5       0.65      0.70      0.67       892
           6       0.87      0.72      0.79       958
           7       0.85      0.47      0.61      1028
           8       0.38      0.80      0.51       974
           9       0.49      0.34      0.40      1009

   micro avg       0.60      0.60      0.60     10000
   macro avg       0.66      0.61      0.58     10000
weighted avg       0.66      0.60      0.57     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5283
Incorrectly classified: 4717
Test accuracy: 52.83%
              precision    recall  f1-score   support

           0       0.84      0.76      0.80       980
           1       0.87      0.06      0.11      1135
           2       0.41      0.87      0.56      1032
           3       0.42      0.62      0.50      1010
           4       0.52      0.45      0.48       982
           5       0.56      0.64      0.60       892
           6       0.75      0.74      0.75       958
           7       0.82      0.38      0.52      1028
           8       0.41      0.56      0.48       974
           9       0.39      0.28      0.32      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.54      0.51     10000
weighted avg       0.60      0.53      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5296
Incorrectly classified: 4704
Test accuracy: 52.96%
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       980
           1       0.85      0.11      0.19      1135
           2       0.56      0.80      0.66      1032
           3       0.58      0.58      0.58      1010
           4       0.59      0.28      0.38       982
           5       0.49      0.68      0.57       892
           6       0.89      0.64      0.74       958
           7       0.82      0.21      0.34      1028
           8       0.28      0.80      0.41       974
           9       0.46      0.44      0.45      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.64      0.54      0.52     10000
weighted avg       0.64      0.53      0.51     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5666
Incorrectly classified: 4334
Test accuracy: 56.66%
              precision    recall  f1-score   support

           0       0.88      0.77      0.82       980
           1       0.86      0.11      0.20      1135
           2       0.65      0.65      0.65      1032
           3       0.64      0.57      0.60      1010
           4       0.50      0.72      0.59       982
           5       0.49      0.75      0.59       892
           6       0.80      0.74      0.77       958
           7       0.85      0.43      0.57      1028
           8       0.35      0.80      0.48       974
           9       0.37      0.24      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.64      0.57      0.55     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5431
Incorrectly classified: 4569
Test accuracy: 54.31%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.89      0.32      0.47      1135
           2       0.52      0.64      0.58      1032
           3       0.43      0.72      0.54      1010
           4       0.64      0.26      0.37       982
           5       0.55      0.47      0.51       892
           6       0.82      0.61      0.70       958
           7       0.72      0.45      0.55      1028
           8       0.35      0.72      0.47       974
           9       0.42      0.56      0.48      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.54      0.54     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4878
Incorrectly classified: 5122
Test accuracy: 48.78%
              precision    recall  f1-score   support

           0       0.91      0.61      0.73       980
           1       0.83      0.03      0.06      1135
           2       0.54      0.71      0.61      1032
           3       0.46      0.60      0.52      1010
           4       0.49      0.39      0.43       982
           5       0.46      0.64      0.54       892
           6       0.83      0.57      0.67       958
           7       0.83      0.30      0.44      1028
           8       0.28      0.75      0.40       974
           9       0.40      0.37      0.38      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4936
Incorrectly classified: 5064
Test accuracy: 49.36%
              precision    recall  f1-score   support

           0       0.88      0.48      0.62       980
           1       0.79      0.05      0.10      1135
           2       0.40      0.72      0.51      1032
           3       0.34      0.87      0.49      1010
           4       0.54      0.46      0.50       982
           5       0.50      0.54      0.52       892
           6       0.81      0.67      0.73       958
           7       0.77      0.39      0.52      1028
           8       0.42      0.45      0.43       974
           9       0.46      0.37      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.59      0.50      0.48     10000
weighted avg       0.59      0.49      0.48     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5256
Incorrectly classified: 4744
Test accuracy: 52.56%
              precision    recall  f1-score   support

           0       0.84      0.77      0.80       980
           1       0.87      0.07      0.14      1135
           2       0.46      0.79      0.58      1032
           3       0.48      0.76      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.55      0.54      0.55       892
           6       0.80      0.72      0.76       958
           7       0.83      0.23      0.36      1028
           8       0.38      0.74      0.50       974
           9       0.34      0.28      0.31      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.53      0.50     10000
weighted avg       0.61      0.53      0.50     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5457
Incorrectly classified: 4543
Test accuracy: 54.57%
              precision    recall  f1-score   support

           0       0.89      0.78      0.83       980
           1       0.83      0.06      0.12      1135
           2       0.49      0.80      0.61      1032
           3       0.41      0.67      0.51      1010
           4       0.49      0.59      0.53       982
           5       0.58      0.59      0.59       892
           6       0.81      0.77      0.79       958
           7       0.83      0.42      0.56      1028
           8       0.38      0.71      0.49       974
           9       0.40      0.15      0.22      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.61      0.55      0.52     10000
weighted avg       0.61      0.55      0.52     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5489
Incorrectly classified: 4511
Test accuracy: 54.89%
              precision    recall  f1-score   support

           0       0.88      0.79      0.83       980
           1       0.93      0.13      0.23      1135
           2       0.47      0.76      0.58      1032
           3       0.56      0.52      0.54      1010
           4       0.58      0.45      0.50       982
           5       0.47      0.73      0.57       892
           6       0.85      0.67      0.75       958
           7       0.86      0.46      0.60      1028
           8       0.31      0.77      0.44       974
           9       0.64      0.29      0.39      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.65      0.56      0.54     10000
weighted avg       0.66      0.55      0.54     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5464
Incorrectly classified: 4536
Test accuracy: 54.64%
              precision    recall  f1-score   support

           0       0.78      0.78      0.78       980
           1       0.91      0.28      0.42      1135
           2       0.56      0.63      0.59      1032
           3       0.54      0.82      0.65      1010
           4       0.49      0.37      0.42       982
           5       0.65      0.61      0.63       892
           6       0.90      0.49      0.63       958
           7       0.72      0.40      0.52      1028
           8       0.31      0.87      0.46       974
           9       0.48      0.27      0.35      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.63      0.55      0.55     10000
weighted avg       0.64      0.55      0.54     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5154
Incorrectly classified: 4846
Test accuracy: 51.54%
              precision    recall  f1-score   support

           0       0.85      0.63      0.73       980
           1       0.86      0.08      0.15      1135
           2       0.55      0.65      0.59      1032
           3       0.48      0.70      0.57      1010
           4       0.49      0.46      0.47       982
           5       0.48      0.50      0.49       892
           6       0.91      0.35      0.51       958
           7       0.69      0.58      0.63      1028
           8       0.35      0.79      0.49       974
           9       0.38      0.46      0.42      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.61      0.52      0.51     10000
weighted avg       0.61      0.52      0.50     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5646
Incorrectly classified: 4354
Test accuracy: 56.46%
              precision    recall  f1-score   support

           0       0.87      0.73      0.80       980
           1       0.88      0.05      0.09      1135
           2       0.52      0.62      0.57      1032
           3       0.42      0.81      0.55      1010
           4       0.64      0.55      0.59       982
           5       0.57      0.65      0.61       892
           6       0.84      0.65      0.73       958
           7       0.71      0.53      0.61      1028
           8       0.41      0.69      0.51       974
           9       0.50      0.45      0.47      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.64      0.57      0.55     10000
weighted avg       0.64      0.56      0.55     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9652
Incorrectly classified: 348
Adversarial accuracy: 96.52%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.96      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.97      0.96      0.96       892
           6       0.97      0.97      0.97       958
           7       0.96      0.96      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.95      0.94      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9393
Incorrectly classified: 607
Test accuracy: 93.93%
              precision    recall  f1-score   support

           0       0.98      0.96      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.93      0.92      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.90      0.92      0.91       892
           6       0.95      0.96      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.92      0.93      0.92       974
           9       0.92      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9415
Incorrectly classified: 585
Test accuracy: 94.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.93      0.91      0.92      1010
           4       0.93      0.94      0.94       982
           5       0.92      0.93      0.92       892
           6       0.94      0.97      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9407
Incorrectly classified: 593
Test accuracy: 94.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.95      0.96      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.91      0.94      0.93       892
           6       0.93      0.97      0.95       958
           7       0.94      0.95      0.95      1028
           8       0.92      0.91      0.92       974
           9       0.93      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9347
Incorrectly classified: 653
Test accuracy: 93.47%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.91      0.92      0.91      1010
           4       0.95      0.91      0.93       982
           5       0.93      0.89      0.91       892
           6       0.95      0.97      0.96       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.91      0.91       974
           9       0.88      0.92      0.90      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9384
Incorrectly classified: 616
Test accuracy: 93.84%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.92      0.93       982
           5       0.94      0.89      0.91       892
           6       0.96      0.95      0.96       958
           7       0.94      0.95      0.95      1028
           8       0.89      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9363
Incorrectly classified: 637
Test accuracy: 93.63%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.97      0.98      1135
           2       0.92      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.95      0.93       982
           5       0.94      0.90      0.92       892
           6       0.95      0.95      0.95       958
           7       0.96      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9382
Incorrectly classified: 618
Test accuracy: 93.82%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.92      0.94      0.93       982
           5       0.96      0.89      0.92       892
           6       0.95      0.95      0.95       958
           7       0.97      0.91      0.94      1028
           8       0.90      0.93      0.92       974
           9       0.90      0.90      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9419
Incorrectly classified: 581
Test accuracy: 94.19%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.94      0.90      0.92      1010
           4       0.94      0.94      0.94       982
           5       0.90      0.94      0.92       892
           6       0.95      0.97      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.93      0.92      0.93       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9406
Incorrectly classified: 594
Test accuracy: 94.06%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.95      0.91      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.91      0.93      0.92       892
           6       0.96      0.96      0.96       958
           7       0.94      0.95      0.94      1028
           8       0.90      0.94      0.92       974
           9       0.91      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9395
Incorrectly classified: 605
Test accuracy: 93.95%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.90      0.94      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.96      0.90      0.93       892
           6       0.96      0.93      0.95       958
           7       0.94      0.96      0.95      1028
           8       0.88      0.95      0.91       974
           9       0.94      0.88      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9405
Incorrectly classified: 595
Test accuracy: 94.05%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.94      0.95      0.95      1032
           3       0.92      0.92      0.92      1010
           4       0.91      0.94      0.93       982
           5       0.93      0.91      0.92       892
           6       0.97      0.95      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9409
Incorrectly classified: 591
Test accuracy: 94.09%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.92      0.93      0.92       982
           5       0.93      0.92      0.93       892
           6       0.95      0.96      0.95       958
           7       0.95      0.95      0.95      1028
           8       0.90      0.94      0.92       974
           9       0.91      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9517
Incorrectly classified: 483
Adversarial accuracy: 95.17%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.95      0.95      0.95      1010
           4       0.92      0.96      0.94       982
           5       0.94      0.96      0.95       892
           6       0.95      0.97      0.96       958
           7       0.95      0.95      0.95      1028
           8       0.95      0.94      0.95       974
           9       0.94      0.89      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9217
Incorrectly classified: 783
Test accuracy: 92.17%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.90      0.91      1010
           4       0.86      0.94      0.89       982
           5       0.86      0.94      0.90       892
           6       0.94      0.95      0.94       958
           7       0.94      0.92      0.93      1028
           8       0.94      0.89      0.91       974
           9       0.89      0.82      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.89      0.89      1010
           4       0.88      0.93      0.90       982
           5       0.88      0.92      0.90       892
           6       0.93      0.96      0.95       958
           7       0.93      0.92      0.93      1028
           8       0.91      0.90      0.91       974
           9       0.91      0.83      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.89      0.90      1010
           4       0.86      0.94      0.90       982
           5       0.87      0.95      0.90       892
           6       0.93      0.96      0.94       958
           7       0.92      0.93      0.93      1028
           8       0.93      0.89      0.91       974
           9       0.90      0.81      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.90      0.91      0.90      1010
           4       0.91      0.92      0.92       982
           5       0.90      0.91      0.90       892
           6       0.94      0.96      0.95       958
           7       0.92      0.90      0.91      1028
           8       0.91      0.86      0.89       974
           9       0.88      0.88      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9211
Incorrectly classified: 789
Test accuracy: 92.11%
              precision    recall  f1-score   support

           0       0.97      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.92      0.92      1032
           3       0.89      0.93      0.91      1010
           4       0.87      0.91      0.89       982
           5       0.91      0.92      0.91       892
           6       0.95      0.94      0.95       958
           7       0.91      0.94      0.93      1028
           8       0.90      0.90      0.90       974
           9       0.89      0.82      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.95      0.96      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.90      0.94      0.92      1032
           3       0.89      0.91      0.90      1010
           4       0.84      0.95      0.89       982
           5       0.91      0.92      0.92       892
           6       0.94      0.95      0.95       958
           7       0.94      0.91      0.92      1028
           8       0.92      0.86      0.89       974
           9       0.92      0.81      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9229
Incorrectly classified: 771
Test accuracy: 92.29%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.90      0.93      0.91      1032
           3       0.90      0.92      0.91      1010
           4       0.86      0.92      0.89       982
           5       0.93      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.95      0.90      0.92      1028
           8       0.92      0.91      0.92       974
           9       0.89      0.84      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9197
Incorrectly classified: 803
Test accuracy: 91.97%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.92      0.93      0.92      1032
           3       0.92      0.87      0.90      1010
           4       0.88      0.93      0.90       982
           5       0.85      0.94      0.89       892
           6       0.93      0.95      0.94       958
           7       0.93      0.92      0.93      1028
           8       0.93      0.88      0.91       974
           9       0.90      0.84      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9282
Incorrectly classified: 718
Test accuracy: 92.82%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.94      0.92      1032
           3       0.94      0.90      0.92      1010
           4       0.91      0.93      0.92       982
           5       0.89      0.94      0.91       892
           6       0.96      0.95      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.92      0.90      0.91       974
           9       0.90      0.86      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9186
Incorrectly classified: 814
Test accuracy: 91.86%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.95      0.90      0.92      1032
           3       0.88      0.94      0.91      1010
           4       0.83      0.93      0.88       982
           5       0.93      0.92      0.92       892
           6       0.95      0.94      0.94       958
           7       0.91      0.94      0.93      1028
           8       0.90      0.92      0.91       974
           9       0.92      0.77      0.84      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9235
Incorrectly classified: 765
Test accuracy: 92.35%
              precision    recall  f1-score   support

           0       0.95      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.91      0.93      0.92      1032
           3       0.92      0.92      0.92      1010
           4       0.84      0.92      0.88       982
           5       0.91      0.93      0.92       892
           6       0.96      0.94      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.92      0.91      0.91       974
           9       0.89      0.80      0.84      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9233
Incorrectly classified: 767
Test accuracy: 92.33%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.95      0.90      0.92      1032
           3       0.90      0.92      0.91      1010
           4       0.88      0.93      0.90       982
           5       0.89      0.93      0.91       892
           6       0.94      0.96      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.90      0.90      0.90       974
           9       0.91      0.83      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  12 , size_proj =  20 ) ===

Loading time: --- 30.93493127822876 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)
Correctly classified: 9831
Incorrectly classified: 169
Test accuracy: 98.31%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.99      0.99      0.99      1010
           4       0.99      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.99      0.98      0.98       958
           7       0.98      0.98      0.98      1028
           8       0.98      0.98      0.98       974
           9       0.98      0.97      0.98      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9748
Incorrectly classified: 252
Test accuracy: 97.48%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9773
Incorrectly classified: 227
Test accuracy: 97.73%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.98       892
           6       0.99      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9749
Incorrectly classified: 251
Test accuracy: 97.49%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.97      0.99      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.98      0.95      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9768
Incorrectly classified: 232
Test accuracy: 97.68%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.96      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9758
Incorrectly classified: 242
Test accuracy: 97.58%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.96      0.96      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9776
Incorrectly classified: 224
Test accuracy: 97.76%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.99      0.97      0.98      1010
           4       0.98      0.99      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.98      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.95      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9764
Incorrectly classified: 236
Test accuracy: 97.64%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.97      0.97       892
           6       0.99      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9770
Incorrectly classified: 230
Test accuracy: 97.70%
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.98      0.97      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.95      0.98      0.96       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9771
Incorrectly classified: 229
Test accuracy: 97.71%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.98      0.98       892
           6       0.99      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.98      1010
           4       0.98      0.97      0.98       982
           5       0.98      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.95      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 2475
Incorrectly classified: 7525
Adversarial accuracy: 24.75%
              precision    recall  f1-score   support

           0       0.65      0.33      0.44       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.46      0.50      1032
           3       0.31      0.36      0.34      1010
           4       0.14      0.08      0.10       982
           5       0.37      0.22      0.28       892
           6       0.56      0.23      0.33       958
           7       0.43      0.03      0.06      1028
           8       0.14      0.73      0.23       974
           9       0.09      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.23     10000
weighted avg       0.32      0.25      0.23     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2500
Incorrectly classified: 7500
Test accuracy: 25.00%
              precision    recall  f1-score   support

           0       0.62      0.38      0.47       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.52      0.50      1032
           3       0.26      0.43      0.32      1010
           4       0.17      0.12      0.14       982
           5       0.29      0.21      0.25       892
           6       0.48      0.23      0.31       958
           7       0.48      0.08      0.14      1028
           8       0.12      0.49      0.19       974
           9       0.09      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2132
Incorrectly classified: 7868
Test accuracy: 21.32%
              precision    recall  f1-score   support

           0       0.68      0.13      0.22       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.49      0.43      1032
           3       0.31      0.28      0.29      1010
           4       0.22      0.09      0.13       982
           5       0.27      0.10      0.15       892
           6       0.58      0.19      0.29       958
           7       0.42      0.02      0.04      1028
           8       0.12      0.74      0.21       974
           9       0.20      0.11      0.14      1009

   micro avg       0.21      0.21      0.21     10000
   macro avg       0.32      0.22      0.19     10000
weighted avg       0.31      0.21      0.19     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2351
Incorrectly classified: 7649
Test accuracy: 23.51%
              precision    recall  f1-score   support

           0       0.59      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.34      0.42      1032
           3       0.25      0.32      0.28      1010
           4       0.24      0.10      0.14       982
           5       0.25      0.23      0.24       892
           6       0.57      0.25      0.34       958
           7       0.48      0.03      0.05      1028
           8       0.14      0.73      0.24       974
           9       0.13      0.11      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.32      0.24      0.22     10000
weighted avg       0.31      0.24      0.22     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2387
Incorrectly classified: 7613
Test accuracy: 23.87%
              precision    recall  f1-score   support

           0       0.49      0.18      0.26       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.43      0.40      1032
           3       0.21      0.37      0.27      1010
           4       0.19      0.13      0.16       982
           5       0.24      0.21      0.23       892
           6       0.55      0.34      0.42       958
           7       0.35      0.14      0.20      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.14      0.14      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.27      0.24      0.23     10000
weighted avg       0.26      0.24      0.23     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2452
Incorrectly classified: 7548
Test accuracy: 24.52%
              precision    recall  f1-score   support

           0       0.66      0.35      0.46       980
           1       0.00      0.00      0.00      1135
           2       0.55      0.43      0.48      1032
           3       0.32      0.34      0.33      1010
           4       0.24      0.24      0.24       982
           5       0.32      0.22      0.26       892
           6       0.42      0.23      0.29       958
           7       0.57      0.05      0.09      1028
           8       0.13      0.60      0.21       974
           9       0.04      0.03      0.04      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.24     10000
weighted avg       0.32      0.25      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2166
Incorrectly classified: 7834
Test accuracy: 21.66%
              precision    recall  f1-score   support

           0       0.57      0.19      0.28       980
           1       0.00      0.00      0.00      1135
           2       0.44      0.41      0.42      1032
           3       0.28      0.39      0.33      1010
           4       0.14      0.08      0.10       982
           5       0.25      0.21      0.23       892
           6       0.58      0.12      0.19       958
           7       0.46      0.05      0.09      1028
           8       0.11      0.58      0.19       974
           9       0.24      0.18      0.20      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.31      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2309
Incorrectly classified: 7691
Test accuracy: 23.09%
              precision    recall  f1-score   support

           0       0.51      0.33      0.40       980
           1       0.00      0.00      0.00      1135
           2       0.47      0.46      0.46      1032
           3       0.38      0.16      0.23      1010
           4       0.13      0.10      0.12       982
           5       0.36      0.20      0.26       892
           6       0.45      0.20      0.28       958
           7       0.48      0.09      0.15      1028
           8       0.13      0.66      0.22       974
           9       0.12      0.14      0.13      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.30      0.23      0.22     10000
weighted avg       0.30      0.23      0.22     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2184
Incorrectly classified: 7816
Test accuracy: 21.84%
              precision    recall  f1-score   support

           0       0.50      0.21      0.29       980
           1       0.00      0.00      0.00      1135
           2       0.41      0.45      0.43      1032
           3       0.25      0.25      0.25      1010
           4       0.11      0.07      0.08       982
           5       0.18      0.12      0.15       892
           6       0.53      0.29      0.38       958
           7       0.55      0.05      0.10      1028
           8       0.14      0.63      0.22       974
           9       0.13      0.14      0.13      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.28      0.22      0.20     10000
weighted avg       0.28      0.22      0.20     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2451
Incorrectly classified: 7549
Test accuracy: 24.51%
              precision    recall  f1-score   support

           0       0.57      0.34      0.42       980
           1       0.17      0.00      0.00      1135
           2       0.43      0.37      0.40      1032
           3       0.21      0.38      0.27      1010
           4       0.26      0.23      0.25       982
           5       0.30      0.28      0.29       892
           6       0.48      0.27      0.35       958
           7       0.43      0.10      0.16      1028
           8       0.13      0.47      0.20       974
           9       0.08      0.05      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2494
Incorrectly classified: 7506
Test accuracy: 24.94%
              precision    recall  f1-score   support

           0       0.58      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.45      0.46      0.45      1032
           3       0.37      0.28      0.32      1010
           4       0.19      0.13      0.16       982
           5       0.37      0.38      0.37       892
           6       0.49      0.19      0.28       958
           7       0.34      0.01      0.02      1028
           8       0.14      0.77      0.24       974
           9       0.08      0.03      0.05      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.23     10000
weighted avg       0.30      0.25      0.22     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2239
Incorrectly classified: 7761
Test accuracy: 22.39%
              precision    recall  f1-score   support

           0       0.61      0.24      0.34       980
           1       0.03      0.00      0.00      1135
           2       0.47      0.26      0.34      1032
           3       0.26      0.44      0.32      1010
           4       0.11      0.06      0.08       982
           5       0.25      0.26      0.25       892
           6       0.55      0.18      0.27       958
           7       0.16      0.03      0.05      1028
           8       0.16      0.60      0.25       974
           9       0.13      0.22      0.17      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.27      0.23      0.21     10000
weighted avg       0.27      0.22      0.20     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2735
Incorrectly classified: 7265
Test accuracy: 27.35%
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       980
           1       0.00      0.00      0.00      1135
           2       0.45      0.48      0.46      1032
           3       0.25      0.36      0.30      1010
           4       0.29      0.13      0.18       982
           5       0.36      0.28      0.31       892
           6       0.39      0.25      0.31       958
           7       0.30      0.08      0.12      1028
           8       0.15      0.55      0.24       974
           9       0.22      0.25      0.23      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.29      0.28      0.26     10000
weighted avg       0.29      0.27      0.26     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 5758
Incorrectly classified: 4242
Adversarial accuracy: 57.58%
              precision    recall  f1-score   support

           0       0.89      0.83      0.86       980
           1       0.78      0.07      0.12      1135
           2       0.59      0.79      0.68      1032
           3       0.58      0.80      0.67      1010
           4       0.52      0.61      0.56       982
           5       0.72      0.53      0.61       892
           6       0.86      0.70      0.77       958
           7       0.84      0.41      0.55      1028
           8       0.33      0.87      0.48       974
           9       0.41      0.24      0.30      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.65      0.58      0.56     10000
weighted avg       0.65      0.58      0.55     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5187
Incorrectly classified: 4813
Test accuracy: 51.87%
              precision    recall  f1-score   support

           0       0.85      0.80      0.83       980
           1       0.80      0.04      0.07      1135
           2       0.51      0.83      0.63      1032
           3       0.57      0.68      0.62      1010
           4       0.49      0.39      0.43       982
           5       0.57      0.39      0.47       892
           6       0.81      0.66      0.73       958
           7       0.75      0.36      0.48      1028
           8       0.29      0.77      0.42       974
           9       0.36      0.32      0.34      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.50     10000
weighted avg       0.60      0.52      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4908
Incorrectly classified: 5092
Test accuracy: 49.08%
              precision    recall  f1-score   support

           0       0.89      0.70      0.79       980
           1       0.81      0.07      0.12      1135
           2       0.52      0.75      0.61      1032
           3       0.53      0.67      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.63      0.28      0.39       892
           6       0.86      0.62      0.72       958
           7       0.85      0.31      0.46      1028
           8       0.26      0.87      0.41       974
           9       0.32      0.24      0.28      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.62      0.49      0.48     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5655
Incorrectly classified: 4345
Test accuracy: 56.55%
              precision    recall  f1-score   support

           0       0.84      0.83      0.83       980
           1       0.93      0.19      0.32      1135
           2       0.61      0.69      0.65      1032
           3       0.58      0.66      0.62      1010
           4       0.50      0.62      0.55       982
           5       0.57      0.63      0.60       892
           6       0.81      0.66      0.73       958
           7       0.78      0.42      0.54      1028
           8       0.34      0.77      0.48       974
           9       0.34      0.25      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.63      0.57      0.56     10000
weighted avg       0.63      0.57      0.56     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5180
Incorrectly classified: 4820
Test accuracy: 51.80%
              precision    recall  f1-score   support

           0       0.88      0.57      0.69       980
           1       0.82      0.13      0.23      1135
           2       0.46      0.64      0.53      1032
           3       0.43      0.86      0.57      1010
           4       0.49      0.44      0.47       982
           5       0.59      0.37      0.46       892
           6       0.85      0.59      0.69       958
           7       0.69      0.60      0.64      1028
           8       0.35      0.74      0.47       974
           9       0.43      0.27      0.33      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.51     10000
weighted avg       0.60      0.52      0.51     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5235
Incorrectly classified: 4765
Test accuracy: 52.35%
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       980
           1       0.89      0.24      0.37      1135
           2       0.62      0.67      0.64      1032
           3       0.45      0.73      0.56      1010
           4       0.46      0.62      0.53       982
           5       0.55      0.46      0.50       892
           6       0.84      0.47      0.61       958
           7       0.78      0.29      0.42      1028
           8       0.30      0.76      0.43       974
           9       0.37      0.24      0.29      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.61      0.53      0.52     10000
weighted avg       0.62      0.52      0.52     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5036
Incorrectly classified: 4964
Test accuracy: 50.36%
              precision    recall  f1-score   support

           0       0.88      0.54      0.67       980
           1       0.88      0.18      0.30      1135
           2       0.57      0.69      0.62      1032
           3       0.47      0.80      0.59      1010
           4       0.46      0.51      0.48       982
           5       0.49      0.53      0.51       892
           6       0.86      0.48      0.62       958
           7       0.71      0.19      0.30      1028
           8       0.33      0.81      0.47       974
           9       0.38      0.37      0.38      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.60      0.51      0.49     10000
weighted avg       0.61      0.50      0.49     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5701
Incorrectly classified: 4299
Test accuracy: 57.01%
              precision    recall  f1-score   support

           0       0.84      0.85      0.85       980
           1       0.92      0.19      0.32      1135
           2       0.51      0.79      0.62      1032
           3       0.64      0.54      0.59      1010
           4       0.52      0.68      0.59       982
           5       0.61      0.49      0.54       892
           6       0.83      0.70      0.76       958
           7       0.85      0.49      0.62      1028
           8       0.34      0.80      0.47       974
           9       0.39      0.23      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.65      0.57      0.56     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5269
Incorrectly classified: 4731
Test accuracy: 52.69%
              precision    recall  f1-score   support

           0       0.87      0.77      0.82       980
           1       0.83      0.11      0.19      1135
           2       0.50      0.79      0.61      1032
           3       0.47      0.69      0.56      1010
           4       0.52      0.44      0.48       982
           5       0.60      0.38      0.47       892
           6       0.80      0.75      0.78       958
           7       0.79      0.20      0.32      1028
           8       0.34      0.78      0.47       974
           9       0.38      0.42      0.40      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.51     10000
weighted avg       0.61      0.53      0.50     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5251
Incorrectly classified: 4749
Test accuracy: 52.51%
              precision    recall  f1-score   support

           0       0.89      0.75      0.82       980
           1       0.76      0.03      0.06      1135
           2       0.62      0.53      0.58      1032
           3       0.51      0.79      0.62      1010
           4       0.48      0.63      0.54       982
           5       0.61      0.49      0.54       892
           6       0.84      0.67      0.74       958
           7       0.84      0.41      0.55      1028
           8       0.27      0.83      0.41       974
           9       0.47      0.21      0.29      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.63      0.53      0.52     10000
weighted avg       0.63      0.53      0.51     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5309
Incorrectly classified: 4691
Test accuracy: 53.09%
              precision    recall  f1-score   support

           0       0.82      0.82      0.82       980
           1       0.81      0.05      0.09      1135
           2       0.48      0.80      0.60      1032
           3       0.61      0.59      0.60      1010
           4       0.50      0.55      0.52       982
           5       0.66      0.59      0.62       892
           6       0.89      0.57      0.69       958
           7       0.86      0.37      0.52      1028
           8       0.29      0.86      0.43       974
           9       0.49      0.21      0.29      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.64      0.54      0.52     10000
weighted avg       0.64      0.53      0.51     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5007
Incorrectly classified: 4993
Test accuracy: 50.07%
              precision    recall  f1-score   support

           0       0.86      0.63      0.73       980
           1       0.82      0.10      0.18      1135
           2       0.62      0.57      0.60      1032
           3       0.54      0.75      0.63      1010
           4       0.50      0.40      0.45       982
           5       0.59      0.45      0.51       892
           6       0.85      0.55      0.67       958
           7       0.74      0.38      0.50      1028
           8       0.26      0.86      0.39       974
           9       0.40      0.37      0.39      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.62      0.51      0.50     10000
weighted avg       0.62      0.50      0.50     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5780
Incorrectly classified: 4220
Test accuracy: 57.80%
              precision    recall  f1-score   support

           0       0.89      0.77      0.82       980
           1       0.85      0.12      0.21      1135
           2       0.53      0.69      0.60      1032
           3       0.42      0.76      0.54      1010
           4       0.58      0.74      0.65       982
           5       0.62      0.61      0.62       892
           6       0.79      0.78      0.78       958
           7       0.75      0.44      0.55      1028
           8       0.44      0.72      0.54       974
           9       0.44      0.24      0.31      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.63      0.59      0.56     10000
weighted avg       0.63      0.58      0.56     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9665
Incorrectly classified: 335
Adversarial accuracy: 96.65%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.98      0.94      0.96       892
           6       0.97      0.98      0.97       958
           7       0.98      0.95      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.95      0.94      0.94      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9478
Incorrectly classified: 522
Test accuracy: 94.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.94      0.94      0.94       982
           5       0.94      0.92      0.93       892
           6       0.95      0.96      0.96       958
           7       0.96      0.95      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.93      0.92      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9434
Incorrectly classified: 566
Test accuracy: 94.34%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.96      0.90      0.93       892
           6       0.96      0.97      0.97       958
           7       0.97      0.92      0.94      1028
           8       0.88      0.97      0.92       974
           9       0.92      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9500
Incorrectly classified: 500
Test accuracy: 95.00%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.93      0.94      0.94      1010
           4       0.94      0.94      0.94       982
           5       0.95      0.93      0.94       892
           6       0.96      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.92      0.94      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9452
Incorrectly classified: 548
Test accuracy: 94.52%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.90      0.96      0.93      1010
           4       0.92      0.95      0.94       982
           5       0.95      0.90      0.92       892
           6       0.94      0.97      0.96       958
           7       0.93      0.95      0.94      1028
           8       0.95      0.90      0.92       974
           9       0.94      0.89      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9458
Incorrectly classified: 542
Test accuracy: 94.58%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.97      0.88      0.92       892
           6       0.97      0.95      0.96       958
           7       0.97      0.93      0.95      1028
           8       0.90      0.95      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9459
Incorrectly classified: 541
Test accuracy: 94.59%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.95      1032
           3       0.92      0.95      0.93      1010
           4       0.94      0.92      0.93       982
           5       0.95      0.90      0.93       892
           6       0.97      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.93      0.94      0.94       974
           9       0.88      0.93      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9492
Incorrectly classified: 508
Test accuracy: 94.92%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.96      0.93      0.95      1010
           4       0.92      0.95      0.94       982
           5       0.96      0.91      0.94       892
           6       0.97      0.96      0.96       958
           7       0.93      0.96      0.95      1028
           8       0.92      0.96      0.94       974
           9       0.94      0.89      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9492
Incorrectly classified: 508
Test accuracy: 94.92%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.97      0.96      1032
           3       0.94      0.93      0.93      1010
           4       0.93      0.95      0.94       982
           5       0.97      0.89      0.93       892
           6       0.96      0.97      0.96       958
           7       0.96      0.95      0.96      1028
           8       0.90      0.95      0.93       974
           9       0.93      0.93      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9512
Incorrectly classified: 488
Test accuracy: 95.12%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.97      0.98      1135
           2       0.96      0.95      0.95      1032
           3       0.93      0.95      0.94      1010
           4       0.92      0.96      0.94       982
           5       0.96      0.92      0.94       892
           6       0.97      0.96      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.90      0.95      0.92       974
           9       0.95      0.91      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9465
Incorrectly classified: 535
Test accuracy: 94.65%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.94      0.97      0.95      1032
           3       0.96      0.91      0.93      1010
           4       0.93      0.96      0.94       982
           5       0.95      0.91      0.93       892
           6       0.96      0.96      0.96       958
           7       0.97      0.92      0.94      1028
           8       0.89      0.96      0.92       974
           9       0.92      0.91      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9495
Incorrectly classified: 505
Test accuracy: 94.95%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.95      0.95      0.95      1032
           3       0.95      0.92      0.93      1010
           4       0.95      0.93      0.94       982
           5       0.95      0.93      0.94       892
           6       0.97      0.97      0.97       958
           7       0.95      0.95      0.95      1028
           8       0.92      0.94      0.93       974
           9       0.92      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9470
Incorrectly classified: 530
Test accuracy: 94.70%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.95      0.95      1032
           3       0.92      0.96      0.94      1010
           4       0.95      0.93      0.94       982
           5       0.95      0.92      0.93       892
           6       0.96      0.97      0.96       958
           7       0.96      0.94      0.95      1028
           8       0.91      0.95      0.93       974
           9       0.92      0.90      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9553
Incorrectly classified: 447
Adversarial accuracy: 95.53%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.98      0.99      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.92      0.96      0.94       982
           5       0.96      0.95      0.96       892
           6       0.96      0.97      0.97       958
           7       0.95      0.95      0.95      1028
           8       0.95      0.95      0.95       974
           9       0.94      0.89      0.92      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.95     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  12 random projections in  one_channel mode: 
Projected data dimensions: (12, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9290
Incorrectly classified: 710
Test accuracy: 92.90%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.97      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.93      0.92      1010
           4       0.87      0.93      0.90       982
           5       0.89      0.93      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.91      0.91       974
           9       0.92      0.84      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9289
Incorrectly classified: 711
Test accuracy: 92.89%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.84      0.95      0.89       982
           5       0.94      0.93      0.93       892
           6       0.97      0.96      0.96       958
           7       0.94      0.91      0.93      1028
           8       0.89      0.94      0.92       974
           9       0.92      0.79      0.85      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9354
Incorrectly classified: 646
Test accuracy: 93.54%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.92      0.95      0.93       892
           6       0.96      0.96      0.96       958
           7       0.95      0.91      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.89      0.87      0.88      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.94      0.93     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9256
Incorrectly classified: 744
Test accuracy: 92.56%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.89      0.94      0.91      1010
           4       0.87      0.95      0.90       982
           5       0.93      0.92      0.92       892
           6       0.94      0.97      0.95       958
           7       0.89      0.94      0.92      1028
           8       0.95      0.87      0.91       974
           9       0.93      0.79      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.92      0.92     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9294
Incorrectly classified: 706
Test accuracy: 92.94%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.84      0.95      0.89       982
           5       0.95      0.90      0.93       892
           6       0.96      0.95      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.93      0.92       974
           9       0.90      0.84      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9307
Incorrectly classified: 693
Test accuracy: 93.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.94      0.92      1010
           4       0.89      0.91      0.90       982
           5       0.94      0.92      0.93       892
           6       0.96      0.95      0.96       958
           7       0.95      0.92      0.93      1028
           8       0.93      0.91      0.92       974
           9       0.87      0.88      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9315
Incorrectly classified: 685
Test accuracy: 93.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.94      0.93      1032
           3       0.94      0.92      0.93      1010
           4       0.87      0.94      0.90       982
           5       0.93      0.92      0.92       892
           6       0.95      0.95      0.95       958
           7       0.91      0.95      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.92      0.81      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9350
Incorrectly classified: 650
Test accuracy: 93.50%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.95      0.94      1032
           3       0.94      0.93      0.93      1010
           4       0.88      0.94      0.91       982
           5       0.95      0.93      0.94       892
           6       0.95      0.96      0.96       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.92      0.91       974
           9       0.91      0.86      0.89      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.94      0.93     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9334
Incorrectly classified: 666
Test accuracy: 93.34%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.91      0.94      0.93      1010
           4       0.87      0.96      0.91       982
           5       0.92      0.94      0.93       892
           6       0.96      0.95      0.96       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.93      0.92       974
           9       0.93      0.81      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9321
Incorrectly classified: 679
Test accuracy: 93.21%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.92      0.96      0.94      1032
           3       0.95      0.92      0.93      1010
           4       0.86      0.95      0.90       982
           5       0.93      0.93      0.93       892
           6       0.96      0.96      0.96       958
           7       0.95      0.90      0.93      1028
           8       0.91      0.94      0.92       974
           9       0.92      0.81      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9322
Incorrectly classified: 678
Test accuracy: 93.22%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.99      0.98      1135
           2       0.93      0.92      0.93      1032
           3       0.94      0.92      0.93      1010
           4       0.89      0.92      0.90       982
           5       0.91      0.95      0.93       892
           6       0.96      0.96      0.96       958
           7       0.92      0.94      0.93      1028
           8       0.94      0.91      0.92       974
           9       0.91      0.85      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9300
Incorrectly classified: 700
Test accuracy: 93.00%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.92      0.91       982
           5       0.92      0.94      0.93       892
           6       0.95      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.91      0.92      0.91       974
           9       0.92      0.83      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  15 , size_proj =  8 ) ===

Loading time: --- 43.70050621032715 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)
Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.97      0.98      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.95      0.97      0.96       974
           9       0.97      0.94      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.89      0.90       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.95      1028
           8       0.90      0.92      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9365
Incorrectly classified: 635
Test accuracy: 93.65%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.94       982
           5       0.91      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.90      0.92      0.91       974
           9       0.93      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9383
Incorrectly classified: 617
Test accuracy: 93.83%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.99      0.99      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.92      0.95      0.93       982
           5       0.91      0.91      0.91       892
           6       0.97      0.95      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.90      0.92      0.91       974
           9       0.94      0.90      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9362
Incorrectly classified: 638
Test accuracy: 93.62%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.93      0.92      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.91      0.91      0.91       892
           6       0.96      0.95      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.88      0.93      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9368
Incorrectly classified: 632
Test accuracy: 93.68%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.91      0.93      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.91      0.91       892
           6       0.97      0.94      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.90      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9376
Incorrectly classified: 624
Test accuracy: 93.76%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.92      0.94      0.93       982
           5       0.94      0.89      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.95      0.94      1028
           8       0.91      0.90      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9378
Incorrectly classified: 622
Test accuracy: 93.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.99      0.98      1135
           2       0.97      0.90      0.93      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.94      0.92      0.93       892
           6       0.94      0.95      0.94       958
           7       0.94      0.94      0.94      1028
           8       0.88      0.94      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9366
Incorrectly classified: 634
Test accuracy: 93.66%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.99      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.93      0.92       982
           5       0.93      0.90      0.92       892
           6       0.92      0.95      0.94       958
           7       0.97      0.92      0.94      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9380
Incorrectly classified: 620
Test accuracy: 93.80%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.93      0.94      0.93       982
           5       0.92      0.93      0.92       892
           6       0.94      0.96      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9392
Incorrectly classified: 608
Test accuracy: 93.92%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.90      0.93      1032
           3       0.91      0.95      0.93      1010
           4       0.94      0.94      0.94       982
           5       0.93      0.92      0.92       892
           6       0.96      0.95      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.91      0.92      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9387
Incorrectly classified: 613
Test accuracy: 93.87%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.95      0.93      0.94       982
           5       0.93      0.89      0.91       892
           6       0.96      0.95      0.95       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.92      0.92      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9414
Incorrectly classified: 586
Test accuracy: 94.14%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.95      0.93      1010
           4       0.94      0.93      0.94       982
           5       0.94      0.92      0.93       892
           6       0.96      0.95      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.94      0.89      0.91       974
           9       0.91      0.93      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9381
Incorrectly classified: 619
Test accuracy: 93.81%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.99      1135
           2       0.89      0.94      0.92      1032
           3       0.91      0.93      0.92      1010
           4       0.92      0.96      0.94       982
           5       0.94      0.91      0.92       892
           6       0.96      0.94      0.95       958
           7       0.94      0.94      0.94      1028
           8       0.92      0.91      0.91       974
           9       0.95      0.89      0.92      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9405
Incorrectly classified: 595
Test accuracy: 94.05%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.94      0.93      1032
           3       0.92      0.93      0.93      1010
           4       0.95      0.93      0.94       982
           5       0.93      0.91      0.92       892
           6       0.95      0.95      0.95       958
           7       0.95      0.94      0.95      1028
           8       0.91      0.90      0.91       974
           9       0.90      0.92      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9361
Incorrectly classified: 639
Test accuracy: 93.61%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.92      0.92      0.92      1010
           4       0.93      0.93      0.93       982
           5       0.92      0.92      0.92       892
           6       0.94      0.96      0.95       958
           7       0.93      0.94      0.94      1028
           8       0.93      0.89      0.91       974
           9       0.90      0.90      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 3230
Incorrectly classified: 6770
Adversarial accuracy: 32.30%
              precision    recall  f1-score   support

           0       0.73      0.44      0.55       980
           1       0.00      0.00      0.00      1135
           2       0.50      0.62      0.55      1032
           3       0.38      0.45      0.42      1010
           4       0.23      0.16      0.19       982
           5       0.38      0.29      0.33       892
           6       0.65      0.38      0.48       958
           7       0.63      0.15      0.24      1028
           8       0.17      0.71      0.27       974
           9       0.12      0.08      0.09      1009

   micro avg       0.32      0.32      0.32     10000
   macro avg       0.38      0.33      0.31     10000
weighted avg       0.37      0.32      0.31     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2436
Incorrectly classified: 7564
Test accuracy: 24.36%
              precision    recall  f1-score   support

           0       0.43      0.30      0.35       980
           1       0.60      0.01      0.02      1135
           2       0.38      0.45      0.41      1032
           3       0.23      0.51      0.32      1010
           4       0.11      0.06      0.08       982
           5       0.15      0.08      0.11       892
           6       0.34      0.24      0.28       958
           7       0.42      0.08      0.13      1028
           8       0.18      0.50      0.26       974
           9       0.18      0.21      0.19      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.30      0.25      0.22     10000
weighted avg       0.31      0.24      0.21     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2311
Incorrectly classified: 7689
Test accuracy: 23.11%
              precision    recall  f1-score   support

           0       0.52      0.31      0.39       980
           1       0.12      0.00      0.00      1135
           2       0.39      0.43      0.41      1032
           3       0.22      0.28      0.25      1010
           4       0.21      0.12      0.15       982
           5       0.26      0.21      0.24       892
           6       0.41      0.31      0.36       958
           7       0.40      0.07      0.12      1028
           8       0.13      0.49      0.20       974
           9       0.12      0.11      0.11      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.28      0.23      0.22     10000
weighted avg       0.28      0.23      0.22     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2158
Incorrectly classified: 7842
Test accuracy: 21.58%
              precision    recall  f1-score   support

           0       0.79      0.20      0.32       980
           1       0.16      0.00      0.01      1135
           2       0.35      0.34      0.34      1032
           3       0.19      0.27      0.22      1010
           4       0.19      0.15      0.17       982
           5       0.27      0.29      0.28       892
           6       0.49      0.21      0.29       958
           7       0.23      0.02      0.03      1028
           8       0.14      0.65      0.23       974
           9       0.19      0.09      0.12      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.30      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.44      0.33      0.38       980
           1       0.56      0.08      0.14      1135
           2       0.29      0.37      0.33      1032
           3       0.23      0.22      0.22      1010
           4       0.21      0.15      0.18       982
           5       0.15      0.26      0.19       892
           6       0.35      0.29      0.32       958
           7       0.36      0.22      0.27      1028
           8       0.15      0.39      0.22       974
           9       0.20      0.13      0.16      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.24     10000
weighted avg       0.30      0.24      0.24     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2408
Incorrectly classified: 7592
Test accuracy: 24.08%
              precision    recall  f1-score   support

           0       0.46      0.39      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.34      0.43      0.38      1032
           3       0.24      0.27      0.26      1010
           4       0.21      0.20      0.20       982
           5       0.17      0.35      0.23       892
           6       0.38      0.22      0.27       958
           7       0.26      0.10      0.14      1028
           8       0.18      0.42      0.25       974
           9       0.14      0.10      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.24      0.25      0.23     10000
weighted avg       0.23      0.24      0.22     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2385
Incorrectly classified: 7615
Test accuracy: 23.85%
              precision    recall  f1-score   support

           0       0.37      0.36      0.37       980
           1       0.17      0.00      0.00      1135
           2       0.53      0.34      0.42      1032
           3       0.27      0.44      0.33      1010
           4       0.15      0.10      0.12       982
           5       0.22      0.41      0.29       892
           6       0.33      0.07      0.12       958
           7       0.17      0.19      0.18      1028
           8       0.16      0.37      0.22       974
           9       0.20      0.15      0.17      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.22     10000
weighted avg       0.26      0.24      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2508
Incorrectly classified: 7492
Test accuracy: 25.08%
              precision    recall  f1-score   support

           0       0.52      0.26      0.34       980
           1       0.13      0.00      0.00      1135
           2       0.44      0.29      0.35      1032
           3       0.28      0.27      0.27      1010
           4       0.20      0.30      0.24       982
           5       0.27      0.11      0.16       892
           6       0.43      0.21      0.29       958
           7       0.50      0.22      0.31      1028
           8       0.16      0.63      0.26       974
           9       0.18      0.23      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2535
Incorrectly classified: 7465
Test accuracy: 25.35%
              precision    recall  f1-score   support

           0       0.50      0.26      0.34       980
           1       0.11      0.00      0.00      1135
           2       0.40      0.30      0.35      1032
           3       0.36      0.36      0.36      1010
           4       0.19      0.27      0.22       982
           5       0.29      0.19      0.23       892
           6       0.37      0.32      0.35       958
           7       0.62      0.10      0.17      1028
           8       0.18      0.64      0.28       974
           9       0.10      0.13      0.11      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.26      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2458
Incorrectly classified: 7542
Test accuracy: 24.58%
              precision    recall  f1-score   support

           0       0.46      0.33      0.38       980
           1       0.50      0.01      0.02      1135
           2       0.31      0.52      0.39      1032
           3       0.33      0.23      0.27      1010
           4       0.25      0.08      0.12       982
           5       0.17      0.31      0.22       892
           6       0.28      0.40      0.33       958
           7       0.52      0.09      0.15      1028
           8       0.15      0.47      0.23       974
           9       0.25      0.06      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.22     10000
weighted avg       0.33      0.25      0.22     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2505
Incorrectly classified: 7495
Test accuracy: 25.05%
              precision    recall  f1-score   support

           0       0.38      0.33      0.35       980
           1       0.12      0.00      0.00      1135
           2       0.28      0.29      0.29      1032
           3       0.27      0.45      0.34      1010
           4       0.18      0.07      0.10       982
           5       0.21      0.43      0.29       892
           6       0.34      0.13      0.19       958
           7       0.40      0.16      0.23      1028
           8       0.16      0.45      0.24       974
           9       0.33      0.24      0.28      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.27      0.26      0.23     10000
weighted avg       0.27      0.25      0.23     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2493
Incorrectly classified: 7507
Test accuracy: 24.93%
              precision    recall  f1-score   support

           0       0.46      0.26      0.33       980
           1       0.03      0.00      0.00      1135
           2       0.29      0.62      0.40      1032
           3       0.20      0.25      0.22      1010
           4       0.25      0.28      0.26       982
           5       0.30      0.21      0.25       892
           6       0.32      0.28      0.30       958
           7       0.48      0.11      0.18      1028
           8       0.19      0.46      0.27       974
           9       0.07      0.05      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.26      0.25      0.23     10000
weighted avg       0.25      0.25      0.22     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2406
Incorrectly classified: 7594
Test accuracy: 24.06%
              precision    recall  f1-score   support

           0       0.53      0.31      0.39       980
           1       0.05      0.00      0.00      1135
           2       0.30      0.33      0.32      1032
           3       0.18      0.45      0.26      1010
           4       0.21      0.12      0.15       982
           5       0.14      0.11      0.12       892
           6       0.50      0.22      0.31       958
           7       0.34      0.26      0.30      1028
           8       0.16      0.34      0.22       974
           9       0.21      0.26      0.24      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.23     10000
weighted avg       0.26      0.24      0.23     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2110
Incorrectly classified: 7890
Test accuracy: 21.10%
              precision    recall  f1-score   support

           0       0.46      0.09      0.16       980
           1       0.29      0.00      0.00      1135
           2       0.23      0.70      0.34      1032
           3       0.29      0.38      0.33      1010
           4       0.30      0.08      0.13       982
           5       0.20      0.14      0.16       892
           6       0.49      0.26      0.34       958
           7       0.23      0.05      0.08      1028
           8       0.10      0.35      0.16       974
           9       0.29      0.06      0.10      1009

   micro avg       0.21      0.21      0.21     10000
   macro avg       0.29      0.21      0.18     10000
weighted avg       0.29      0.21      0.18     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2824
Incorrectly classified: 7176
Test accuracy: 28.24%
              precision    recall  f1-score   support

           0       0.53      0.21      0.30       980
           1       0.00      0.00      0.00      1135
           2       0.30      0.57      0.39      1032
           3       0.29      0.19      0.23      1010
           4       0.29      0.29      0.29       982
           5       0.25      0.28      0.26       892
           6       0.44      0.35      0.39       958
           7       0.48      0.25      0.33      1028
           8       0.18      0.41      0.25       974
           9       0.22      0.31      0.26      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.30      0.29      0.27     10000
weighted avg       0.29      0.28      0.27     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2836
Incorrectly classified: 7164
Test accuracy: 28.36%
              precision    recall  f1-score   support

           0       0.58      0.35      0.43       980
           1       0.21      0.00      0.01      1135
           2       0.26      0.54      0.35      1032
           3       0.36      0.32      0.34      1010
           4       0.29      0.30      0.30       982
           5       0.26      0.21      0.23       892
           6       0.26      0.44      0.33       958
           7       0.45      0.19      0.27      1028
           8       0.19      0.44      0.27       974
           9       0.22      0.08      0.11      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.31      0.29      0.26     10000
weighted avg       0.31      0.28      0.26     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 6475
Incorrectly classified: 3525
Adversarial accuracy: 64.75%
              precision    recall  f1-score   support

           0       0.91      0.84      0.87       980
           1       0.93      0.13      0.22      1135
           2       0.59      0.85      0.70      1032
           3       0.71      0.82      0.76      1010
           4       0.57      0.73      0.64       982
           5       0.76      0.61      0.67       892
           6       0.89      0.76      0.82       958
           7       0.87      0.64      0.74      1028
           8       0.38      0.89      0.53       974
           9       0.59      0.29      0.38      1009

   micro avg       0.65      0.65      0.65     10000
   macro avg       0.72      0.66      0.64     10000
weighted avg       0.72      0.65      0.63     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4815
Incorrectly classified: 5185
Test accuracy: 48.15%
              precision    recall  f1-score   support

           0       0.73      0.65      0.69       980
           1       0.90      0.19      0.32      1135
           2       0.55      0.52      0.54      1032
           3       0.47      0.68      0.56      1010
           4       0.50      0.37      0.43       982
           5       0.54      0.35      0.42       892
           6       0.67      0.52      0.58       958
           7       0.75      0.32      0.45      1028
           8       0.28      0.81      0.42       974
           9       0.38      0.44      0.41      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.48     10000
weighted avg       0.58      0.48      0.48     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4918
Incorrectly classified: 5082
Test accuracy: 49.18%
              precision    recall  f1-score   support

           0       0.87      0.62      0.72       980
           1       0.97      0.11      0.20      1135
           2       0.53      0.70      0.60      1032
           3       0.42      0.68      0.52      1010
           4       0.64      0.32      0.43       982
           5       0.39      0.58      0.47       892
           6       0.79      0.66      0.72       958
           7       0.76      0.17      0.28      1028
           8       0.31      0.65      0.42       974
           9       0.40      0.50      0.45      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4812
Incorrectly classified: 5188
Test accuracy: 48.12%
              precision    recall  f1-score   support

           0       0.93      0.45      0.61       980
           1       0.90      0.10      0.18      1135
           2       0.49      0.70      0.58      1032
           3       0.44      0.52      0.47      1010
           4       0.44      0.70      0.54       982
           5       0.38      0.57      0.46       892
           6       0.72      0.57      0.63       958
           7       0.79      0.35      0.49      1028
           8       0.33      0.73      0.46       974
           9       0.42      0.19      0.26      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.49      0.47     10000
weighted avg       0.59      0.48      0.46     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5678
Incorrectly classified: 4322
Test accuracy: 56.78%
              precision    recall  f1-score   support

           0       0.81      0.71      0.76       980
           1       0.90      0.52      0.66      1135
           2       0.56      0.54      0.55      1032
           3       0.47      0.59      0.52      1010
           4       0.54      0.50      0.52       982
           5       0.46      0.56      0.50       892
           6       0.78      0.69      0.73       958
           7       0.80      0.49      0.61      1028
           8       0.38      0.69      0.49       974
           9       0.42      0.40      0.41      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.58     10000
weighted avg       0.62      0.57      0.58     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4922
Incorrectly classified: 5078
Test accuracy: 49.22%
              precision    recall  f1-score   support

           0       0.73      0.73      0.73       980
           1       0.88      0.07      0.14      1135
           2       0.44      0.63      0.52      1032
           3       0.41      0.67      0.51      1010
           4       0.50      0.33      0.40       982
           5       0.42      0.55      0.47       892
           6       0.71      0.60      0.65       958
           7       0.66      0.41      0.51      1028
           8       0.33      0.63      0.43       974
           9       0.55      0.36      0.44      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.56      0.50      0.48     10000
weighted avg       0.57      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4608
Incorrectly classified: 5392
Test accuracy: 46.08%
              precision    recall  f1-score   support

           0       0.67      0.60      0.64       980
           1       0.89      0.12      0.22      1135
           2       0.68      0.44      0.53      1032
           3       0.46      0.54      0.50      1010
           4       0.45      0.55      0.50       982
           5       0.37      0.54      0.44       892
           6       0.66      0.31      0.42       958
           7       0.36      0.77      0.49      1028
           8       0.42      0.51      0.46       974
           9       0.35      0.27      0.30      1009

   micro avg       0.46      0.46      0.46     10000
   macro avg       0.53      0.47      0.45     10000
weighted avg       0.54      0.46      0.45     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5081
Incorrectly classified: 4919
Test accuracy: 50.81%
              precision    recall  f1-score   support

           0       0.73      0.66      0.69       980
           1       0.91      0.26      0.41      1135
           2       0.56      0.50      0.53      1032
           3       0.61      0.62      0.61      1010
           4       0.40      0.66      0.50       982
           5       0.66      0.17      0.27       892
           6       0.76      0.44      0.56       958
           7       0.69      0.63      0.66      1028
           8       0.29      0.77      0.42       974
           9       0.40      0.38      0.39      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.60      0.51      0.50     10000
weighted avg       0.61      0.51      0.51     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4756
Incorrectly classified: 5244
Test accuracy: 47.56%
              precision    recall  f1-score   support

           0       0.85      0.70      0.77       980
           1       0.80      0.08      0.14      1135
           2       0.57      0.56      0.57      1032
           3       0.49      0.61      0.54      1010
           4       0.43      0.55      0.49       982
           5       0.48      0.48      0.48       892
           6       0.71      0.53      0.61       958
           7       0.88      0.36      0.52      1028
           8       0.25      0.79      0.38       974
           9       0.30      0.17      0.21      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.58      0.48      0.47     10000
weighted avg       0.58      0.48      0.47     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4367
Incorrectly classified: 5633
Test accuracy: 43.67%
              precision    recall  f1-score   support

           0       0.72      0.67      0.69       980
           1       0.92      0.08      0.14      1135
           2       0.44      0.79      0.56      1032
           3       0.50      0.35      0.41      1010
           4       0.63      0.18      0.28       982
           5       0.34      0.67      0.45       892
           6       0.79      0.51      0.61       958
           7       0.84      0.27      0.41      1028
           8       0.23      0.69      0.35       974
           9       0.48      0.24      0.32      1009

   micro avg       0.44      0.44      0.44     10000
   macro avg       0.59      0.44      0.42     10000
weighted avg       0.60      0.44      0.42     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4663
Incorrectly classified: 5337
Test accuracy: 46.63%
              precision    recall  f1-score   support

           0       0.79      0.57      0.66       980
           1       0.95      0.08      0.14      1135
           2       0.61      0.57      0.59      1032
           3       0.60      0.66      0.63      1010
           4       0.52      0.42      0.47       982
           5       0.53      0.47      0.50       892
           6       0.83      0.52      0.64       958
           7       0.85      0.28      0.42      1028
           8       0.21      0.85      0.34       974
           9       0.44      0.32      0.37      1009

   micro avg       0.47      0.47      0.47     10000
   macro avg       0.63      0.47      0.48     10000
weighted avg       0.64      0.47      0.47     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5105
Incorrectly classified: 4895
Test accuracy: 51.05%
              precision    recall  f1-score   support

           0       0.81      0.68      0.74       980
           1       0.88      0.22      0.35      1135
           2       0.41      0.82      0.54      1032
           3       0.62      0.64      0.63      1010
           4       0.60      0.36      0.45       982
           5       0.52      0.44      0.48       892
           6       0.77      0.64      0.70       958
           7       0.78      0.33      0.46      1028
           8       0.27      0.74      0.40       974
           9       0.49      0.27      0.35      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.62      0.51      0.51     10000
weighted avg       0.62      0.51      0.51     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5372
Incorrectly classified: 4628
Test accuracy: 53.72%
              precision    recall  f1-score   support

           0       0.77      0.77      0.77       980
           1       0.94      0.19      0.31      1135
           2       0.46      0.69      0.55      1032
           3       0.44      0.84      0.58      1010
           4       0.52      0.51      0.52       982
           5       0.59      0.33      0.42       892
           6       0.82      0.53      0.64       958
           7       0.61      0.55      0.58      1028
           8       0.43      0.60      0.50       974
           9       0.42      0.39      0.40      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.60      0.54      0.53     10000
weighted avg       0.60      0.54      0.52     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4685
Incorrectly classified: 5315
Test accuracy: 46.85%
              precision    recall  f1-score   support

           0       0.89      0.52      0.65       980
           1       0.82      0.10      0.17      1135
           2       0.23      0.88      0.37      1032
           3       0.55      0.63      0.59      1010
           4       0.48      0.48      0.48       982
           5       0.70      0.22      0.34       892
           6       0.81      0.63      0.71       958
           7       0.69      0.59      0.64      1028
           8       0.43      0.51      0.46       974
           9       0.66      0.15      0.25      1009

   micro avg       0.47      0.47      0.47     10000
   macro avg       0.63      0.47      0.47     10000
weighted avg       0.63      0.47      0.46     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5457
Incorrectly classified: 4543
Test accuracy: 54.57%
              precision    recall  f1-score   support

           0       0.91      0.52      0.66       980
           1       0.89      0.34      0.49      1135
           2       0.40      0.75      0.52      1032
           3       0.60      0.64      0.62      1010
           4       0.48      0.69      0.56       982
           5       0.56      0.34      0.42       892
           6       0.77      0.68      0.72       958
           7       0.76      0.58      0.66      1028
           8       0.38      0.75      0.50       974
           9       0.42      0.19      0.26      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.55      0.54     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5368
Incorrectly classified: 4632
Test accuracy: 53.68%
              precision    recall  f1-score   support

           0       0.92      0.71      0.80       980
           1       0.91      0.16      0.27      1135
           2       0.46      0.75      0.57      1032
           3       0.70      0.67      0.68      1010
           4       0.41      0.76      0.53       982
           5       0.61      0.52      0.56       892
           6       0.53      0.78      0.63       958
           7       0.78      0.39      0.52      1028
           8       0.37      0.62      0.46       974
           9       0.33      0.08      0.12      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.60      0.54      0.52     10000
weighted avg       0.61      0.54      0.51     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9452
Incorrectly classified: 548
Adversarial accuracy: 94.52%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.94      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.93      0.95      0.94       982
           5       0.94      0.90      0.92       892
           6       0.96      0.95      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.92      0.91      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8818
Incorrectly classified: 1182
Test accuracy: 88.18%
              precision    recall  f1-score   support

           0       0.92      0.93      0.93       980
           1       0.97      0.97      0.97      1135
           2       0.89      0.89      0.89      1032
           3       0.85      0.86      0.86      1010
           4       0.85      0.87      0.86       982
           5       0.84      0.79      0.81       892
           6       0.91      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.82      0.85      0.83       974
           9       0.84      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8857
Incorrectly classified: 1143
Test accuracy: 88.57%
              precision    recall  f1-score   support

           0       0.94      0.94      0.94       980
           1       0.97      0.96      0.97      1135
           2       0.92      0.89      0.90      1032
           3       0.86      0.86      0.86      1010
           4       0.84      0.91      0.87       982
           5       0.85      0.84      0.84       892
           6       0.92      0.89      0.91       958
           7       0.89      0.89      0.89      1028
           8       0.82      0.87      0.84       974
           9       0.84      0.79      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8803
Incorrectly classified: 1197
Test accuracy: 88.03%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.97      0.98      0.98      1135
           2       0.88      0.89      0.88      1032
           3       0.82      0.84      0.83      1010
           4       0.84      0.87      0.86       982
           5       0.83      0.82      0.83       892
           6       0.94      0.90      0.92       958
           7       0.93      0.88      0.90      1028
           8       0.81      0.85      0.83       974
           9       0.83      0.82      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8767
Incorrectly classified: 1233
Test accuracy: 87.67%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.85      0.88      1032
           3       0.85      0.79      0.82      1010
           4       0.85      0.88      0.86       982
           5       0.81      0.82      0.81       892
           6       0.93      0.90      0.91       958
           7       0.88      0.89      0.89      1028
           8       0.83      0.84      0.84       974
           9       0.79      0.86      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8817
Incorrectly classified: 1183
Test accuracy: 88.17%
              precision    recall  f1-score   support

           0       0.92      0.94      0.93       980
           1       0.98      0.96      0.97      1135
           2       0.92      0.87      0.90      1032
           3       0.83      0.85      0.84      1010
           4       0.86      0.87      0.86       982
           5       0.85      0.80      0.83       892
           6       0.95      0.88      0.91       958
           7       0.88      0.90      0.89      1028
           8       0.81      0.87      0.84       974
           9       0.82      0.85      0.84      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8789
Incorrectly classified: 1211
Test accuracy: 87.89%
              precision    recall  f1-score   support

           0       0.93      0.92      0.93       980
           1       0.98      0.97      0.98      1135
           2       0.90      0.91      0.91      1032
           3       0.84      0.89      0.86      1010
           4       0.80      0.88      0.84       982
           5       0.88      0.79      0.83       892
           6       0.92      0.91      0.92       958
           7       0.87      0.91      0.89      1028
           8       0.82      0.84      0.83       974
           9       0.83      0.76      0.79      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8823
Incorrectly classified: 1177
Test accuracy: 88.23%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.98      0.97      0.97      1135
           2       0.94      0.83      0.88      1032
           3       0.86      0.83      0.84      1010
           4       0.81      0.91      0.86       982
           5       0.86      0.84      0.85       892
           6       0.93      0.90      0.91       958
           7       0.91      0.90      0.91      1028
           8       0.77      0.90      0.83       974
           9       0.85      0.81      0.83      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.88      0.88     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8860
Incorrectly classified: 1140
Test accuracy: 88.60%
              precision    recall  f1-score   support

           0       0.93      0.94      0.94       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.90      0.90      1032
           3       0.87      0.85      0.86      1010
           4       0.83      0.87      0.85       982
           5       0.86      0.84      0.85       892
           6       0.89      0.92      0.90       958
           7       0.94      0.86      0.90      1028
           8       0.83      0.87      0.85       974
           9       0.80      0.82      0.81      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8869
Incorrectly classified: 1131
Test accuracy: 88.69%
              precision    recall  f1-score   support

           0       0.95      0.92      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.89      0.90      1032
           3       0.86      0.85      0.86      1010
           4       0.86      0.87      0.86       982
           5       0.84      0.85      0.84       892
           6       0.89      0.92      0.90       958
           7       0.91      0.90      0.91      1028
           8       0.84      0.85      0.84       974
           9       0.83      0.83      0.83      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8894
Incorrectly classified: 1106
Test accuracy: 88.94%
              precision    recall  f1-score   support

           0       0.91      0.95      0.93       980
           1       0.98      0.97      0.97      1135
           2       0.94      0.82      0.88      1032
           3       0.83      0.89      0.86      1010
           4       0.88      0.89      0.89       982
           5       0.86      0.87      0.86       892
           6       0.93      0.91      0.92       958
           7       0.92      0.88      0.90      1028
           8       0.81      0.86      0.83       974
           9       0.83      0.85      0.84      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8864
Incorrectly classified: 1136
Test accuracy: 88.64%
              precision    recall  f1-score   support

           0       0.93      0.94      0.94       980
           1       0.98      0.96      0.97      1135
           2       0.87      0.91      0.89      1032
           3       0.84      0.84      0.84      1010
           4       0.91      0.87      0.89       982
           5       0.87      0.80      0.83       892
           6       0.93      0.92      0.92       958
           7       0.92      0.87      0.90      1028
           8       0.79      0.86      0.82       974
           9       0.82      0.86      0.84      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.88      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8931
Incorrectly classified: 1069
Test accuracy: 89.31%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.98      0.97      0.98      1135
           2       0.90      0.90      0.90      1032
           3       0.82      0.89      0.85      1010
           4       0.90      0.86      0.88       982
           5       0.84      0.84      0.84       892
           6       0.94      0.90      0.92       958
           7       0.90      0.91      0.91      1028
           8       0.89      0.82      0.85       974
           9       0.82      0.87      0.84      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8871
Incorrectly classified: 1129
Test accuracy: 88.71%
              precision    recall  f1-score   support

           0       0.94      0.94      0.94       980
           1       0.98      0.96      0.97      1135
           2       0.82      0.92      0.87      1032
           3       0.84      0.86      0.85      1010
           4       0.83      0.92      0.88       982
           5       0.89      0.81      0.85       892
           6       0.94      0.88      0.91       958
           7       0.88      0.92      0.90      1028
           8       0.84      0.85      0.84       974
           9       0.91      0.79      0.85      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.89      0.89      0.89     10000
weighted avg       0.89      0.89      0.89     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8831
Incorrectly classified: 1169
Test accuracy: 88.31%
              precision    recall  f1-score   support

           0       0.94      0.92      0.93       980
           1       0.98      0.93      0.96      1135
           2       0.88      0.91      0.89      1032
           3       0.84      0.88      0.86      1010
           4       0.89      0.85      0.87       982
           5       0.86      0.79      0.82       892
           6       0.93      0.91      0.92       958
           7       0.89      0.90      0.89      1028
           8       0.83      0.84      0.83       974
           9       0.79      0.88      0.84      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.88      0.88     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8860
Incorrectly classified: 1140
Test accuracy: 88.60%
              precision    recall  f1-score   support

           0       0.94      0.95      0.94       980
           1       0.97      0.96      0.97      1135
           2       0.91      0.90      0.90      1032
           3       0.86      0.84      0.85      1010
           4       0.84      0.86      0.85       982
           5       0.84      0.84      0.84       892
           6       0.90      0.93      0.92       958
           7       0.89      0.92      0.90      1028
           8       0.87      0.83      0.85       974
           9       0.82      0.82      0.82      1009

   micro avg       0.89      0.89      0.89     10000
   macro avg       0.88      0.88      0.88     10000
weighted avg       0.89      0.89      0.89     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

Adversarial test data.
Correctly classified: 9353
Incorrectly classified: 647
Adversarial accuracy: 93.53%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.93      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.92      0.91      0.92       892
           6       0.95      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.93      0.91      0.92       974
           9       0.92      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.94      0.94     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 8, 8, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8639
Incorrectly classified: 1361
Test accuracy: 86.39%
              precision    recall  f1-score   support

           0       0.89      0.92      0.91       980
           1       0.95      0.95      0.95      1135
           2       0.87      0.87      0.87      1032
           3       0.85      0.85      0.85      1010
           4       0.82      0.87      0.85       982
           5       0.80      0.81      0.81       892
           6       0.91      0.90      0.90       958
           7       0.87      0.88      0.88      1028
           8       0.82      0.82      0.82       974
           9       0.83      0.77      0.80      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8646
Incorrectly classified: 1354
Test accuracy: 86.46%
              precision    recall  f1-score   support

           0       0.94      0.93      0.94       980
           1       0.96      0.95      0.95      1135
           2       0.90      0.86      0.88      1032
           3       0.83      0.84      0.84      1010
           4       0.79      0.89      0.84       982
           5       0.81      0.86      0.84       892
           6       0.92      0.90      0.91       958
           7       0.84      0.87      0.85      1028
           8       0.83      0.85      0.84       974
           9       0.82      0.69      0.75      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.86      0.86     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8605
Incorrectly classified: 1395
Test accuracy: 86.05%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.96      1135
           2       0.85      0.86      0.85      1032
           3       0.80      0.82      0.81      1010
           4       0.80      0.87      0.83       982
           5       0.80      0.86      0.83       892
           6       0.94      0.90      0.92       958
           7       0.89      0.88      0.88      1028
           8       0.82      0.79      0.81       974
           9       0.82      0.73      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8566
Incorrectly classified: 1434
Test accuracy: 85.66%
              precision    recall  f1-score   support

           0       0.94      0.92      0.93       980
           1       0.96      0.94      0.95      1135
           2       0.90      0.79      0.84      1032
           3       0.84      0.79      0.81      1010
           4       0.81      0.86      0.84       982
           5       0.78      0.85      0.81       892
           6       0.91      0.90      0.91       958
           7       0.85      0.89      0.87      1028
           8       0.81      0.82      0.81       974
           9       0.77      0.80      0.78      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8620
Incorrectly classified: 1380
Test accuracy: 86.20%
              precision    recall  f1-score   support

           0       0.92      0.91      0.91       980
           1       0.96      0.95      0.96      1135
           2       0.91      0.84      0.87      1032
           3       0.82      0.86      0.84      1010
           4       0.81      0.86      0.83       982
           5       0.80      0.83      0.81       892
           6       0.94      0.85      0.89       958
           7       0.86      0.90      0.88      1028
           8       0.82      0.84      0.83       974
           9       0.79      0.76      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8545
Incorrectly classified: 1455
Test accuracy: 85.45%
              precision    recall  f1-score   support

           0       0.92      0.89      0.91       980
           1       0.96      0.96      0.96      1135
           2       0.87      0.89      0.88      1032
           3       0.82      0.86      0.84      1010
           4       0.77      0.85      0.81       982
           5       0.83      0.80      0.82       892
           6       0.90      0.90      0.90       958
           7       0.83      0.87      0.85      1028
           8       0.83      0.79      0.81       974
           9       0.80      0.70      0.75      1009

   micro avg       0.85      0.85      0.85     10000
   macro avg       0.85      0.85      0.85     10000
weighted avg       0.85      0.85      0.85     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8734
Incorrectly classified: 1266
Test accuracy: 87.34%
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       980
           1       0.96      0.97      0.97      1135
           2       0.92      0.81      0.87      1032
           3       0.83      0.85      0.84      1010
           4       0.80      0.91      0.85       982
           5       0.83      0.85      0.84       892
           6       0.92      0.89      0.90       958
           7       0.89      0.89      0.89      1028
           8       0.79      0.86      0.83       974
           9       0.86      0.77      0.81      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.87      0.87     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8655
Incorrectly classified: 1345
Test accuracy: 86.55%
              precision    recall  f1-score   support

           0       0.92      0.93      0.92       980
           1       0.96      0.96      0.96      1135
           2       0.90      0.86      0.88      1032
           3       0.86      0.84      0.85      1010
           4       0.79      0.87      0.83       982
           5       0.83      0.84      0.83       892
           6       0.88      0.92      0.90       958
           7       0.91      0.83      0.87      1028
           8       0.82      0.84      0.83       974
           9       0.78      0.75      0.76      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8714
Incorrectly classified: 1286
Test accuracy: 87.14%
              precision    recall  f1-score   support

           0       0.95      0.92      0.93       980
           1       0.96      0.96      0.96      1135
           2       0.88      0.85      0.87      1032
           3       0.84      0.85      0.85      1010
           4       0.82      0.86      0.84       982
           5       0.80      0.88      0.84       892
           6       0.88      0.91      0.90       958
           7       0.88      0.90      0.89      1028
           8       0.86      0.79      0.83       974
           9       0.82      0.77      0.80      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8688
Incorrectly classified: 1312
Test accuracy: 86.88%
              precision    recall  f1-score   support

           0       0.91      0.94      0.93       980
           1       0.96      0.96      0.96      1135
           2       0.91      0.80      0.85      1032
           3       0.79      0.87      0.83      1010
           4       0.84      0.89      0.86       982
           5       0.82      0.88      0.85       892
           6       0.92      0.89      0.90       958
           7       0.90      0.88      0.89      1028
           8       0.80      0.79      0.80       974
           9       0.82      0.78      0.80      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.87      0.87      0.87     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8753
Incorrectly classified: 1247
Test accuracy: 87.53%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.97      0.95      0.96      1135
           2       0.85      0.90      0.87      1032
           3       0.85      0.84      0.85      1010
           4       0.85      0.87      0.86       982
           5       0.84      0.84      0.84       892
           6       0.92      0.91      0.91       958
           7       0.90      0.87      0.88      1028
           8       0.82      0.83      0.82       974
           9       0.83      0.80      0.81      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8745
Incorrectly classified: 1255
Test accuracy: 87.45%
              precision    recall  f1-score   support

           0       0.93      0.93      0.93       980
           1       0.97      0.97      0.97      1135
           2       0.88      0.86      0.87      1032
           3       0.80      0.89      0.84      1010
           4       0.86      0.85      0.86       982
           5       0.82      0.85      0.83       892
           6       0.93      0.90      0.91       958
           7       0.86      0.90      0.88      1028
           8       0.89      0.78      0.83       974
           9       0.81      0.81      0.81      1009

   micro avg       0.87      0.87      0.87     10000
   macro avg       0.87      0.87      0.87     10000
weighted avg       0.88      0.87      0.87     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8571
Incorrectly classified: 1429
Test accuracy: 85.71%
              precision    recall  f1-score   support

           0       0.94      0.92      0.93       980
           1       0.96      0.94      0.95      1135
           2       0.81      0.88      0.84      1032
           3       0.84      0.86      0.85      1010
           4       0.75      0.89      0.81       982
           5       0.84      0.84      0.84       892
           6       0.93      0.89      0.91       958
           7       0.85      0.89      0.87      1028
           8       0.83      0.80      0.82       974
           9       0.85      0.65      0.74      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8755
Incorrectly classified: 1245
Test accuracy: 87.55%
              precision    recall  f1-score   support

           0       0.94      0.91      0.93       980
           1       0.97      0.94      0.96      1135
           2       0.86      0.89      0.88      1032
           3       0.86      0.88      0.87      1010
           4       0.84      0.86      0.85       982
           5       0.84      0.84      0.84       892
           6       0.93      0.92      0.92       958
           7       0.88      0.90      0.89      1028
           8       0.84      0.79      0.81       974
           9       0.79      0.81      0.80      1009

   micro avg       0.88      0.88      0.88     10000
   macro avg       0.88      0.87      0.87     10000
weighted avg       0.88      0.88      0.88     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 8, 8, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8642
Incorrectly classified: 1358
Test accuracy: 86.42%
              precision    recall  f1-score   support

           0       0.94      0.94      0.94       980
           1       0.96      0.94      0.95      1135
           2       0.89      0.85      0.87      1032
           3       0.84      0.83      0.83      1010
           4       0.80      0.87      0.83       982
           5       0.79      0.85      0.82       892
           6       0.90      0.93      0.92       958
           7       0.85      0.89      0.87      1028
           8       0.87      0.79      0.83       974
           9       0.80      0.74      0.77      1009

   micro avg       0.86      0.86      0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  15 , size_proj =  12 ) ===

Loading time: --- 39.6764030456543 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)
Correctly classified: 9774
Incorrectly classified: 226
Test accuracy: 97.74%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.97      0.98      0.98       982
           5       0.99      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9627
Incorrectly classified: 373
Test accuracy: 96.27%
              precision    recall  f1-score   support

           0       0.96      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.96      0.96      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.96      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.96      0.95       974
           9       0.96      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9644
Incorrectly classified: 356
Test accuracy: 96.44%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.97      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.97      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9633
Incorrectly classified: 367
Test accuracy: 96.33%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.95      0.95      1010
           4       0.96      0.97      0.97       982
           5       0.95      0.95      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.97      1028
           8       0.95      0.95      0.95       974
           9       0.95      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9601
Incorrectly classified: 399
Test accuracy: 96.01%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.95      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.94      0.96      0.95       892
           6       0.97      0.98      0.97       958
           7       0.96      0.95      0.96      1028
           8       0.95      0.94      0.94       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9615
Incorrectly classified: 385
Test accuracy: 96.15%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.95      0.96      0.96       982
           5       0.96      0.94      0.95       892
           6       0.97      0.97      0.97       958
           7       0.97      0.94      0.96      1028
           8       0.93      0.97      0.95       974
           9       0.95      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9640
Incorrectly classified: 360
Test accuracy: 96.40%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.96      1032
           3       0.95      0.96      0.96      1010
           4       0.97      0.95      0.96       982
           5       0.96      0.96      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.95      0.96       974
           9       0.96      0.95      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9593
Incorrectly classified: 407
Test accuracy: 95.93%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.94      0.95      1032
           3       0.95      0.95      0.95      1010
           4       0.95      0.97      0.96       982
           5       0.94      0.96      0.95       892
           6       0.96      0.98      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.93      0.94      0.94       974
           9       0.97      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9600
Incorrectly classified: 400
Test accuracy: 96.00%
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.96      0.96      1032
           3       0.93      0.96      0.95      1010
           4       0.96      0.96      0.96       982
           5       0.97      0.95      0.96       892
           6       0.97      0.96      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.96      0.94      0.95       974
           9       0.94      0.94      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9610
Incorrectly classified: 390
Test accuracy: 96.10%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.95      1032
           3       0.97      0.94      0.96      1010
           4       0.94      0.98      0.96       982
           5       0.96      0.95      0.95       892
           6       0.96      0.98      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.91      0.96      0.94       974
           9       0.97      0.92      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9624
Incorrectly classified: 376
Test accuracy: 96.24%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.95      0.96      1010
           4       0.95      0.97      0.96       982
           5       0.95      0.96      0.95       892
           6       0.98      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.92      0.95      0.94       974
           9       0.96      0.94      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9638
Incorrectly classified: 362
Test accuracy: 96.38%
              precision    recall  f1-score   support

           0       0.96      0.99      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.95      0.96      0.96      1010
           4       0.95      0.98      0.96       982
           5       0.96      0.96      0.96       892
           6       0.99      0.96      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.95      0.95      0.95       974
           9       0.96      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9618
Incorrectly classified: 382
Test accuracy: 96.18%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.95      0.95      1032
           3       0.95      0.96      0.95      1010
           4       0.95      0.96      0.95       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.96      0.96      0.96      1028
           8       0.96      0.94      0.95       974
           9       0.96      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9604
Incorrectly classified: 396
Test accuracy: 96.04%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.97      0.96      1032
           3       0.95      0.96      0.95      1010
           4       0.96      0.95      0.95       982
           5       0.96      0.96      0.96       892
           6       0.96      0.97      0.97       958
           7       0.97      0.94      0.95      1028
           8       0.95      0.94      0.95       974
           9       0.94      0.95      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9640
Incorrectly classified: 360
Test accuracy: 96.40%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.96      0.96      0.96      1010
           4       0.94      0.98      0.96       982
           5       0.97      0.95      0.96       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.95      0.96      0.95       974
           9       0.97      0.93      0.95      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9617
Incorrectly classified: 383
Test accuracy: 96.17%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.95      0.96      0.96      1032
           3       0.97      0.95      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.95      0.96      0.95       892
           6       0.96      0.97      0.96       958
           7       0.96      0.96      0.96      1028
           8       0.95      0.94      0.95       974
           9       0.95      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 3104
Incorrectly classified: 6896
Adversarial accuracy: 31.04%
              precision    recall  f1-score   support

           0       0.70      0.45      0.55       980
           1       0.00      0.00      0.00      1135
           2       0.52      0.64      0.57      1032
           3       0.35      0.46      0.40      1010
           4       0.22      0.15      0.18       982
           5       0.37      0.28      0.32       892
           6       0.60      0.36      0.45       958
           7       0.58      0.09      0.15      1028
           8       0.16      0.68      0.26       974
           9       0.08      0.05      0.06      1009

   micro avg       0.31      0.31      0.31     10000
   macro avg       0.36      0.32      0.29     10000
weighted avg       0.35      0.31      0.29     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2574
Incorrectly classified: 7426
Test accuracy: 25.74%
              precision    recall  f1-score   support

           0       0.48      0.33      0.39       980
           1       0.18      0.01      0.01      1135
           2       0.34      0.56      0.42      1032
           3       0.25      0.43      0.32      1010
           4       0.20      0.12      0.15       982
           5       0.31      0.25      0.27       892
           6       0.37      0.25      0.30       958
           7       0.55      0.17      0.26      1028
           8       0.14      0.33      0.20       974
           9       0.12      0.17      0.14      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.25     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2743
Incorrectly classified: 7257
Test accuracy: 27.43%
              precision    recall  f1-score   support

           0       0.59      0.29      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.60      0.50      1032
           3       0.33      0.41      0.37      1010
           4       0.22      0.12      0.16       982
           5       0.32      0.30      0.31       892
           6       0.38      0.18      0.25       958
           7       0.35      0.06      0.10      1028
           8       0.17      0.65      0.27       974
           9       0.17      0.16      0.16      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.29      0.28      0.25     10000
weighted avg       0.29      0.27      0.25     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2795
Incorrectly classified: 7205
Test accuracy: 27.95%
              precision    recall  f1-score   support

           0       0.55      0.48      0.51       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.38      0.45      1032
           3       0.25      0.18      0.21      1010
           4       0.26      0.18      0.21       982
           5       0.24      0.39      0.29       892
           6       0.54      0.31      0.39       958
           7       0.53      0.15      0.23      1028
           8       0.16      0.63      0.26       974
           9       0.20      0.15      0.17      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.33      0.29      0.27     10000
weighted avg       0.32      0.28      0.27     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2357
Incorrectly classified: 7643
Test accuracy: 23.57%
              precision    recall  f1-score   support

           0       0.58      0.36      0.44       980
           1       0.04      0.00      0.00      1135
           2       0.32      0.43      0.37      1032
           3       0.22      0.31      0.26      1010
           4       0.24      0.09      0.13       982
           5       0.19      0.27      0.22       892
           6       0.45      0.29      0.35       958
           7       0.41      0.08      0.13      1028
           8       0.13      0.45      0.20       974
           9       0.19      0.13      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.23     10000
weighted avg       0.27      0.24      0.22     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2582
Incorrectly classified: 7418
Test accuracy: 25.82%
              precision    recall  f1-score   support

           0       0.58      0.32      0.41       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.48      0.45      1032
           3       0.39      0.30      0.34      1010
           4       0.20      0.14      0.16       982
           5       0.22      0.31      0.26       892
           6       0.36      0.45      0.40       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.53      0.22       974
           9       0.10      0.05      0.06      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.26      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2413
Incorrectly classified: 7587
Test accuracy: 24.13%
              precision    recall  f1-score   support

           0       0.46      0.35      0.39       980
           1       0.29      0.00      0.00      1135
           2       0.44      0.47      0.46      1032
           3       0.25      0.51      0.33      1010
           4       0.15      0.13      0.14       982
           5       0.25      0.22      0.23       892
           6       0.52      0.22      0.31       958
           7       0.31      0.05      0.09      1028
           8       0.13      0.43      0.20       974
           9       0.11      0.06      0.08      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.22     10000
weighted avg       0.29      0.24      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2367
Incorrectly classified: 7633
Test accuracy: 23.67%
              precision    recall  f1-score   support

           0       0.42      0.17      0.25       980
           1       0.00      0.00      0.00      1135
           2       0.36      0.47      0.41      1032
           3       0.22      0.52      0.31      1010
           4       0.18      0.09      0.12       982
           5       0.18      0.09      0.12       892
           6       0.64      0.29      0.40       958
           7       0.50      0.11      0.17      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.16      0.15      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.28      0.24      0.22     10000
weighted avg       0.28      0.24      0.21     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2688
Incorrectly classified: 7312
Test accuracy: 26.88%
              precision    recall  f1-score   support

           0       0.62      0.26      0.37       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.51      0.49      1032
           3       0.32      0.35      0.33      1010
           4       0.21      0.31      0.25       982
           5       0.28      0.26      0.27       892
           6       0.38      0.31      0.34       958
           7       0.46      0.06      0.11      1028
           8       0.17      0.63      0.26       974
           9       0.08      0.04      0.05      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.30      0.27      0.25     10000
weighted avg       0.30      0.27      0.24     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2494
Incorrectly classified: 7506
Test accuracy: 24.94%
              precision    recall  f1-score   support

           0       0.58      0.31      0.40       980
           1       0.20      0.00      0.00      1135
           2       0.38      0.39      0.39      1032
           3       0.23      0.12      0.16      1010
           4       0.25      0.22      0.24       982
           5       0.22      0.40      0.28       892
           6       0.36      0.42      0.39       958
           7       0.58      0.08      0.14      1028
           8       0.16      0.58      0.25       974
           9       0.09      0.04      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.23     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2662
Incorrectly classified: 7338
Test accuracy: 26.62%
              precision    recall  f1-score   support

           0       0.46      0.30      0.36       980
           1       0.00      0.00      0.00      1135
           2       0.39      0.53      0.45      1032
           3       0.29      0.23      0.26      1010
           4       0.20      0.12      0.15       982
           5       0.29      0.42      0.34       892
           6       0.27      0.32      0.29       958
           7       0.52      0.11      0.19      1028
           8       0.17      0.61      0.27       974
           9       0.16      0.09      0.11      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.28      0.27      0.24     10000
weighted avg       0.27      0.27      0.24     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2495
Incorrectly classified: 7505
Test accuracy: 24.95%
              precision    recall  f1-score   support

           0       0.50      0.40      0.44       980
           1       0.12      0.00      0.01      1135
           2       0.36      0.43      0.39      1032
           3       0.28      0.33      0.30      1010
           4       0.29      0.18      0.22       982
           5       0.21      0.08      0.12       892
           6       0.53      0.20      0.30       958
           7       0.39      0.09      0.14      1028
           8       0.15      0.59      0.24       974
           9       0.15      0.22      0.18      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.25      0.23     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2791
Incorrectly classified: 7209
Test accuracy: 27.91%
              precision    recall  f1-score   support

           0       0.53      0.39      0.45       980
           1       0.00      0.00      0.00      1135
           2       0.43      0.47      0.45      1032
           3       0.26      0.41      0.32      1010
           4       0.26      0.22      0.24       982
           5       0.25      0.26      0.25       892
           6       0.35      0.13      0.19       958
           7       0.26      0.25      0.26      1028
           8       0.22      0.40      0.28       974
           9       0.18      0.30      0.23      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.27      0.28      0.27     10000
weighted avg       0.27      0.28      0.26     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2393
Incorrectly classified: 7607
Test accuracy: 23.93%
              precision    recall  f1-score   support

           0       0.66      0.18      0.28       980
           1       0.00      0.00      0.00      1135
           2       0.28      0.67      0.39      1032
           3       0.28      0.41      0.34      1010
           4       0.19      0.13      0.16       982
           5       0.31      0.16      0.21       892
           6       0.57      0.24      0.34       958
           7       0.33      0.06      0.10      1028
           8       0.12      0.44      0.19       974
           9       0.20      0.10      0.14      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.29      0.24      0.22     10000
weighted avg       0.29      0.24      0.21     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2533
Incorrectly classified: 7467
Test accuracy: 25.33%
              precision    recall  f1-score   support

           0       0.58      0.22      0.32       980
           1       0.11      0.00      0.01      1135
           2       0.30      0.54      0.39      1032
           3       0.26      0.36      0.30      1010
           4       0.33      0.16      0.21       982
           5       0.21      0.18      0.19       892
           6       0.48      0.31      0.37       958
           7       0.47      0.14      0.22      1028
           8       0.14      0.51      0.21       974
           9       0.26      0.14      0.18      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.26      0.24     10000
weighted avg       0.31      0.25      0.24     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2806
Incorrectly classified: 7194
Test accuracy: 28.06%
              precision    recall  f1-score   support

           0       0.56      0.40      0.47       980
           1       0.00      0.00      0.00      1135
           2       0.23      0.48      0.32      1032
           3       0.28      0.44      0.34      1010
           4       0.33      0.33      0.33       982
           5       0.18      0.29      0.22       892
           6       0.35      0.34      0.35       958
           7       0.36      0.21      0.26      1028
           8       0.24      0.24      0.24       974
           9       0.18      0.11      0.13      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.27      0.28      0.27     10000
weighted avg       0.27      0.28      0.26     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 6384
Incorrectly classified: 3616
Adversarial accuracy: 63.84%
              precision    recall  f1-score   support

           0       0.90      0.87      0.88       980
           1       0.90      0.13      0.22      1135
           2       0.55      0.87      0.67      1032
           3       0.64      0.79      0.71      1010
           4       0.58      0.69      0.63       982
           5       0.73      0.62      0.67       892
           6       0.86      0.80      0.83       958
           7       0.88      0.60      0.71      1028
           8       0.41      0.82      0.55       974
           9       0.54      0.29      0.38      1009

   micro avg       0.64      0.64      0.64     10000
   macro avg       0.70      0.65      0.62     10000
weighted avg       0.70      0.64      0.62     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5698
Incorrectly classified: 4302
Test accuracy: 56.98%
              precision    recall  f1-score   support

           0       0.74      0.84      0.79       980
           1       0.91      0.19      0.31      1135
           2       0.55      0.81      0.65      1032
           3       0.53      0.60      0.56      1010
           4       0.53      0.36      0.43       982
           5       0.54      0.50      0.52       892
           6       0.73      0.68      0.71       958
           7       0.78      0.59      0.67      1028
           8       0.43      0.66      0.52       974
           9       0.40      0.52      0.45      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.61      0.57      0.56     10000
weighted avg       0.62      0.57      0.56     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5208
Incorrectly classified: 4792
Test accuracy: 52.08%
              precision    recall  f1-score   support

           0       0.83      0.75      0.79       980
           1       0.90      0.05      0.09      1135
           2       0.41      0.86      0.56      1032
           3       0.53      0.66      0.59      1010
           4       0.72      0.25      0.37       982
           5       0.52      0.64      0.58       892
           6       0.86      0.56      0.68       958
           7       0.76      0.33      0.47      1028
           8       0.31      0.74      0.44       974
           9       0.51      0.45      0.48      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.64      0.53      0.50     10000
weighted avg       0.64      0.52      0.50     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5925
Incorrectly classified: 4075
Test accuracy: 59.25%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.95      0.40      0.56      1135
           2       0.56      0.72      0.63      1032
           3       0.78      0.37      0.50      1010
           4       0.48      0.69      0.57       982
           5       0.44      0.71      0.54       892
           6       0.72      0.79      0.75       958
           7       0.83      0.61      0.70      1028
           8       0.44      0.72      0.55       974
           9       0.39      0.27      0.32      1009

   micro avg       0.59      0.59      0.59     10000
   macro avg       0.65      0.60      0.59     10000
weighted avg       0.65      0.59      0.59     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5253
Incorrectly classified: 4747
Test accuracy: 52.53%
              precision    recall  f1-score   support

           0       0.92      0.63      0.75       980
           1       0.85      0.24      0.37      1135
           2       0.49      0.74      0.59      1032
           3       0.54      0.57      0.55      1010
           4       0.54      0.57      0.56       982
           5       0.48      0.37      0.42       892
           6       0.75      0.67      0.71       958
           7       0.80      0.41      0.54      1028
           8       0.31      0.78      0.44       974
           9       0.39      0.31      0.35      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.53     10000
weighted avg       0.61      0.53      0.53     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4883
Incorrectly classified: 5117
Test accuracy: 48.83%
              precision    recall  f1-score   support

           0       0.90      0.66      0.76       980
           1       0.86      0.10      0.19      1135
           2       0.53      0.71      0.61      1032
           3       0.51      0.52      0.51      1010
           4       0.49      0.45      0.47       982
           5       0.44      0.50      0.47       892
           6       0.83      0.62      0.71       958
           7       0.84      0.35      0.49      1028
           8       0.25      0.80      0.39       974
           9       0.40      0.24      0.31      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.49     10000
weighted avg       0.61      0.49      0.48     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5136
Incorrectly classified: 4864
Test accuracy: 51.36%
              precision    recall  f1-score   support

           0       0.80      0.63      0.70       980
           1       0.91      0.18      0.30      1135
           2       0.51      0.66      0.58      1032
           3       0.42      0.84      0.56      1010
           4       0.45      0.64      0.52       982
           5       0.57      0.51      0.54       892
           6       0.77      0.63      0.69       958
           7       0.81      0.30      0.44      1028
           8       0.34      0.61      0.44       974
           9       0.35      0.19      0.25      1009

   micro avg       0.51      0.51      0.51     10000
   macro avg       0.59      0.52      0.50     10000
weighted avg       0.60      0.51      0.50     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4906
Incorrectly classified: 5094
Test accuracy: 49.06%
              precision    recall  f1-score   support

           0       0.78      0.80      0.79       980
           1       0.82      0.07      0.12      1135
           2       0.55      0.58      0.57      1032
           3       0.29      0.89      0.44      1010
           4       0.55      0.39      0.46       982
           5       0.54      0.31      0.39       892
           6       0.87      0.51      0.65       958
           7       0.74      0.43      0.55      1028
           8       0.39      0.58      0.47       974
           9       0.44      0.38      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.49      0.48     10000
weighted avg       0.60      0.49      0.48     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5616
Incorrectly classified: 4384
Test accuracy: 56.16%
              precision    recall  f1-score   support

           0       0.87      0.76      0.81       980
           1       0.92      0.16      0.27      1135
           2       0.48      0.81      0.60      1032
           3       0.53      0.65      0.58      1010
           4       0.48      0.73      0.58       982
           5       0.57      0.50      0.53       892
           6       0.75      0.71      0.73       958
           7       0.84      0.49      0.61      1028
           8       0.39      0.73      0.51       974
           9       0.37      0.13      0.19      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.62      0.57      0.54     10000
weighted avg       0.62      0.56      0.54     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5027
Incorrectly classified: 4973
Test accuracy: 50.27%
              precision    recall  f1-score   support

           0       0.86      0.78      0.82       980
           1       0.94      0.16      0.28      1135
           2       0.62      0.71      0.66      1032
           3       0.47      0.18      0.26      1010
           4       0.58      0.47      0.52       982
           5       0.38      0.67      0.49       892
           6       0.79      0.69      0.74       958
           7       0.87      0.29      0.43      1028
           8       0.26      0.87      0.40       974
           9       0.55      0.30      0.39      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.63      0.51      0.50     10000
weighted avg       0.64      0.50      0.49     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5627
Incorrectly classified: 4373
Test accuracy: 56.27%
              precision    recall  f1-score   support

           0       0.84      0.70      0.76       980
           1       0.91      0.17      0.28      1135
           2       0.55      0.78      0.64      1032
           3       0.58      0.44      0.50      1010
           4       0.57      0.58      0.58       982
           5       0.46      0.74      0.57       892
           6       0.71      0.74      0.73       958
           7       0.73      0.55      0.63      1028
           8       0.36      0.74      0.49       974
           9       0.50      0.28      0.36      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.62      0.57      0.55     10000
weighted avg       0.63      0.56      0.55     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5456
Incorrectly classified: 4544
Test accuracy: 54.56%
              precision    recall  f1-score   support

           0       0.74      0.80      0.77       980
           1       0.86      0.29      0.43      1135
           2       0.53      0.72      0.61      1032
           3       0.55      0.67      0.61      1010
           4       0.60      0.61      0.60       982
           5       0.61      0.30      0.40       892
           6       0.77      0.59      0.67       958
           7       0.80      0.42      0.55      1028
           8       0.30      0.75      0.43       974
           9       0.42      0.33      0.37      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.55      0.54     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5514
Incorrectly classified: 4486
Test accuracy: 55.14%
              precision    recall  f1-score   support

           0       0.86      0.76      0.81       980
           1       0.92      0.07      0.13      1135
           2       0.40      0.81      0.53      1032
           3       0.42      0.75      0.54      1010
           4       0.65      0.49      0.56       982
           5       0.58      0.52      0.55       892
           6       0.77      0.66      0.71       958
           7       0.64      0.54      0.59      1028
           8       0.49      0.56      0.52       974
           9       0.52      0.41      0.46      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.63      0.56      0.54     10000
weighted avg       0.63      0.55      0.53     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5212
Incorrectly classified: 4788
Test accuracy: 52.12%
              precision    recall  f1-score   support

           0       0.92      0.51      0.65       980
           1       0.89      0.14      0.25      1135
           2       0.33      0.84      0.47      1032
           3       0.53      0.72      0.61      1010
           4       0.54      0.45      0.49       982
           5       0.69      0.24      0.35       892
           6       0.79      0.69      0.73       958
           7       0.77      0.60      0.68      1028
           8       0.37      0.67      0.48       974
           9       0.52      0.36      0.43      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.63      0.52      0.51     10000
weighted avg       0.63      0.52      0.51     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5812
Incorrectly classified: 4188
Test accuracy: 58.12%
              precision    recall  f1-score   support

           0       0.88      0.76      0.82       980
           1       0.90      0.38      0.53      1135
           2       0.43      0.75      0.55      1032
           3       0.56      0.71      0.63      1010
           4       0.54      0.45      0.49       982
           5       0.72      0.31      0.43       892
           6       0.79      0.74      0.76       958
           7       0.78      0.56      0.65      1028
           8       0.41      0.76      0.53       974
           9       0.43      0.39      0.41      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.64      0.58      0.58     10000
weighted avg       0.64      0.58      0.58     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5538
Incorrectly classified: 4462
Test accuracy: 55.38%
              precision    recall  f1-score   support

           0       0.90      0.74      0.82       980
           1       0.85      0.09      0.17      1135
           2       0.41      0.73      0.52      1032
           3       0.45      0.77      0.57      1010
           4       0.46      0.86      0.60       982
           5       0.56      0.65      0.60       892
           6       0.77      0.69      0.73       958
           7       0.73      0.61      0.67      1028
           8       0.59      0.37      0.45       974
           9       0.31      0.09      0.14      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.60      0.56      0.53     10000
weighted avg       0.61      0.55      0.52     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9580
Incorrectly classified: 420
Adversarial accuracy: 95.80%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.96      0.96      1032
           3       0.96      0.94      0.95      1010
           4       0.94      0.96      0.95       982
           5       0.97      0.94      0.96       892
           6       0.96      0.97      0.96       958
           7       0.96      0.95      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.94      0.93      0.94      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9264
Incorrectly classified: 736
Test accuracy: 92.64%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.91      0.91      1010
           4       0.92      0.91      0.92       982
           5       0.92      0.88      0.90       892
           6       0.94      0.94      0.94       958
           7       0.96      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.89      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.96      0.97      1135
           2       0.92      0.94      0.93      1032
           3       0.87      0.92      0.90      1010
           4       0.93      0.91      0.92       982
           5       0.94      0.88      0.91       892
           6       0.94      0.94      0.94       958
           7       0.93      0.92      0.92      1028
           8       0.86      0.91      0.88       974
           9       0.89      0.88      0.89      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9235
Incorrectly classified: 765
Test accuracy: 92.35%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.93      0.94      1032
           3       0.92      0.88      0.90      1010
           4       0.87      0.94      0.91       982
           5       0.90      0.90      0.90       892
           6       0.95      0.94      0.95       958
           7       0.95      0.93      0.94      1028
           8       0.89      0.91      0.90       974
           9       0.89      0.85      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9206
Incorrectly classified: 794
Test accuracy: 92.06%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.87      0.88      1010
           4       0.91      0.92      0.92       982
           5       0.88      0.91      0.89       892
           6       0.93      0.96      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.89      0.89      0.89       974
           9       0.89      0.87      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9192
Incorrectly classified: 808
Test accuracy: 91.92%
              precision    recall  f1-score   support

           0       0.95      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.90      0.90      0.90      1010
           4       0.90      0.90      0.90       982
           5       0.91      0.86      0.89       892
           6       0.94      0.94      0.94       958
           7       0.95      0.91      0.92      1028
           8       0.85      0.94      0.89       974
           9       0.87      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9230
Incorrectly classified: 770
Test accuracy: 92.30%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.89      0.91      0.90      1010
           4       0.90      0.91      0.90       982
           5       0.93      0.87      0.90       892
           6       0.93      0.96      0.94       958
           7       0.95      0.91      0.93      1028
           8       0.89      0.91      0.90       974
           9       0.88      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9215
Incorrectly classified: 785
Test accuracy: 92.15%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.91      0.93      1032
           3       0.88      0.90      0.89      1010
           4       0.90      0.93      0.91       982
           5       0.90      0.89      0.89       892
           6       0.93      0.97      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.87      0.90      0.88       974
           9       0.91      0.86      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9214
Incorrectly classified: 786
Test accuracy: 92.14%
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.98      0.97      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.88      0.92      0.90      1010
           4       0.92      0.89      0.90       982
           5       0.94      0.88      0.91       892
           6       0.94      0.93      0.93       958
           7       0.94      0.91      0.93      1028
           8       0.90      0.89      0.89       974
           9       0.86      0.89      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9161
Incorrectly classified: 839
Test accuracy: 91.61%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.93      0.92      0.92      1032
           3       0.93      0.84      0.88      1010
           4       0.86      0.95      0.90       982
           5       0.91      0.86      0.88       892
           6       0.93      0.95      0.94       958
           7       0.94      0.93      0.94      1028
           8       0.81      0.94      0.87       974
           9       0.93      0.82      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.91     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9236
Incorrectly classified: 764
Test accuracy: 92.36%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.99      0.97      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.92      0.89      0.90      1010
           4       0.87      0.94      0.90       982
           5       0.92      0.90      0.91       892
           6       0.94      0.94      0.94       958
           7       0.95      0.92      0.93      1028
           8       0.85      0.93      0.89       974
           9       0.91      0.84      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9216
Incorrectly classified: 784
Test accuracy: 92.16%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.99      0.98      0.98      1135
           2       0.93      0.94      0.94      1032
           3       0.87      0.93      0.90      1010
           4       0.88      0.95      0.91       982
           5       0.92      0.86      0.89       892
           6       0.96      0.93      0.95       958
           7       0.94      0.91      0.92      1028
           8       0.90      0.89      0.89       974
           9       0.90      0.85      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9229
Incorrectly classified: 771
Test accuracy: 92.29%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.92      0.93      0.92      1032
           3       0.88      0.90      0.89      1010
           4       0.88      0.92      0.90       982
           5       0.92      0.88      0.90       892
           6       0.93      0.94      0.93       958
           7       0.93      0.94      0.94      1028
           8       0.91      0.89      0.90       974
           9       0.91      0.86      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9217
Incorrectly classified: 783
Test accuracy: 92.17%
              precision    recall  f1-score   support

           0       0.97      0.95      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.90      0.94      0.92      1032
           3       0.90      0.89      0.89      1010
           4       0.92      0.91      0.91       982
           5       0.93      0.88      0.90       892
           6       0.93      0.96      0.94       958
           7       0.94      0.91      0.92      1028
           8       0.87      0.91      0.89       974
           9       0.88      0.90      0.89      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9274
Incorrectly classified: 726
Test accuracy: 92.74%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.94      0.93      1032
           3       0.91      0.90      0.90      1010
           4       0.87      0.95      0.91       982
           5       0.94      0.87      0.90       892
           6       0.94      0.95      0.95       958
           7       0.94      0.93      0.94      1028
           8       0.88      0.93      0.91       974
           9       0.91      0.84      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9205
Incorrectly classified: 795
Test accuracy: 92.05%
              precision    recall  f1-score   support

           0       0.95      0.98      0.97       980
           1       0.98      0.96      0.97      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.89      0.90      1010
           4       0.88      0.92      0.90       982
           5       0.91      0.89      0.90       892
           6       0.93      0.94      0.94       958
           7       0.92      0.93      0.92      1028
           8       0.90      0.90      0.90       974
           9       0.88      0.86      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

Adversarial test data.
Correctly classified: 9456
Incorrectly classified: 544
Adversarial accuracy: 94.56%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.95      0.94      0.94      1010
           4       0.90      0.95      0.93       982
           5       0.95      0.95      0.95       892
           6       0.95      0.96      0.96       958
           7       0.94      0.94      0.94      1028
           8       0.94      0.94      0.94       974
           9       0.93      0.87      0.90      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 12, 12, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9108
Incorrectly classified: 892
Test accuracy: 91.08%
              precision    recall  f1-score   support

           0       0.93      0.96      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.92      0.91      1032
           3       0.90      0.88      0.89      1010
           4       0.87      0.91      0.89       982
           5       0.87      0.91      0.89       892
           6       0.94      0.94      0.94       958
           7       0.93      0.90      0.92      1028
           8       0.90      0.89      0.89       974
           9       0.88      0.83      0.85      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9065
Incorrectly classified: 935
Test accuracy: 90.65%
              precision    recall  f1-score   support

           0       0.95      0.94      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.89      0.92      0.91      1032
           3       0.86      0.90      0.88      1010
           4       0.89      0.91      0.90       982
           5       0.89      0.90      0.90       892
           6       0.94      0.94      0.94       958
           7       0.90      0.91      0.90      1028
           8       0.87      0.88      0.87       974
           9       0.89      0.80      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9051
Incorrectly classified: 949
Test accuracy: 90.51%
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.94      0.91      0.92      1032
           3       0.90      0.88      0.89      1010
           4       0.83      0.92      0.88       982
           5       0.86      0.90      0.88       892
           6       0.94      0.93      0.94       958
           7       0.92      0.92      0.92      1028
           8       0.90      0.87      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.91      0.91      0.90     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8988
Incorrectly classified: 1012
Test accuracy: 89.88%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.90      0.91      0.90      1032
           3       0.89      0.85      0.87      1010
           4       0.87      0.90      0.88       982
           5       0.82      0.91      0.86       892
           6       0.92      0.96      0.94       958
           7       0.90      0.91      0.91      1028
           8       0.90      0.84      0.87       974
           9       0.86      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9010
Incorrectly classified: 990
Test accuracy: 90.10%
              precision    recall  f1-score   support

           0       0.95      0.94      0.94       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.90      0.91      1032
           3       0.88      0.89      0.88      1010
           4       0.85      0.88      0.86       982
           5       0.87      0.88      0.88       892
           6       0.94      0.93      0.93       958
           7       0.92      0.90      0.91      1028
           8       0.86      0.91      0.88       974
           9       0.85      0.80      0.83      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9027
Incorrectly classified: 973
Test accuracy: 90.27%
              precision    recall  f1-score   support

           0       0.93      0.97      0.95       980
           1       0.98      0.96      0.97      1135
           2       0.90      0.90      0.90      1032
           3       0.87      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.90      0.89      0.90       892
           6       0.91      0.96      0.93       958
           7       0.92      0.89      0.90      1028
           8       0.90      0.87      0.89       974
           9       0.86      0.78      0.82      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9071
Incorrectly classified: 929
Test accuracy: 90.71%
              precision    recall  f1-score   support

           0       0.95      0.95      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.89      0.91      1032
           3       0.89      0.89      0.89      1010
           4       0.85      0.92      0.88       982
           5       0.87      0.92      0.89       892
           6       0.92      0.96      0.94       958
           7       0.91      0.92      0.91      1028
           8       0.88      0.88      0.88       974
           9       0.91      0.78      0.84      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9059
Incorrectly classified: 941
Test accuracy: 90.59%
              precision    recall  f1-score   support

           0       0.92      0.98      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.92      0.91      0.92      1032
           3       0.86      0.91      0.89      1010
           4       0.85      0.89      0.87       982
           5       0.91      0.89      0.90       892
           6       0.93      0.93      0.93       958
           7       0.92      0.91      0.91      1028
           8       0.92      0.84      0.88       974
           9       0.86      0.81      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.90      0.90     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9075
Incorrectly classified: 925
Test accuracy: 90.75%
              precision    recall  f1-score   support

           0       0.96      0.95      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.92      0.87      0.89      1010
           4       0.83      0.94      0.88       982
           5       0.89      0.89      0.89       892
           6       0.93      0.94      0.93       958
           7       0.92      0.93      0.93      1028
           8       0.84      0.91      0.87       974
           9       0.90      0.77      0.83      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9011
Incorrectly classified: 989
Test accuracy: 90.11%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.97      0.96      0.97      1135
           2       0.92      0.91      0.92      1032
           3       0.90      0.88      0.89      1010
           4       0.78      0.92      0.85       982
           5       0.89      0.91      0.90       892
           6       0.93      0.94      0.94       958
           7       0.92      0.90      0.91      1028
           8       0.87      0.90      0.89       974
           9       0.87      0.71      0.78      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 8989
Incorrectly classified: 1011
Test accuracy: 89.89%
              precision    recall  f1-score   support

           0       0.92      0.95      0.94       980
           1       0.97      0.98      0.97      1135
           2       0.91      0.90      0.90      1032
           3       0.86      0.91      0.88      1010
           4       0.80      0.93      0.86       982
           5       0.88      0.89      0.89       892
           6       0.95      0.93      0.94       958
           7       0.92      0.89      0.90      1028
           8       0.91      0.86      0.88       974
           9       0.87      0.74      0.80      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9017
Incorrectly classified: 983
Test accuracy: 90.17%
              precision    recall  f1-score   support

           0       0.97      0.94      0.96       980
           1       0.96      0.98      0.97      1135
           2       0.92      0.91      0.91      1032
           3       0.86      0.89      0.88      1010
           4       0.82      0.92      0.87       982
           5       0.87      0.88      0.88       892
           6       0.93      0.94      0.93       958
           7       0.89      0.92      0.91      1028
           8       0.92      0.87      0.89       974
           9       0.89      0.75      0.82      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9025
Incorrectly classified: 975
Test accuracy: 90.25%
              precision    recall  f1-score   support

           0       0.97      0.93      0.95       980
           1       0.97      0.97      0.97      1135
           2       0.89      0.92      0.90      1032
           3       0.88      0.89      0.88      1010
           4       0.86      0.89      0.87       982
           5       0.88      0.89      0.89       892
           6       0.92      0.94      0.93       958
           7       0.90      0.90      0.90      1028
           8       0.89      0.87      0.88       974
           9       0.85      0.82      0.84      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9067
Incorrectly classified: 933
Test accuracy: 90.67%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.97      0.98      0.97      1135
           2       0.91      0.88      0.90      1032
           3       0.90      0.88      0.89      1010
           4       0.81      0.94      0.87       982
           5       0.90      0.90      0.90       892
           6       0.92      0.95      0.94       958
           7       0.91      0.92      0.91      1028
           8       0.89      0.90      0.89       974
           9       0.89      0.75      0.81      1009

   micro avg       0.91      0.91      0.91     10000
   macro avg       0.91      0.91      0.91     10000
weighted avg       0.91      0.91      0.91     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 12, 12, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9015
Incorrectly classified: 985
Test accuracy: 90.15%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.95      0.96      1135
           2       0.90      0.92      0.91      1032
           3       0.91      0.89      0.90      1010
           4       0.81      0.90      0.85       982
           5       0.87      0.90      0.89       892
           6       0.93      0.93      0.93       958
           7       0.90      0.91      0.90      1028
           8       0.91      0.87      0.89       974
           9       0.85      0.76      0.80      1009

   micro avg       0.90      0.90      0.90     10000
   macro avg       0.90      0.90      0.90     10000
weighted avg       0.90      0.90      0.90     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  15 , size_proj =  16 ) ===

Loading time: --- 43.922534227371216 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)
Correctly classified: 9813
Incorrectly classified: 187
Test accuracy: 98.13%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.99      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.99      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9706
Incorrectly classified: 294
Test accuracy: 97.06%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.96      0.98      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9713
Incorrectly classified: 287
Test accuracy: 97.13%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.96      0.98      0.97       958
           7       0.99      0.97      0.98      1028
           8       0.96      0.96      0.96       974
           9       0.96      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.97      0.96       892
           6       0.97      0.98      0.97       958
           7       0.96      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9705
Incorrectly classified: 295
Test accuracy: 97.05%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.97      1028
           8       0.96      0.95      0.96       974
           9       0.95      0.96      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9708
Incorrectly classified: 292
Test accuracy: 97.08%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.97      0.98      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.95      0.95       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9721
Incorrectly classified: 279
Test accuracy: 97.21%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.99      0.96      0.97       892
           6       0.97      0.97      0.97       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9711
Incorrectly classified: 289
Test accuracy: 97.11%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.95      0.98      0.96       892
           6       0.97      0.98      0.97       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.95      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9726
Incorrectly classified: 274
Test accuracy: 97.26%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.97      0.96      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.96      0.97      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9742
Incorrectly classified: 258
Test accuracy: 97.42%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.98      0.97      0.98       958
           7       0.97      0.98      0.98      1028
           8       0.96      0.97      0.97       974
           9       0.98      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9739
Incorrectly classified: 261
Test accuracy: 97.39%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.98      0.97      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.97      0.97      0.97       892
           6       0.99      0.97      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.97      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9722
Incorrectly classified: 278
Test accuracy: 97.22%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.95      0.96      0.96       974
           9       0.97      0.95      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9715
Incorrectly classified: 285
Test accuracy: 97.15%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.97      0.97      1010
           4       0.98      0.95      0.96       982
           5       0.99      0.96      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.97      1028
           8       0.95      0.97      0.96       974
           9       0.96      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9734
Incorrectly classified: 266
Test accuracy: 97.34%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.97      1032
           3       0.98      0.96      0.97      1010
           4       0.97      0.98      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.97      0.97       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9720
Incorrectly classified: 280
Test accuracy: 97.20%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.97      0.97      1010
           4       0.98      0.96      0.97       982
           5       0.97      0.98      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.95      0.97      0.96       974
           9       0.96      0.96      0.96      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 2797
Incorrectly classified: 7203
Adversarial accuracy: 27.97%
              precision    recall  f1-score   support

           0       0.66      0.37      0.48       980
           1       0.00      0.00      0.00      1135
           2       0.53      0.51      0.52      1032
           3       0.34      0.40      0.36      1010
           4       0.19      0.10      0.13       982
           5       0.35      0.31      0.33       892
           6       0.61      0.34      0.44       958
           7       0.46      0.04      0.07      1028
           8       0.15      0.70      0.24       974
           9       0.12      0.08      0.10      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.34      0.29      0.27     10000
weighted avg       0.34      0.28      0.26     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2635
Incorrectly classified: 7365
Test accuracy: 26.35%
              precision    recall  f1-score   support

           0       0.58      0.33      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.61      0.42      1032
           3       0.24      0.32      0.28      1010
           4       0.23      0.15      0.19       982
           5       0.31      0.34      0.32       892
           6       0.35      0.35      0.35       958
           7       0.53      0.06      0.11      1028
           8       0.14      0.35      0.20       974
           9       0.16      0.16      0.16      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.27      0.25     10000
weighted avg       0.28      0.26      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2529
Incorrectly classified: 7471
Test accuracy: 25.29%
              precision    recall  f1-score   support

           0       0.61      0.24      0.35       980
           1       0.09      0.00      0.00      1135
           2       0.47      0.47      0.47      1032
           3       0.35      0.27      0.31      1010
           4       0.22      0.13      0.17       982
           5       0.29      0.28      0.28       892
           6       0.43      0.34      0.38       958
           7       0.25      0.01      0.02      1028
           8       0.14      0.57      0.22       974
           9       0.18      0.25      0.21      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2731
Incorrectly classified: 7269
Test accuracy: 27.31%
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       980
           1       0.11      0.00      0.00      1135
           2       0.56      0.21      0.31      1032
           3       0.24      0.31      0.27      1010
           4       0.37      0.22      0.27       982
           5       0.25      0.40      0.31       892
           6       0.45      0.25      0.32       958
           7       0.43      0.05      0.09      1028
           8       0.16      0.61      0.25       974
           9       0.30      0.34      0.32      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.34      0.28      0.26     10000
weighted avg       0.34      0.27      0.25     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2264
Incorrectly classified: 7736
Test accuracy: 22.64%
              precision    recall  f1-score   support

           0       0.56      0.25      0.34       980
           1       0.06      0.00      0.00      1135
           2       0.33      0.46      0.38      1032
           3       0.24      0.33      0.28      1010
           4       0.26      0.08      0.12       982
           5       0.22      0.17      0.19       892
           6       0.54      0.28      0.37       958
           7       0.34      0.06      0.11      1028
           8       0.12      0.51      0.19       974
           9       0.18      0.15      0.17      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.29      0.23      0.21     10000
weighted avg       0.28      0.23      0.21     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2685
Incorrectly classified: 7315
Test accuracy: 26.85%
              precision    recall  f1-score   support

           0       0.70      0.24      0.35       980
           1       1.00      0.00      0.00      1135
           2       0.44      0.57      0.50      1032
           3       0.33      0.37      0.35      1010
           4       0.22      0.15      0.18       982
           5       0.32      0.31      0.32       892
           6       0.48      0.34      0.40       958
           7       0.57      0.09      0.15      1028
           8       0.14      0.56      0.22       974
           9       0.12      0.10      0.11      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.43      0.27      0.26     10000
weighted avg       0.44      0.27      0.25     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2505
Incorrectly classified: 7495
Test accuracy: 25.05%
              precision    recall  f1-score   support

           0       0.57      0.21      0.31       980
           1       0.00      0.00      0.00      1135
           2       0.33      0.59      0.42      1032
           3       0.24      0.51      0.33      1010
           4       0.16      0.10      0.12       982
           5       0.21      0.36      0.27       892
           6       0.48      0.27      0.34       958
           7       0.47      0.08      0.13      1028
           8       0.15      0.35      0.21       974
           9       0.15      0.08      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.28      0.25      0.22     10000
weighted avg       0.27      0.25      0.22     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2486
Incorrectly classified: 7514
Test accuracy: 24.86%
              precision    recall  f1-score   support

           0       0.58      0.29      0.38       980
           1       0.00      0.00      0.00      1135
           2       0.50      0.45      0.48      1032
           3       0.33      0.44      0.38      1010
           4       0.14      0.08      0.10       982
           5       0.39      0.24      0.29       892
           6       0.48      0.34      0.40       958
           7       0.45      0.03      0.05      1028
           8       0.13      0.62      0.22       974
           9       0.05      0.05      0.05      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.30      0.25      0.23     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2547
Incorrectly classified: 7453
Test accuracy: 25.47%
              precision    recall  f1-score   support

           0       0.59      0.27      0.37       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.53      0.44      1032
           3       0.23      0.26      0.25      1010
           4       0.20      0.15      0.17       982
           5       0.21      0.31      0.25       892
           6       0.50      0.33      0.40       958
           7       0.49      0.08      0.14      1028
           8       0.16      0.59      0.25       974
           9       0.15      0.07      0.10      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.29      0.26      0.24     10000
weighted avg       0.29      0.25      0.23     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2628
Incorrectly classified: 7372
Test accuracy: 26.28%
              precision    recall  f1-score   support

           0       0.54      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.47      0.41      1032
           3       0.31      0.21      0.25      1010
           4       0.25      0.17      0.20       982
           5       0.25      0.32      0.28       892
           6       0.52      0.34      0.41       958
           7       0.54      0.18      0.27      1028
           8       0.13      0.55      0.21       974
           9       0.22      0.14      0.17      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.31      0.27      0.26     10000
weighted avg       0.31      0.26      0.26     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2333
Incorrectly classified: 7667
Test accuracy: 23.33%
              precision    recall  f1-score   support

           0       0.54      0.33      0.41       980
           1       0.00      0.00      0.00      1135
           2       0.42      0.30      0.35      1032
           3       0.28      0.35      0.31      1010
           4       0.17      0.09      0.12       982
           5       0.38      0.29      0.33       892
           6       0.52      0.12      0.19       958
           7       0.51      0.03      0.06      1028
           8       0.14      0.80      0.24       974
           9       0.17      0.06      0.09      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.31      0.24      0.21     10000
weighted avg       0.31      0.23      0.21     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2223
Incorrectly classified: 7777
Test accuracy: 22.23%
              precision    recall  f1-score   support

           0       0.64      0.28      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.29      0.36      1032
           3       0.22      0.35      0.27      1010
           4       0.13      0.05      0.07       982
           5       0.25      0.16      0.20       892
           6       0.57      0.08      0.14       958
           7       0.31      0.05      0.09      1028
           8       0.15      0.77      0.25       974
           9       0.19      0.22      0.20      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.29      0.23      0.20     10000
weighted avg       0.29      0.22      0.20     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2617
Incorrectly classified: 7383
Test accuracy: 26.17%
              precision    recall  f1-score   support

           0       0.49      0.30      0.37       980
           1       0.17      0.01      0.01      1135
           2       0.45      0.37      0.41      1032
           3       0.26      0.39      0.31      1010
           4       0.26      0.18      0.21       982
           5       0.29      0.41      0.34       892
           6       0.36      0.26      0.31       958
           7       0.26      0.10      0.14      1028
           8       0.17      0.51      0.25       974
           9       0.15      0.16      0.15      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.29      0.27      0.25     10000
weighted avg       0.28      0.26      0.25     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2545
Incorrectly classified: 7455
Test accuracy: 25.45%
              precision    recall  f1-score   support

           0       0.67      0.38      0.49       980
           1       0.00      0.00      0.00      1135
           2       0.40      0.46      0.43      1032
           3       0.28      0.44      0.35      1010
           4       0.20      0.14      0.16       982
           5       0.25      0.31      0.27       892
           6       0.67      0.21      0.32       958
           7       0.26      0.05      0.09      1028
           8       0.13      0.50      0.21       974
           9       0.13      0.09      0.11      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2291
Incorrectly classified: 7709
Test accuracy: 22.91%
              precision    recall  f1-score   support

           0       0.62      0.19      0.29       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.34      0.42      1032
           3       0.32      0.16      0.22      1010
           4       0.22      0.18      0.20       982
           5       0.23      0.28      0.25       892
           6       0.54      0.32      0.40       958
           7       0.54      0.08      0.14      1028
           8       0.13      0.68      0.21       974
           9       0.15      0.09      0.12      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.33      0.23      0.23     10000
weighted avg       0.33      0.23      0.22     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2799
Incorrectly classified: 7201
Test accuracy: 27.99%
              precision    recall  f1-score   support

           0       0.41      0.42      0.42       980
           1       0.09      0.00      0.01      1135
           2       0.28      0.44      0.34      1032
           3       0.32      0.37      0.34      1010
           4       0.39      0.23      0.29       982
           5       0.23      0.28      0.26       892
           6       0.33      0.34      0.33       958
           7       0.45      0.15      0.22      1028
           8       0.20      0.45      0.27       974
           9       0.17      0.16      0.16      1009

   micro avg       0.28      0.28      0.28     10000
   macro avg       0.29      0.28      0.26     10000
weighted avg       0.29      0.28      0.26     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 6094
Incorrectly classified: 3906
Adversarial accuracy: 60.94%
              precision    recall  f1-score   support

           0       0.89      0.84      0.86       980
           1       0.78      0.07      0.12      1135
           2       0.58      0.81      0.68      1032
           3       0.57      0.81      0.67      1010
           4       0.59      0.56      0.58       982
           5       0.68      0.69      0.68       892
           6       0.88      0.72      0.79       958
           7       0.85      0.51      0.63      1028
           8       0.37      0.82      0.51       974
           9       0.51      0.36      0.42      1009

   micro avg       0.61      0.61      0.61     10000
   macro avg       0.67      0.62      0.60     10000
weighted avg       0.67      0.61      0.59     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5283
Incorrectly classified: 4717
Test accuracy: 52.83%
              precision    recall  f1-score   support

           0       0.84      0.76      0.80       980
           1       0.87      0.06      0.11      1135
           2       0.41      0.87      0.56      1032
           3       0.42      0.62      0.50      1010
           4       0.52      0.45      0.48       982
           5       0.56      0.64      0.60       892
           6       0.75      0.74      0.75       958
           7       0.82      0.38      0.52      1028
           8       0.41      0.56      0.48       974
           9       0.39      0.28      0.32      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.54      0.51     10000
weighted avg       0.60      0.53      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5296
Incorrectly classified: 4704
Test accuracy: 52.96%
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       980
           1       0.85      0.11      0.19      1135
           2       0.56      0.80      0.66      1032
           3       0.58      0.58      0.58      1010
           4       0.59      0.28      0.38       982
           5       0.49      0.68      0.57       892
           6       0.89      0.64      0.74       958
           7       0.82      0.21      0.34      1028
           8       0.28      0.80      0.41       974
           9       0.46      0.44      0.45      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.64      0.54      0.52     10000
weighted avg       0.64      0.53      0.51     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5666
Incorrectly classified: 4334
Test accuracy: 56.66%
              precision    recall  f1-score   support

           0       0.88      0.77      0.82       980
           1       0.86      0.11      0.20      1135
           2       0.65      0.65      0.65      1032
           3       0.64      0.57      0.60      1010
           4       0.50      0.72      0.59       982
           5       0.49      0.75      0.59       892
           6       0.80      0.74      0.77       958
           7       0.85      0.43      0.57      1028
           8       0.35      0.80      0.48       974
           9       0.37      0.24      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.64      0.57      0.55     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5431
Incorrectly classified: 4569
Test accuracy: 54.31%
              precision    recall  f1-score   support

           0       0.86      0.71      0.78       980
           1       0.89      0.32      0.47      1135
           2       0.52      0.64      0.58      1032
           3       0.43      0.72      0.54      1010
           4       0.64      0.26      0.37       982
           5       0.55      0.47      0.51       892
           6       0.82      0.61      0.70       958
           7       0.72      0.45      0.55      1028
           8       0.35      0.72      0.47       974
           9       0.42      0.56      0.48      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.62      0.55      0.54     10000
weighted avg       0.62      0.54      0.54     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4878
Incorrectly classified: 5122
Test accuracy: 48.78%
              precision    recall  f1-score   support

           0       0.91      0.61      0.73       980
           1       0.83      0.03      0.06      1135
           2       0.54      0.71      0.61      1032
           3       0.46      0.60      0.52      1010
           4       0.49      0.39      0.43       982
           5       0.46      0.64      0.54       892
           6       0.83      0.57      0.67       958
           7       0.83      0.30      0.44      1028
           8       0.28      0.75      0.40       974
           9       0.40      0.37      0.38      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.60      0.50      0.48     10000
weighted avg       0.61      0.49      0.47     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4936
Incorrectly classified: 5064
Test accuracy: 49.36%
              precision    recall  f1-score   support

           0       0.88      0.48      0.62       980
           1       0.79      0.05      0.10      1135
           2       0.40      0.72      0.51      1032
           3       0.34      0.87      0.49      1010
           4       0.54      0.46      0.50       982
           5       0.50      0.54      0.52       892
           6       0.81      0.67      0.73       958
           7       0.77      0.39      0.52      1028
           8       0.42      0.45      0.43       974
           9       0.46      0.37      0.41      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.59      0.50      0.48     10000
weighted avg       0.59      0.49      0.48     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5256
Incorrectly classified: 4744
Test accuracy: 52.56%
              precision    recall  f1-score   support

           0       0.84      0.77      0.80       980
           1       0.87      0.07      0.14      1135
           2       0.46      0.79      0.58      1032
           3       0.48      0.76      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.55      0.54      0.55       892
           6       0.80      0.72      0.76       958
           7       0.83      0.23      0.36      1028
           8       0.38      0.74      0.50       974
           9       0.34      0.28      0.31      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.60      0.53      0.50     10000
weighted avg       0.61      0.53      0.50     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5457
Incorrectly classified: 4543
Test accuracy: 54.57%
              precision    recall  f1-score   support

           0       0.89      0.78      0.83       980
           1       0.83      0.06      0.12      1135
           2       0.49      0.80      0.61      1032
           3       0.41      0.67      0.51      1010
           4       0.49      0.59      0.53       982
           5       0.58      0.59      0.59       892
           6       0.81      0.77      0.79       958
           7       0.83      0.42      0.56      1028
           8       0.38      0.71      0.49       974
           9       0.40      0.15      0.22      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.61      0.55      0.52     10000
weighted avg       0.61      0.55      0.52     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5489
Incorrectly classified: 4511
Test accuracy: 54.89%
              precision    recall  f1-score   support

           0       0.88      0.79      0.83       980
           1       0.93      0.13      0.23      1135
           2       0.47      0.76      0.58      1032
           3       0.56      0.52      0.54      1010
           4       0.58      0.45      0.50       982
           5       0.47      0.73      0.57       892
           6       0.85      0.67      0.75       958
           7       0.86      0.46      0.60      1028
           8       0.31      0.77      0.44       974
           9       0.64      0.29      0.39      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.65      0.56      0.54     10000
weighted avg       0.66      0.55      0.54     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5464
Incorrectly classified: 4536
Test accuracy: 54.64%
              precision    recall  f1-score   support

           0       0.78      0.78      0.78       980
           1       0.91      0.28      0.42      1135
           2       0.56      0.63      0.59      1032
           3       0.54      0.82      0.65      1010
           4       0.49      0.37      0.42       982
           5       0.65      0.61      0.63       892
           6       0.90      0.49      0.63       958
           7       0.72      0.40      0.52      1028
           8       0.31      0.87      0.46       974
           9       0.48      0.27      0.35      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.63      0.55      0.55     10000
weighted avg       0.64      0.55      0.54     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5154
Incorrectly classified: 4846
Test accuracy: 51.54%
              precision    recall  f1-score   support

           0       0.85      0.63      0.73       980
           1       0.86      0.08      0.15      1135
           2       0.55      0.65      0.59      1032
           3       0.48      0.70      0.57      1010
           4       0.49      0.46      0.47       982
           5       0.48      0.50      0.49       892
           6       0.91      0.35      0.51       958
           7       0.69      0.58      0.63      1028
           8       0.35      0.79      0.49       974
           9       0.38      0.46      0.42      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.61      0.52      0.51     10000
weighted avg       0.61      0.52      0.50     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5646
Incorrectly classified: 4354
Test accuracy: 56.46%
              precision    recall  f1-score   support

           0       0.87      0.73      0.80       980
           1       0.88      0.05      0.09      1135
           2       0.52      0.62      0.57      1032
           3       0.42      0.81      0.55      1010
           4       0.64      0.55      0.59       982
           5       0.57      0.65      0.61       892
           6       0.84      0.65      0.73       958
           7       0.71      0.53      0.61      1028
           8       0.41      0.69      0.51       974
           9       0.50      0.45      0.47      1009

   micro avg       0.56      0.56      0.56     10000
   macro avg       0.64      0.57      0.55     10000
weighted avg       0.64      0.56      0.55     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5788
Incorrectly classified: 4212
Test accuracy: 57.88%
              precision    recall  f1-score   support

           0       0.86      0.79      0.82       980
           1       0.93      0.27      0.42      1135
           2       0.59      0.69      0.63      1032
           3       0.51      0.85      0.64      1010
           4       0.51      0.46      0.48       982
           5       0.64      0.41      0.50       892
           6       0.92      0.53      0.68       958
           7       0.72      0.68      0.70      1028
           8       0.37      0.75      0.50       974
           9       0.41      0.37      0.39      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.65      0.58      0.58     10000
weighted avg       0.65      0.58      0.57     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5516
Incorrectly classified: 4484
Test accuracy: 55.16%
              precision    recall  f1-score   support

           0       0.90      0.65      0.76       980
           1       0.89      0.14      0.24      1135
           2       0.71      0.63      0.67      1032
           3       0.69      0.55      0.61      1010
           4       0.54      0.62      0.58       982
           5       0.58      0.38      0.46       892
           6       0.83      0.70      0.76       958
           7       0.76      0.61      0.68      1028
           8       0.29      0.90      0.44       974
           9       0.40      0.40      0.40      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.66      0.56      0.56     10000
weighted avg       0.66      0.55      0.55     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5445
Incorrectly classified: 4555
Test accuracy: 54.45%
              precision    recall  f1-score   support

           0       0.83      0.80      0.82       980
           1       0.84      0.14      0.25      1135
           2       0.52      0.69      0.59      1032
           3       0.49      0.76      0.59      1010
           4       0.61      0.50      0.55       982
           5       0.60      0.59      0.59       892
           6       0.84      0.64      0.72       958
           7       0.81      0.31      0.44      1028
           8       0.30      0.75      0.43       974
           9       0.53      0.35      0.42      1009

   micro avg       0.54      0.54      0.54     10000
   macro avg       0.64      0.55      0.54     10000
weighted avg       0.64      0.54      0.53     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9653
Incorrectly classified: 347
Adversarial accuracy: 96.53%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.97      0.97      1032
           3       0.96      0.95      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.97      0.96      0.96       892
           6       0.97      0.97      0.97       958
           7       0.97      0.96      0.96      1028
           8       0.94      0.96      0.95       974
           9       0.95      0.94      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.96      0.96     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9393
Incorrectly classified: 607
Test accuracy: 93.93%
              precision    recall  f1-score   support

           0       0.98      0.96      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.93      0.92      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.90      0.92      0.91       892
           6       0.95      0.96      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.92      0.93      0.92       974
           9       0.92      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9415
Incorrectly classified: 585
Test accuracy: 94.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.93      0.91      0.92      1010
           4       0.93      0.94      0.94       982
           5       0.92      0.93      0.92       892
           6       0.94      0.97      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9407
Incorrectly classified: 593
Test accuracy: 94.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.95      0.96      1032
           3       0.93      0.92      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.91      0.94      0.93       892
           6       0.93      0.97      0.95       958
           7       0.94      0.95      0.95      1028
           8       0.92      0.91      0.92       974
           9       0.93      0.87      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9347
Incorrectly classified: 653
Test accuracy: 93.47%
              precision    recall  f1-score   support

           0       0.95      0.98      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.91      0.92      0.91      1010
           4       0.95      0.91      0.93       982
           5       0.93      0.89      0.91       892
           6       0.95      0.97      0.96       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.91      0.91       974
           9       0.88      0.92      0.90      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9384
Incorrectly classified: 616
Test accuracy: 93.84%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.93      0.92      0.93       982
           5       0.94      0.89      0.91       892
           6       0.96      0.95      0.96       958
           7       0.94      0.95      0.95      1028
           8       0.89      0.93      0.91       974
           9       0.91      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9363
Incorrectly classified: 637
Test accuracy: 93.63%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.99      0.97      0.98      1135
           2       0.92      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.95      0.93       982
           5       0.94      0.90      0.92       892
           6       0.95      0.95      0.95       958
           7       0.96      0.93      0.94      1028
           8       0.91      0.91      0.91       974
           9       0.93      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9382
Incorrectly classified: 618
Test accuracy: 93.82%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.93      0.96      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.92      0.94      0.93       982
           5       0.96      0.89      0.92       892
           6       0.95      0.95      0.95       958
           7       0.97      0.91      0.94      1028
           8       0.90      0.93      0.92       974
           9       0.90      0.90      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9419
Incorrectly classified: 581
Test accuracy: 94.19%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.94      0.90      0.92      1010
           4       0.94      0.94      0.94       982
           5       0.90      0.94      0.92       892
           6       0.95      0.97      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.93      0.92      0.93       974
           9       0.92      0.91      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9406
Incorrectly classified: 594
Test accuracy: 94.06%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.94      0.96      0.95      1032
           3       0.95      0.91      0.93      1010
           4       0.93      0.93      0.93       982
           5       0.91      0.93      0.92       892
           6       0.96      0.96      0.96       958
           7       0.94      0.95      0.94      1028
           8       0.90      0.94      0.92       974
           9       0.91      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9395
Incorrectly classified: 605
Test accuracy: 93.95%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.90      0.94      0.92      1010
           4       0.91      0.95      0.93       982
           5       0.96      0.90      0.93       892
           6       0.96      0.93      0.95       958
           7       0.94      0.96      0.95      1028
           8       0.88      0.95      0.91       974
           9       0.94      0.88      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9405
Incorrectly classified: 595
Test accuracy: 94.05%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.94      0.95      0.95      1032
           3       0.92      0.92      0.92      1010
           4       0.91      0.94      0.93       982
           5       0.93      0.91      0.92       892
           6       0.97      0.95      0.96       958
           7       0.95      0.94      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.91      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9409
Incorrectly classified: 591
Test accuracy: 94.09%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.92      0.93      0.92       982
           5       0.93      0.92      0.93       892
           6       0.95      0.96      0.95       958
           7       0.95      0.95      0.95      1028
           8       0.90      0.94      0.92       974
           9       0.91      0.89      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9374
Incorrectly classified: 626
Test accuracy: 93.74%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.97      0.99      0.98      1135
           2       0.93      0.95      0.94      1032
           3       0.91      0.93      0.92      1010
           4       0.94      0.89      0.92       982
           5       0.96      0.90      0.93       892
           6       0.97      0.95      0.96       958
           7       0.96      0.92      0.94      1028
           8       0.89      0.94      0.91       974
           9       0.88      0.92      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9415
Incorrectly classified: 585
Test accuracy: 94.15%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.95      0.90      0.92      1010
           4       0.92      0.93      0.93       982
           5       0.93      0.93      0.93       892
           6       0.95      0.96      0.95       958
           7       0.96      0.94      0.95      1028
           8       0.89      0.95      0.92       974
           9       0.89      0.92      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9400
Incorrectly classified: 600
Test accuracy: 94.00%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.94      0.95      0.95      1032
           3       0.95      0.91      0.93      1010
           4       0.94      0.91      0.93       982
           5       0.93      0.92      0.93       892
           6       0.95      0.96      0.96       958
           7       0.97      0.93      0.95      1028
           8       0.89      0.93      0.91       974
           9       0.88      0.92      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

Adversarial test data.
Correctly classified: 9523
Incorrectly classified: 477
Adversarial accuracy: 95.23%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.96      0.95      0.95      1032
           3       0.95      0.95      0.95      1010
           4       0.93      0.96      0.94       982
           5       0.94      0.96      0.95       892
           6       0.96      0.97      0.96       958
           7       0.95      0.95      0.95      1028
           8       0.95      0.94      0.94       974
           9       0.94      0.90      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 16, 16, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9217
Incorrectly classified: 783
Test accuracy: 92.17%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.94      0.93      1032
           3       0.92      0.90      0.91      1010
           4       0.86      0.94      0.89       982
           5       0.86      0.94      0.90       892
           6       0.94      0.95      0.94       958
           7       0.94      0.92      0.93      1028
           8       0.94      0.89      0.91       974
           9       0.89      0.82      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.89      0.89      1010
           4       0.88      0.93      0.90       982
           5       0.88      0.92      0.90       892
           6       0.93      0.96      0.95       958
           7       0.93      0.92      0.93      1028
           8       0.91      0.90      0.91       974
           9       0.91      0.83      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9221
Incorrectly classified: 779
Test accuracy: 92.21%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.89      0.90      1010
           4       0.86      0.94      0.90       982
           5       0.87      0.95      0.90       892
           6       0.93      0.96      0.94       958
           7       0.92      0.93      0.93      1028
           8       0.93      0.89      0.91       974
           9       0.90      0.81      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.94      0.97      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.91      0.91      0.91      1032
           3       0.90      0.91      0.90      1010
           4       0.91      0.92      0.92       982
           5       0.90      0.91      0.90       892
           6       0.94      0.96      0.95       958
           7       0.92      0.90      0.91      1028
           8       0.91      0.86      0.89       974
           9       0.88      0.88      0.88      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9211
Incorrectly classified: 789
Test accuracy: 92.11%
              precision    recall  f1-score   support

           0       0.97      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.92      0.92      1032
           3       0.89      0.93      0.91      1010
           4       0.87      0.91      0.89       982
           5       0.91      0.92      0.91       892
           6       0.95      0.94      0.95       958
           7       0.91      0.94      0.93      1028
           8       0.90      0.90      0.90       974
           9       0.89      0.82      0.85      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9191
Incorrectly classified: 809
Test accuracy: 91.91%
              precision    recall  f1-score   support

           0       0.95      0.96      0.95       980
           1       0.98      0.97      0.97      1135
           2       0.90      0.94      0.92      1032
           3       0.89      0.91      0.90      1010
           4       0.84      0.95      0.89       982
           5       0.91      0.92      0.92       892
           6       0.94      0.95      0.95       958
           7       0.94      0.91      0.92      1028
           8       0.92      0.86      0.89       974
           9       0.92      0.81      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9229
Incorrectly classified: 771
Test accuracy: 92.29%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.90      0.93      0.91      1032
           3       0.90      0.92      0.91      1010
           4       0.86      0.92      0.89       982
           5       0.93      0.92      0.92       892
           6       0.95      0.94      0.95       958
           7       0.95      0.90      0.92      1028
           8       0.92      0.91      0.92       974
           9       0.89      0.84      0.86      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9197
Incorrectly classified: 803
Test accuracy: 91.97%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.92      0.93      0.92      1032
           3       0.92      0.87      0.90      1010
           4       0.88      0.93      0.90       982
           5       0.85      0.94      0.89       892
           6       0.93      0.95      0.94       958
           7       0.93      0.92      0.93      1028
           8       0.93      0.88      0.91       974
           9       0.90      0.84      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9282
Incorrectly classified: 718
Test accuracy: 92.82%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.91      0.94      0.92      1032
           3       0.94      0.90      0.92      1010
           4       0.91      0.93      0.92       982
           5       0.89      0.94      0.91       892
           6       0.96      0.95      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.92      0.90      0.91       974
           9       0.90      0.86      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9186
Incorrectly classified: 814
Test accuracy: 91.86%
              precision    recall  f1-score   support

           0       0.96      0.95      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.95      0.90      0.92      1032
           3       0.88      0.94      0.91      1010
           4       0.83      0.93      0.88       982
           5       0.93      0.92      0.92       892
           6       0.95      0.94      0.94       958
           7       0.91      0.94      0.93      1028
           8       0.90      0.92      0.91       974
           9       0.92      0.77      0.84      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9235
Incorrectly classified: 765
Test accuracy: 92.35%
              precision    recall  f1-score   support

           0       0.95      0.96      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.91      0.93      0.92      1032
           3       0.92      0.92      0.92      1010
           4       0.84      0.92      0.88       982
           5       0.91      0.93      0.92       892
           6       0.96      0.94      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.92      0.91      0.91       974
           9       0.89      0.80      0.84      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9233
Incorrectly classified: 767
Test accuracy: 92.33%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.95      0.90      0.92      1032
           3       0.90      0.92      0.91      1010
           4       0.88      0.93      0.90       982
           5       0.89      0.93      0.91       892
           6       0.94      0.96      0.95       958
           7       0.92      0.93      0.92      1028
           8       0.90      0.90      0.90       974
           9       0.91      0.83      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9238
Incorrectly classified: 762
Test accuracy: 92.38%
              precision    recall  f1-score   support

           0       0.96      0.95      0.95       980
           1       0.95      0.99      0.97      1135
           2       0.91      0.92      0.92      1032
           3       0.90      0.94      0.92      1010
           4       0.90      0.89      0.90       982
           5       0.93      0.92      0.92       892
           6       0.96      0.94      0.95       958
           7       0.94      0.90      0.92      1028
           8       0.90      0.92      0.91       974
           9       0.87      0.87      0.87      1009

   micro avg       0.92      0.92      0.92     10000
   macro avg       0.92      0.92      0.92     10000
weighted avg       0.92      0.92      0.92     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9279
Incorrectly classified: 721
Test accuracy: 92.79%
              precision    recall  f1-score   support

           0       0.97      0.94      0.96       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.91      0.93      1032
           3       0.93      0.90      0.92      1010
           4       0.89      0.93      0.91       982
           5       0.89      0.94      0.92       892
           6       0.94      0.96      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.91      0.91      0.91       974
           9       0.88      0.87      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 16, 16, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9259
Incorrectly classified: 741
Test accuracy: 92.59%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.97      0.97      0.97      1135
           2       0.93      0.92      0.93      1032
           3       0.93      0.90      0.91      1010
           4       0.90      0.91      0.91       982
           5       0.90      0.94      0.92       892
           6       0.94      0.95      0.95       958
           7       0.94      0.91      0.93      1028
           8       0.90      0.90      0.90       974
           9       0.88      0.87      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Loading mnist.
x_train shape: (60000, 28, 28, 1) 
x_test shape: (10000, 28, 28, 1)

 === RandEns model ( n_proj =  15 , size_proj =  20 ) ===

Loading time: --- 45.22944235801697 seconds ---

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 28, 28, 1) 
y_test.shape =  (10000, 10) 

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)
Correctly classified: 9833
Incorrectly classified: 167
Test accuracy: 98.33%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.98      0.98      1032
           3       0.98      0.99      0.99      1010
           4       0.99      0.98      0.98       982
           5       0.99      0.98      0.98       892
           6       0.99      0.99      0.99       958
           7       0.98      0.98      0.98      1028
           8       0.98      0.98      0.98       974
           9       0.98      0.97      0.98      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9748
Incorrectly classified: 252
Test accuracy: 97.48%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.96      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.97      0.97      0.97       892
           6       0.97      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9773
Incorrectly classified: 227
Test accuracy: 97.73%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.98       892
           6       0.99      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.98      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9749
Incorrectly classified: 251
Test accuracy: 97.49%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.97      0.99      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.98      0.95      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9768
Incorrectly classified: 232
Test accuracy: 97.68%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.98      1032
           3       0.98      0.98      0.98      1010
           4       0.96      0.98      0.97       982
           5       0.98      0.96      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.98      0.97       974
           9       0.97      0.97      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9758
Incorrectly classified: 242
Test accuracy: 97.58%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.96      0.96      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9776
Incorrectly classified: 224
Test accuracy: 97.76%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.99      0.97      0.98      1010
           4       0.98      0.99      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.97      0.98      0.97      1028
           8       0.97      0.98      0.97       974
           9       0.98      0.95      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9764
Incorrectly classified: 236
Test accuracy: 97.64%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.97      0.97      0.97       982
           5       0.98      0.97      0.97       892
           6       0.99      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9770
Incorrectly classified: 230
Test accuracy: 97.70%
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.98      0.97      1032
           3       0.98      0.97      0.97      1010
           4       0.97      0.98      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.96      0.97      1028
           8       0.95      0.98      0.96       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9771
Incorrectly classified: 229
Test accuracy: 97.71%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.98      0.98      0.98      1010
           4       0.98      0.98      0.98       982
           5       0.98      0.98      0.98       892
           6       0.99      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.97      0.97      0.97       974
           9       0.97      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9755
Incorrectly classified: 245
Test accuracy: 97.55%
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.97      0.98      0.98      1010
           4       0.98      0.97      0.98       982
           5       0.98      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.97      0.97      0.97      1028
           8       0.96      0.97      0.97       974
           9       0.97      0.95      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9751
Incorrectly classified: 249
Test accuracy: 97.51%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.98      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.97      0.98      0.97       982
           5       0.97      0.98      0.97       892
           6       0.98      0.97      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.95      0.97      0.96       974
           9       0.98      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.97      0.98      0.97     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9757
Incorrectly classified: 243
Test accuracy: 97.57%
              precision    recall  f1-score   support

           0       0.98      0.99      0.99       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.98      0.98      1032
           3       0.96      0.98      0.97      1010
           4       0.98      0.97      0.98       982
           5       0.98      0.97      0.97       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.97      1028
           8       0.96      0.97      0.96       974
           9       0.97      0.96      0.97      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9764
Incorrectly classified: 236
Test accuracy: 97.64%
              precision    recall  f1-score   support

           0       0.98      0.99      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.98      0.97      1010
           4       0.99      0.97      0.98       982
           5       0.98      0.97      0.98       892
           6       0.98      0.98      0.98       958
           7       0.98      0.97      0.98      1028
           8       0.98      0.96      0.97       974
           9       0.96      0.97      0.96      1009

   micro avg       0.98      0.98      0.98     10000
   macro avg       0.98      0.98      0.98     10000
weighted avg       0.98      0.98      0.98     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with fgsm method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 2503
Incorrectly classified: 7497
Adversarial accuracy: 25.03%
              precision    recall  f1-score   support

           0       0.65      0.34      0.45       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.47      0.50      1032
           3       0.31      0.38      0.34      1010
           4       0.12      0.07      0.09       982
           5       0.36      0.23      0.28       892
           6       0.58      0.25      0.35       958
           7       0.47      0.04      0.07      1028
           8       0.14      0.71      0.23       974
           9       0.10      0.06      0.08      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.33      0.25      0.24     10000
weighted avg       0.32      0.25      0.23     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2500
Incorrectly classified: 7500
Test accuracy: 25.00%
              precision    recall  f1-score   support

           0       0.62      0.38      0.47       980
           1       0.00      0.00      0.00      1135
           2       0.48      0.52      0.50      1032
           3       0.26      0.43      0.32      1010
           4       0.17      0.12      0.14       982
           5       0.29      0.21      0.25       892
           6       0.48      0.23      0.31       958
           7       0.48      0.08      0.14      1028
           8       0.12      0.49      0.19       974
           9       0.09      0.06      0.07      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2132
Incorrectly classified: 7868
Test accuracy: 21.32%
              precision    recall  f1-score   support

           0       0.68      0.13      0.22       980
           1       0.00      0.00      0.00      1135
           2       0.38      0.49      0.43      1032
           3       0.31      0.28      0.29      1010
           4       0.22      0.09      0.13       982
           5       0.27      0.10      0.15       892
           6       0.58      0.19      0.29       958
           7       0.42      0.02      0.04      1028
           8       0.12      0.74      0.21       974
           9       0.20      0.11      0.14      1009

   micro avg       0.21      0.21      0.21     10000
   macro avg       0.32      0.22      0.19     10000
weighted avg       0.31      0.21      0.19     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2351
Incorrectly classified: 7649
Test accuracy: 23.51%
              precision    recall  f1-score   support

           0       0.59      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.54      0.34      0.42      1032
           3       0.25      0.32      0.28      1010
           4       0.24      0.10      0.14       982
           5       0.25      0.23      0.24       892
           6       0.57      0.25      0.34       958
           7       0.48      0.03      0.05      1028
           8       0.14      0.73      0.24       974
           9       0.13      0.11      0.12      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.32      0.24      0.22     10000
weighted avg       0.31      0.24      0.22     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2387
Incorrectly classified: 7613
Test accuracy: 23.87%
              precision    recall  f1-score   support

           0       0.49      0.18      0.26       980
           1       0.00      0.00      0.00      1135
           2       0.37      0.43      0.40      1032
           3       0.21      0.37      0.27      1010
           4       0.19      0.13      0.16       982
           5       0.24      0.21      0.23       892
           6       0.55      0.34      0.42       958
           7       0.35      0.14      0.20      1028
           8       0.15      0.47      0.22       974
           9       0.14      0.14      0.14      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.27      0.24      0.23     10000
weighted avg       0.26      0.24      0.23     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2452
Incorrectly classified: 7548
Test accuracy: 24.52%
              precision    recall  f1-score   support

           0       0.66      0.35      0.46       980
           1       0.00      0.00      0.00      1135
           2       0.55      0.43      0.48      1032
           3       0.32      0.34      0.33      1010
           4       0.24      0.24      0.24       982
           5       0.32      0.22      0.26       892
           6       0.42      0.23      0.29       958
           7       0.57      0.05      0.09      1028
           8       0.13      0.60      0.21       974
           9       0.04      0.03      0.04      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.32      0.25      0.24     10000
weighted avg       0.32      0.25      0.24     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2166
Incorrectly classified: 7834
Test accuracy: 21.66%
              precision    recall  f1-score   support

           0       0.57      0.19      0.28       980
           1       0.00      0.00      0.00      1135
           2       0.44      0.41      0.42      1032
           3       0.28      0.39      0.33      1010
           4       0.14      0.08      0.10       982
           5       0.25      0.21      0.23       892
           6       0.58      0.12      0.19       958
           7       0.46      0.05      0.09      1028
           8       0.11      0.58      0.19       974
           9       0.24      0.18      0.20      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.31      0.22      0.20     10000
weighted avg       0.30      0.22      0.20     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2309
Incorrectly classified: 7691
Test accuracy: 23.09%
              precision    recall  f1-score   support

           0       0.51      0.33      0.40       980
           1       0.00      0.00      0.00      1135
           2       0.47      0.46      0.46      1032
           3       0.38      0.16      0.23      1010
           4       0.13      0.10      0.12       982
           5       0.36      0.20      0.26       892
           6       0.45      0.20      0.28       958
           7       0.48      0.09      0.15      1028
           8       0.13      0.66      0.22       974
           9       0.12      0.14      0.13      1009

   micro avg       0.23      0.23      0.23     10000
   macro avg       0.30      0.23      0.22     10000
weighted avg       0.30      0.23      0.22     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2184
Incorrectly classified: 7816
Test accuracy: 21.84%
              precision    recall  f1-score   support

           0       0.50      0.21      0.29       980
           1       0.00      0.00      0.00      1135
           2       0.41      0.45      0.43      1032
           3       0.25      0.25      0.25      1010
           4       0.11      0.07      0.08       982
           5       0.18      0.12      0.15       892
           6       0.53      0.29      0.38       958
           7       0.55      0.05      0.10      1028
           8       0.14      0.63      0.22       974
           9       0.13      0.14      0.13      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.28      0.22      0.20     10000
weighted avg       0.28      0.22      0.20     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2451
Incorrectly classified: 7549
Test accuracy: 24.51%
              precision    recall  f1-score   support

           0       0.57      0.34      0.42       980
           1       0.17      0.00      0.00      1135
           2       0.43      0.37      0.40      1032
           3       0.21      0.38      0.27      1010
           4       0.26      0.23      0.25       982
           5       0.30      0.28      0.29       892
           6       0.48      0.27      0.35       958
           7       0.43      0.10      0.16      1028
           8       0.13      0.47      0.20       974
           9       0.08      0.05      0.06      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.31      0.25      0.24     10000
weighted avg       0.30      0.25      0.24     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2494
Incorrectly classified: 7506
Test accuracy: 24.94%
              precision    recall  f1-score   support

           0       0.58      0.30      0.39       980
           1       0.00      0.00      0.00      1135
           2       0.45      0.46      0.45      1032
           3       0.37      0.28      0.32      1010
           4       0.19      0.13      0.16       982
           5       0.37      0.38      0.37       892
           6       0.49      0.19      0.28       958
           7       0.34      0.01      0.02      1028
           8       0.14      0.77      0.24       974
           9       0.08      0.03      0.05      1009

   micro avg       0.25      0.25      0.25     10000
   macro avg       0.30      0.26      0.23     10000
weighted avg       0.30      0.25      0.22     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2239
Incorrectly classified: 7761
Test accuracy: 22.39%
              precision    recall  f1-score   support

           0       0.61      0.24      0.34       980
           1       0.03      0.00      0.00      1135
           2       0.47      0.26      0.34      1032
           3       0.26      0.44      0.32      1010
           4       0.11      0.06      0.08       982
           5       0.25      0.26      0.25       892
           6       0.55      0.18      0.27       958
           7       0.16      0.03      0.05      1028
           8       0.16      0.60      0.25       974
           9       0.13      0.22      0.17      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.27      0.23      0.21     10000
weighted avg       0.27      0.22      0.20     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2735
Incorrectly classified: 7265
Test accuracy: 27.35%
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       980
           1       0.00      0.00      0.00      1135
           2       0.45      0.48      0.46      1032
           3       0.25      0.36      0.30      1010
           4       0.29      0.13      0.18       982
           5       0.36      0.28      0.31       892
           6       0.39      0.25      0.31       958
           7       0.30      0.08      0.12      1028
           8       0.15      0.55      0.24       974
           9       0.22      0.25      0.23      1009

   micro avg       0.27      0.27      0.27     10000
   macro avg       0.29      0.28      0.26     10000
weighted avg       0.29      0.27      0.26     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2185
Incorrectly classified: 7815
Test accuracy: 21.85%
              precision    recall  f1-score   support

           0       0.57      0.24      0.34       980
           1       0.00      0.00      0.00      1135
           2       0.50      0.32      0.39      1032
           3       0.25      0.32      0.28      1010
           4       0.08      0.02      0.03       982
           5       0.32      0.39      0.35       892
           6       0.62      0.19      0.29       958
           7       0.44      0.02      0.03      1028
           8       0.12      0.67      0.20       974
           9       0.26      0.08      0.12      1009

   micro avg       0.22      0.22      0.22     10000
   macro avg       0.32      0.22      0.20     10000
weighted avg       0.31      0.22      0.20     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2560
Incorrectly classified: 7440
Test accuracy: 25.60%
              precision    recall  f1-score   support

           0       0.63      0.33      0.44       980
           1       0.00      0.00      0.00      1135
           2       0.39      0.49      0.43      1032
           3       0.25      0.52      0.33      1010
           4       0.23      0.10      0.14       982
           5       0.23      0.15      0.18       892
           6       0.54      0.35      0.42       958
           7       0.44      0.07      0.12      1028
           8       0.13      0.47      0.20       974
           9       0.18      0.11      0.14      1009

   micro avg       0.26      0.26      0.26     10000
   macro avg       0.30      0.26      0.24     10000
weighted avg       0.30      0.26      0.24     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 2360
Incorrectly classified: 7640
Test accuracy: 23.60%
              precision    recall  f1-score   support

           0       0.56      0.34      0.42       980
           1       0.00      0.00      0.00      1135
           2       0.50      0.35      0.42      1032
           3       0.19      0.29      0.23      1010
           4       0.23      0.08      0.12       982
           5       0.18      0.24      0.21       892
           6       0.35      0.32      0.34       958
           7       0.33      0.10      0.15      1028
           8       0.15      0.47      0.23       974
           9       0.15      0.21      0.17      1009

   micro avg       0.24      0.24      0.24     10000
   macro avg       0.26      0.24      0.23     10000
weighted avg       0.26      0.24      0.22     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with pgd method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 5756
Incorrectly classified: 4244
Adversarial accuracy: 57.56%
              precision    recall  f1-score   support

           0       0.89      0.84      0.86       980
           1       0.78      0.06      0.10      1135
           2       0.59      0.78      0.67      1032
           3       0.57      0.81      0.67      1010
           4       0.53      0.58      0.55       982
           5       0.71      0.52      0.60       892
           6       0.87      0.71      0.78       958
           7       0.83      0.44      0.57      1028
           8       0.33      0.85      0.47       974
           9       0.43      0.24      0.31      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.65      0.58      0.56     10000
weighted avg       0.65      0.58      0.55     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5187
Incorrectly classified: 4813
Test accuracy: 51.87%
              precision    recall  f1-score   support

           0       0.85      0.80      0.83       980
           1       0.80      0.04      0.07      1135
           2       0.51      0.83      0.63      1032
           3       0.57      0.68      0.62      1010
           4       0.49      0.39      0.43       982
           5       0.57      0.39      0.47       892
           6       0.81      0.66      0.73       958
           7       0.75      0.36      0.48      1028
           8       0.29      0.77      0.42       974
           9       0.36      0.32      0.34      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.50     10000
weighted avg       0.60      0.52      0.50     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4908
Incorrectly classified: 5092
Test accuracy: 49.08%
              precision    recall  f1-score   support

           0       0.89      0.70      0.79       980
           1       0.81      0.07      0.12      1135
           2       0.52      0.75      0.61      1032
           3       0.53      0.67      0.59      1010
           4       0.48      0.44      0.46       982
           5       0.63      0.28      0.39       892
           6       0.86      0.62      0.72       958
           7       0.85      0.31      0.46      1028
           8       0.26      0.87      0.41       974
           9       0.32      0.24      0.28      1009

   micro avg       0.49      0.49      0.49     10000
   macro avg       0.61      0.50      0.48     10000
weighted avg       0.62      0.49      0.48     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5655
Incorrectly classified: 4345
Test accuracy: 56.55%
              precision    recall  f1-score   support

           0       0.84      0.83      0.83       980
           1       0.93      0.19      0.32      1135
           2       0.61      0.69      0.65      1032
           3       0.58      0.66      0.62      1010
           4       0.50      0.62      0.55       982
           5       0.57      0.63      0.60       892
           6       0.81      0.66      0.73       958
           7       0.78      0.42      0.54      1028
           8       0.34      0.77      0.48       974
           9       0.34      0.25      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.63      0.57      0.56     10000
weighted avg       0.63      0.57      0.56     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5180
Incorrectly classified: 4820
Test accuracy: 51.80%
              precision    recall  f1-score   support

           0       0.88      0.57      0.69       980
           1       0.82      0.13      0.23      1135
           2       0.46      0.64      0.53      1032
           3       0.43      0.86      0.57      1010
           4       0.49      0.44      0.47       982
           5       0.59      0.37      0.46       892
           6       0.85      0.59      0.69       958
           7       0.69      0.60      0.64      1028
           8       0.35      0.74      0.47       974
           9       0.43      0.27      0.33      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.60      0.52      0.51     10000
weighted avg       0.60      0.52      0.51     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5235
Incorrectly classified: 4765
Test accuracy: 52.35%
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       980
           1       0.89      0.24      0.37      1135
           2       0.62      0.67      0.64      1032
           3       0.45      0.73      0.56      1010
           4       0.46      0.62      0.53       982
           5       0.55      0.46      0.50       892
           6       0.84      0.47      0.61       958
           7       0.78      0.29      0.42      1028
           8       0.30      0.76      0.43       974
           9       0.37      0.24      0.29      1009

   micro avg       0.52      0.52      0.52     10000
   macro avg       0.61      0.53      0.52     10000
weighted avg       0.62      0.52      0.52     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5036
Incorrectly classified: 4964
Test accuracy: 50.36%
              precision    recall  f1-score   support

           0       0.88      0.54      0.67       980
           1       0.88      0.18      0.30      1135
           2       0.57      0.69      0.62      1032
           3       0.47      0.80      0.59      1010
           4       0.46      0.51      0.48       982
           5       0.49      0.53      0.51       892
           6       0.86      0.48      0.62       958
           7       0.71      0.19      0.30      1028
           8       0.33      0.81      0.47       974
           9       0.38      0.37      0.38      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.60      0.51      0.49     10000
weighted avg       0.61      0.50      0.49     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5701
Incorrectly classified: 4299
Test accuracy: 57.01%
              precision    recall  f1-score   support

           0       0.84      0.85      0.85       980
           1       0.92      0.19      0.32      1135
           2       0.51      0.79      0.62      1032
           3       0.64      0.54      0.59      1010
           4       0.52      0.68      0.59       982
           5       0.61      0.49      0.54       892
           6       0.83      0.70      0.76       958
           7       0.85      0.49      0.62      1028
           8       0.34      0.80      0.47       974
           9       0.39      0.23      0.29      1009

   micro avg       0.57      0.57      0.57     10000
   macro avg       0.64      0.58      0.56     10000
weighted avg       0.65      0.57      0.56     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5269
Incorrectly classified: 4731
Test accuracy: 52.69%
              precision    recall  f1-score   support

           0       0.87      0.77      0.82       980
           1       0.83      0.11      0.19      1135
           2       0.50      0.79      0.61      1032
           3       0.47      0.69      0.56      1010
           4       0.52      0.44      0.48       982
           5       0.60      0.38      0.47       892
           6       0.80      0.75      0.78       958
           7       0.79      0.20      0.32      1028
           8       0.34      0.78      0.47       974
           9       0.38      0.42      0.40      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.61      0.53      0.51     10000
weighted avg       0.61      0.53      0.50     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5251
Incorrectly classified: 4749
Test accuracy: 52.51%
              precision    recall  f1-score   support

           0       0.89      0.75      0.82       980
           1       0.76      0.03      0.06      1135
           2       0.62      0.53      0.58      1032
           3       0.51      0.79      0.62      1010
           4       0.48      0.63      0.54       982
           5       0.61      0.49      0.54       892
           6       0.84      0.67      0.74       958
           7       0.84      0.41      0.55      1028
           8       0.27      0.83      0.41       974
           9       0.47      0.21      0.29      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.63      0.53      0.52     10000
weighted avg       0.63      0.53      0.51     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5309
Incorrectly classified: 4691
Test accuracy: 53.09%
              precision    recall  f1-score   support

           0       0.82      0.82      0.82       980
           1       0.81      0.05      0.09      1135
           2       0.48      0.80      0.60      1032
           3       0.61      0.59      0.60      1010
           4       0.50      0.55      0.52       982
           5       0.66      0.59      0.62       892
           6       0.89      0.57      0.69       958
           7       0.86      0.37      0.52      1028
           8       0.29      0.86      0.43       974
           9       0.49      0.21      0.29      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.64      0.54      0.52     10000
weighted avg       0.64      0.53      0.51     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5007
Incorrectly classified: 4993
Test accuracy: 50.07%
              precision    recall  f1-score   support

           0       0.86      0.63      0.73       980
           1       0.82      0.10      0.18      1135
           2       0.62      0.57      0.60      1032
           3       0.54      0.75      0.63      1010
           4       0.50      0.40      0.45       982
           5       0.59      0.45      0.51       892
           6       0.85      0.55      0.67       958
           7       0.74      0.38      0.50      1028
           8       0.26      0.86      0.39       974
           9       0.40      0.37      0.39      1009

   micro avg       0.50      0.50      0.50     10000
   macro avg       0.62      0.51      0.50     10000
weighted avg       0.62      0.50      0.50     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5780
Incorrectly classified: 4220
Test accuracy: 57.80%
              precision    recall  f1-score   support

           0       0.89      0.77      0.82       980
           1       0.85      0.12      0.21      1135
           2       0.53      0.69      0.60      1032
           3       0.42      0.76      0.54      1010
           4       0.58      0.74      0.65       982
           5       0.62      0.61      0.62       892
           6       0.79      0.78      0.78       958
           7       0.75      0.44      0.55      1028
           8       0.44      0.72      0.54       974
           9       0.44      0.24      0.31      1009

   micro avg       0.58      0.58      0.58     10000
   macro avg       0.63      0.59      0.56     10000
weighted avg       0.63      0.58      0.56     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 4804
Incorrectly classified: 5196
Test accuracy: 48.04%
              precision    recall  f1-score   support

           0       0.90      0.73      0.80       980
           1       0.81      0.05      0.09      1135
           2       0.51      0.62      0.56      1032
           3       0.45      0.76      0.56      1010
           4       0.37      0.25      0.30       982
           5       0.51      0.55      0.53       892
           6       0.91      0.46      0.62       958
           7       0.79      0.41      0.54      1028
           8       0.27      0.81      0.41       974
           9       0.39      0.23      0.29      1009

   micro avg       0.48      0.48      0.48     10000
   macro avg       0.59      0.49      0.47     10000
weighted avg       0.59      0.48      0.46     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5266
Incorrectly classified: 4734
Test accuracy: 52.66%
              precision    recall  f1-score   support

           0       0.87      0.75      0.81       980
           1       0.81      0.06      0.12      1135
           2       0.54      0.70      0.61      1032
           3       0.45      0.80      0.58      1010
           4       0.62      0.38      0.47       982
           5       0.63      0.31      0.41       892
           6       0.86      0.67      0.76       958
           7       0.72      0.46      0.57      1028
           8       0.30      0.80      0.44       974
           9       0.41      0.36      0.39      1009

   micro avg       0.53      0.53      0.53     10000
   macro avg       0.62      0.53      0.51     10000
weighted avg       0.62      0.53      0.51     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 5489
Incorrectly classified: 4511
Test accuracy: 54.89%
              precision    recall  f1-score   support

           0       0.84      0.82      0.83       980
           1       0.84      0.05      0.10      1135
           2       0.55      0.75      0.63      1032
           3       0.44      0.76      0.56      1010
           4       0.57      0.52      0.55       982
           5       0.60      0.48      0.53       892
           6       0.79      0.69      0.73       958
           7       0.73      0.51      0.60      1028
           8       0.33      0.70      0.45       974
           9       0.46      0.26      0.33      1009

   micro avg       0.55      0.55      0.55     10000
   macro avg       0.61      0.56      0.53     10000
weighted avg       0.62      0.55      0.53     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with deepfool method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9677
Incorrectly classified: 323
Adversarial accuracy: 96.77%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.99      0.99      1135
           2       0.97      0.97      0.97      1032
           3       0.96      0.97      0.96      1010
           4       0.96      0.96      0.96       982
           5       0.98      0.94      0.96       892
           6       0.98      0.98      0.98       958
           7       0.97      0.96      0.96      1028
           8       0.95      0.97      0.96       974
           9       0.95      0.95      0.95      1009

   micro avg       0.97      0.97      0.97     10000
   macro avg       0.97      0.97      0.97     10000
weighted avg       0.97      0.97      0.97     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9478
Incorrectly classified: 522
Test accuracy: 94.78%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.97      0.94      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.94      0.94      0.94       982
           5       0.94      0.92      0.93       892
           6       0.95      0.96      0.96       958
           7       0.96      0.95      0.95      1028
           8       0.91      0.93      0.92       974
           9       0.93      0.92      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9434
Incorrectly classified: 566
Test accuracy: 94.34%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.92      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.96      0.90      0.93       892
           6       0.96      0.97      0.97       958
           7       0.97      0.92      0.94      1028
           8       0.88      0.97      0.92       974
           9       0.92      0.89      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9500
Incorrectly classified: 500
Test accuracy: 95.00%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.93      0.94      0.94      1010
           4       0.94      0.94      0.94       982
           5       0.95      0.93      0.94       892
           6       0.96      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.92      0.94      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9452
Incorrectly classified: 548
Test accuracy: 94.52%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.90      0.96      0.93      1010
           4       0.92      0.95      0.94       982
           5       0.95      0.90      0.92       892
           6       0.94      0.97      0.96       958
           7       0.93      0.95      0.94      1028
           8       0.95      0.90      0.92       974
           9       0.94      0.89      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.94     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9458
Incorrectly classified: 542
Test accuracy: 94.58%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.98      0.99      1135
           2       0.95      0.96      0.95      1032
           3       0.93      0.93      0.93      1010
           4       0.91      0.95      0.93       982
           5       0.97      0.88      0.92       892
           6       0.97      0.95      0.96       958
           7       0.97      0.93      0.95      1028
           8       0.90      0.95      0.93       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9459
Incorrectly classified: 541
Test accuracy: 94.59%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.95      0.96      0.95      1032
           3       0.92      0.95      0.93      1010
           4       0.94      0.92      0.93       982
           5       0.95      0.90      0.93       892
           6       0.97      0.96      0.96       958
           7       0.96      0.93      0.95      1028
           8       0.93      0.94      0.94       974
           9       0.88      0.93      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.94      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9492
Incorrectly classified: 508
Test accuracy: 94.92%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.95      0.95      0.95      1032
           3       0.96      0.93      0.95      1010
           4       0.92      0.95      0.94       982
           5       0.96      0.91      0.94       892
           6       0.97      0.96      0.96       958
           7       0.93      0.96      0.95      1028
           8       0.92      0.96      0.94       974
           9       0.94      0.89      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9492
Incorrectly classified: 508
Test accuracy: 94.92%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.98      0.98      1135
           2       0.94      0.97      0.96      1032
           3       0.94      0.93      0.93      1010
           4       0.93      0.95      0.94       982
           5       0.97      0.89      0.93       892
           6       0.96      0.97      0.96       958
           7       0.96      0.95      0.96      1028
           8       0.90      0.95      0.93       974
           9       0.93      0.93      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9512
Incorrectly classified: 488
Test accuracy: 95.12%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.99      0.97      0.98      1135
           2       0.96      0.95      0.95      1032
           3       0.93      0.95      0.94      1010
           4       0.92      0.96      0.94       982
           5       0.96      0.92      0.94       892
           6       0.97      0.96      0.96       958
           7       0.97      0.95      0.96      1028
           8       0.90      0.95      0.92       974
           9       0.95      0.91      0.93      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9465
Incorrectly classified: 535
Test accuracy: 94.65%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.99      0.98      1135
           2       0.94      0.97      0.95      1032
           3       0.96      0.91      0.93      1010
           4       0.93      0.96      0.94       982
           5       0.95      0.91      0.93       892
           6       0.96      0.96      0.96       958
           7       0.97      0.92      0.94      1028
           8       0.89      0.96      0.92       974
           9       0.92      0.91      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9495
Incorrectly classified: 505
Test accuracy: 94.95%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.98      0.99      0.99      1135
           2       0.95      0.95      0.95      1032
           3       0.95      0.92      0.93      1010
           4       0.95      0.93      0.94       982
           5       0.95      0.93      0.94       892
           6       0.97      0.97      0.97       958
           7       0.95      0.95      0.95      1028
           8       0.92      0.94      0.93       974
           9       0.92      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9470
Incorrectly classified: 530
Test accuracy: 94.70%
              precision    recall  f1-score   support

           0       0.96      0.98      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.96      0.95      0.95      1032
           3       0.92      0.96      0.94      1010
           4       0.95      0.93      0.94       982
           5       0.95      0.92      0.93       892
           6       0.96      0.97      0.96       958
           7       0.96      0.94      0.95      1028
           8       0.91      0.95      0.93       974
           9       0.92      0.90      0.91      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9448
Incorrectly classified: 552
Test accuracy: 94.48%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.97      0.98      1135
           2       0.96      0.94      0.95      1032
           3       0.92      0.95      0.93      1010
           4       0.92      0.95      0.93       982
           5       0.93      0.93      0.93       892
           6       0.97      0.95      0.96       958
           7       0.96      0.95      0.95      1028
           8       0.89      0.94      0.92       974
           9       0.93      0.90      0.91      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.94      0.94     10000
weighted avg       0.95      0.94      0.94     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9476
Incorrectly classified: 524
Test accuracy: 94.76%
              precision    recall  f1-score   support

           0       0.98      0.98      0.98       980
           1       0.99      0.97      0.98      1135
           2       0.95      0.96      0.96      1032
           3       0.89      0.96      0.92      1010
           4       0.96      0.93      0.94       982
           5       0.96      0.91      0.93       892
           6       0.97      0.96      0.97       958
           7       0.97      0.94      0.96      1028
           8       0.91      0.92      0.92       974
           9       0.91      0.93      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9500
Incorrectly classified: 500
Test accuracy: 95.00%
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       980
           1       0.99      0.99      0.99      1135
           2       0.96      0.95      0.96      1032
           3       0.91      0.95      0.93      1010
           4       0.95      0.93      0.94       982
           5       0.95      0.92      0.93       892
           6       0.96      0.97      0.97       958
           7       0.97      0.95      0.96      1028
           8       0.94      0.91      0.92       974
           9       0.90      0.94      0.92      1009

   micro avg       0.95      0.95      0.95     10000
   macro avg       0.95      0.95      0.95     10000
weighted avg       0.95      0.95      0.95     10000


===== Adversarial evaluation =====

Loading model: ../trained_models/baseline/mnist_baseline.h5

Loading adversaries generated with carlini_linf method on mnist
10000 10000
Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

Adversarial test data.
Correctly classified: 9562
Incorrectly classified: 438
Adversarial accuracy: 95.62%
              precision    recall  f1-score   support

           0       0.97      0.98      0.98       980
           1       0.98      0.99      0.99      1135
           2       0.96      0.96      0.96      1032
           3       0.94      0.96      0.95      1010
           4       0.93      0.96      0.94       982
           5       0.96      0.95      0.96       892
           6       0.96      0.97      0.97       958
           7       0.95      0.95      0.95      1028
           8       0.95      0.95      0.95       974
           9       0.94      0.90      0.92      1009

   micro avg       0.96      0.96      0.96     10000
   macro avg       0.96      0.96      0.96     10000
weighted avg       0.96      0.96      0.96     10000

Input shape:  (10000, 28, 28, 1)

Computing  15 random projections in  one_channel mode: 
Projected data dimensions: (15, 10000, 20, 20, 1)

 === projections report ===

Test evaluation on projection  123

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9290
Incorrectly classified: 710
Test accuracy: 92.90%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.97      1135
           2       0.96      0.91      0.94      1032
           3       0.92      0.93      0.92      1010
           4       0.87      0.93      0.90       982
           5       0.89      0.93      0.91       892
           6       0.94      0.96      0.95       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.91      0.91       974
           9       0.92      0.84      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  45

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9289
Incorrectly classified: 711
Test accuracy: 92.89%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.92      0.93      0.92      1010
           4       0.84      0.95      0.89       982
           5       0.94      0.93      0.93       892
           6       0.97      0.96      0.96       958
           7       0.94      0.91      0.93      1028
           8       0.89      0.94      0.92       974
           9       0.92      0.79      0.85      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  180

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9354
Incorrectly classified: 646
Test accuracy: 93.54%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.94      0.94      1032
           3       0.92      0.94      0.93      1010
           4       0.90      0.94      0.92       982
           5       0.92      0.95      0.93       892
           6       0.96      0.96      0.96       958
           7       0.95      0.91      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.89      0.87      0.88      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.94      0.93     10000
weighted avg       0.94      0.94      0.94     10000


Test evaluation on projection  172

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9256
Incorrectly classified: 744
Test accuracy: 92.56%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.89      0.94      0.91      1010
           4       0.87      0.95      0.90       982
           5       0.93      0.92      0.92       892
           6       0.94      0.97      0.95       958
           7       0.89      0.94      0.92      1028
           8       0.95      0.87      0.91       974
           9       0.93      0.79      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.92      0.92     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  61

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9294
Incorrectly classified: 706
Test accuracy: 92.94%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.93      0.93      1032
           3       0.93      0.93      0.93      1010
           4       0.84      0.95      0.89       982
           5       0.95      0.90      0.93       892
           6       0.96      0.95      0.95       958
           7       0.94      0.92      0.93      1028
           8       0.91      0.93      0.92       974
           9       0.90      0.84      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  63

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9307
Incorrectly classified: 693
Test accuracy: 93.07%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.98      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.90      0.94      0.92      1010
           4       0.89      0.91      0.90       982
           5       0.94      0.92      0.93       892
           6       0.96      0.95      0.96       958
           7       0.95      0.92      0.93      1028
           8       0.93      0.91      0.92       974
           9       0.87      0.88      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  70

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9315
Incorrectly classified: 685
Test accuracy: 93.15%
              precision    recall  f1-score   support

           0       0.96      0.97      0.97       980
           1       0.97      0.98      0.98      1135
           2       0.93      0.94      0.93      1032
           3       0.94      0.92      0.93      1010
           4       0.87      0.94      0.90       982
           5       0.93      0.92      0.92       892
           6       0.95      0.95      0.95       958
           7       0.91      0.95      0.93      1028
           8       0.93      0.92      0.92       974
           9       0.92      0.81      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  83

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9350
Incorrectly classified: 650
Test accuracy: 93.50%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.98      0.97      0.98      1135
           2       0.92      0.95      0.94      1032
           3       0.94      0.93      0.93      1010
           4       0.88      0.94      0.91       982
           5       0.95      0.93      0.94       892
           6       0.95      0.96      0.96       958
           7       0.94      0.93      0.94      1028
           8       0.91      0.92      0.91       974
           9       0.91      0.86      0.89      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.94      0.94      0.93     10000


Test evaluation on projection  115

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9334
Incorrectly classified: 666
Test accuracy: 93.34%
              precision    recall  f1-score   support

           0       0.97      0.96      0.97       980
           1       0.98      0.97      0.98      1135
           2       0.94      0.93      0.93      1032
           3       0.91      0.94      0.93      1010
           4       0.87      0.96      0.91       982
           5       0.92      0.94      0.93       892
           6       0.96      0.95      0.96       958
           7       0.93      0.94      0.93      1028
           8       0.92      0.93      0.92       974
           9       0.93      0.81      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  67

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9321
Incorrectly classified: 679
Test accuracy: 93.21%
              precision    recall  f1-score   support

           0       0.97      0.96      0.96       980
           1       0.97      0.98      0.98      1135
           2       0.92      0.96      0.94      1032
           3       0.95      0.92      0.93      1010
           4       0.86      0.95      0.90       982
           5       0.93      0.93      0.93       892
           6       0.96      0.96      0.96       958
           7       0.95      0.90      0.93      1028
           8       0.91      0.94      0.92       974
           9       0.92      0.81      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  56

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9322
Incorrectly classified: 678
Test accuracy: 93.22%
              precision    recall  f1-score   support

           0       0.96      0.96      0.96       980
           1       0.97      0.99      0.98      1135
           2       0.93      0.92      0.93      1032
           3       0.94      0.92      0.93      1010
           4       0.89      0.92      0.90       982
           5       0.91      0.95      0.93       892
           6       0.96      0.96      0.96       958
           7       0.92      0.94      0.93      1028
           8       0.94      0.91      0.92       974
           9       0.91      0.85      0.88      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  133

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9300
Incorrectly classified: 700
Test accuracy: 93.00%
              precision    recall  f1-score   support

           0       0.95      0.97      0.96       980
           1       0.97      0.97      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.91      0.93      0.92      1010
           4       0.90      0.92      0.91       982
           5       0.92      0.94      0.93       892
           6       0.95      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.91      0.92      0.91       974
           9       0.92      0.83      0.87      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  12

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9264
Incorrectly classified: 736
Test accuracy: 92.64%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.99      0.96      0.98      1135
           2       0.94      0.92      0.93      1032
           3       0.90      0.93      0.92      1010
           4       0.86      0.93      0.89       982
           5       0.90      0.95      0.93       892
           6       0.96      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.90      0.91      0.91       974
           9       0.91      0.81      0.86      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  198

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9292
Incorrectly classified: 708
Test accuracy: 92.92%
              precision    recall  f1-score   support

           0       0.98      0.96      0.97       980
           1       0.98      0.96      0.97      1135
           2       0.93      0.93      0.93      1032
           3       0.87      0.95      0.91      1010
           4       0.92      0.92      0.92       982
           5       0.92      0.92      0.92       892
           6       0.95      0.95      0.95       958
           7       0.93      0.93      0.93      1028
           8       0.91      0.89      0.90       974
           9       0.90      0.88      0.89      1009

   micro avg       0.93      0.93      0.93     10000
   macro avg       0.93      0.93      0.93     10000
weighted avg       0.93      0.93      0.93     10000


Test evaluation on projection  156

===== Test set evaluation =====

Testing infos:
x_test.shape =  (10000, 20, 20, 1) 
y_test.shape =  (10000, 10) 

Correctly classified: 9350
Incorrectly classified: 650
Test accuracy: 93.50%
              precision    recall  f1-score   support

           0       0.97      0.97      0.97       980
           1       0.98      0.98      0.98      1135
           2       0.95      0.92      0.94      1032
           3       0.88      0.94      0.91      1010
           4       0.93      0.93      0.93       982
           5       0.91      0.93      0.92       892
           6       0.95      0.97      0.96       958
           7       0.95      0.93      0.94      1028
           8       0.95      0.87      0.91       974
           9       0.88      0.91      0.90      1009

   micro avg       0.94      0.94      0.94     10000
   macro avg       0.94      0.93      0.93     10000
weighted avg       0.94      0.94      0.94     10000

